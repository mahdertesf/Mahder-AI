{"cells":[{"cell_type":"markdown","metadata":{"id":"1J2hpt7S7acC"},"source":["<center>\n","    <h1><b>Pretraining a Transformer Model from Scratch on an Amharic Dataset and Fine-Tuning for Amharic Hate Speech Recognition Task</b></h1>\n","</center>\n"]},{"cell_type":"markdown","metadata":{"id":"YVhS5vAY7acF"},"source":["## Table of Contents  \n","1. [Introduction](#introduction)  \n","2. [Importing Packages](#importing-packages)  \n","3. [Dataset Collection & Preprocessing](#dataset-collection--preprocessing)  \n","   - 3.1 [Data Collection](#data-collection)  \n","   - 3.2 [Data Cleaning](#data-cleaning)  \n","   - 3.3 [Tokenization](#tokenization)  \n","   - 3.4 [Tokenizing and Masking](#tokenizing-and-masking)  \n","   - 3.5 [Creating Training Data Pairs](#creating-training-data-pairs)  \n","4. [Pretraining the Transformer Model](#pretraining-the-transformer-model)  \n","   - 4.1 [Positional Encoding](#positional-encoding)  \n","   - 4.2 [Masking](#masking)  \n","   - 4.3 [Self Attention](#self-attention)  \n","   - 4.4 [Encoder](#encoder)  \n","   - 4.5 [Decoder](#decoder)  \n","   - 4.6 [Transformer](#transformer)  \n","   - 4.7 [Initialize_Model](#initialize-model)  \n","   - 4.8 [Pre-training](#pre-training)  \n","5. [Fine-Tuning for Hate Speech Recognition](#fine-tuning-for-hate-speech-recognition)  \n","6. [Evaluation](#evaluation)  \n","7. [Deployment on Mahder AI App](#deployment-on-mahder-ai-app)  \n","8. [Conclusion](#conclusion)  \n"]},{"cell_type":"markdown","metadata":{"id":"zdCmWd0P7acG"},"source":["## 1. Introduction  \n","\n","In this notebook, I will pretrain a Transformer network on an Amharic dataset collected from a variety of Telegram channels, using the Masked Language Model (MLM). The primary objective of pretraining is to enable the model to learn contextualized word and phrase representations, thereby enhancing its understanding of language semantics. The Transformerâ€™s self-attention mechanism plays a crucial role by allowing the model to dynamically weigh different parts of the input sequence, effectively capturing long-range dependencies in the data.  \n","\n","After pretraining, I will fine-tune the model on a labeled dataset of hate speech and deploy the resulting model in the **Mahder AI** app.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24196,"status":"ok","timestamp":1740034354931,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"e0ctKNwS7hc4","outputId":"fbcb22e9-8f96-4a8c-f59e-b1b3e728b5ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# prompt: import drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"wE_KPXem7acG"},"source":["\n","## 2. Importing the Packages\n","\n","Let's start by importing all the required libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":139662,"status":"ok","timestamp":1740034508704,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"rKOdmCJC8BTd","outputId":"79425b64-5d8d-4d54-f8c0-fd61c4544ddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: tensorflow 2.18.0\n","Uninstalling tensorflow-2.18.0:\n","  Would remove:\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.11/dist-packages/tensorflow-2.18.0.dist-info/*\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/aligned_allocator.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/base.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/cache_control.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/algo/copy-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/algo/find-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/algo/transform-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/order.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/shared-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/sorting_networks-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/traits-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/traits128-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/vqsort-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/contrib/sort/vqsort.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/detect_compiler_arch.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/detect_targets.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/foreach_target.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/highway.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/highway_export.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/arm_neon-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/arm_sve-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/emu128-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/generic_ops-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/scalar-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/set_macros-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/shared-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/tuple-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/x86_128-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/x86_256-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/ops/x86_512-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/per_target.cc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/per_target.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/print-inl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/print.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/com_google_highway/hwy/targets.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/local_config_nccl/_virtual_includes/nccl_config/third_party/nccl/nccl_config.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/external/local_config_nccl/nccl_config.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/jit/xla_tpu_device.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/service/tpu_computation_placer.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/noncopyable_buffer.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/status_helper.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_api_dlsym_set_fn.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_event.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_executable.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_executable_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_executor.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_executor_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_executor_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_initialize_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_library_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_node_context.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_op_executable.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_platform.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_platform_id.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_platform_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_profiler_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_stream.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_stream_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_topology.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_transfer_manager.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tpu_transfer_manager_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/compiler/xla/stream_executor/tpu/tsl_status_helper.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/common_runtime/device_propagation.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/common_runtime/next_pluggable_device/c/outside_compilation_params.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb_text-impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/attr_value.pb_text.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/resource_handle.pb_text-impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/resource_handle.pb_text.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/tensor.pb_text-impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/tensor.pb_text.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.pb_text-impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.pb_text.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/types.pb_text-impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/framework/types.pb_text.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/protobuf/tpu/compilation_result.pb.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/combine_tpu_embedding_load_retrieve_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/cond_builder.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/configure_tpu_embedding_rewrite_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/distributed_tpu_configuration_rewrite_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_helpers.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass_internal.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/host_training_loop_optimization_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/incomplete_nodedef_builder.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/tpu_embedding_rewrite_pass_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/tpu_embedding_software_deduplication_rewrite_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/update_tpu_embedding_ops_passes.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/graph_rewrite/variable_merger_pass.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/compiled_subgraph.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/infeed_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/outfeed_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/sharding_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/sparse_core_ops_stats_handler.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/sparse_core_ops_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/sparse_core_preprocess_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/sparse_core_xla_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache.pb.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_common.pb.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_entry.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_entry_unloader.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_external.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_factory.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_grpc.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_key.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_local_lookup.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_lookup.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_rpc_lookup.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_rpc_support.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_cache_service.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compilation_metrics.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile.pb.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile_op.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile_op_common.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile_op_impl.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile_op_options.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_compile_op_support.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_configuration_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_embedding_engine_state_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_embedding_enqueue_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_embedding_load_retrieve_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_executable_info.pb.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_execute_op.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_execute_op_options.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_fingerprint_lookup.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_functional_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_mesh_state_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_op_consts.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_op_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_ordinal_selector.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_ordinal_selector_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_pod_state.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_program_group.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_program_group_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_reshard_variables_op.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_reshard_variables_op_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/tpu_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/trace_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/kernels/transfer_ops.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_compile_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_configuration.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_embedding_configuration_proto_rewrite.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_embedding_configuration_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_embedding_spmd_sharding_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_execute.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_fingerprint_utils.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_init_mode.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/tpu_node_device_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/core/tpu/virtual_device.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/dtensor/cc/dstatus.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/tensorflow/dtensor/cc/tpu_system_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/service/tpu_computation_placer.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/noncopyable_buffer.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/status_helper.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_api_dlsym_set_fn.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_event.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_executable.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_executable_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_executor.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_executor_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_executor_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_initialize_util.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_library_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_node_context.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_op_executable.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_platform.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_platform_id.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_platform_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_profiler_init_fns.inc\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_stream.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_stream_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_topology.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_transfer_manager.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tpu_transfer_manager_interface.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/include/xla/stream_executor/tpu/tsl_status_helper.h\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/is_mlir_bridge_test_true.py\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/grpc_tpu_worker.py\n","    /usr/local/lib/python3.11/dist-packages/tensorflow/python/tools/grpc_tpu_worker_service.py\n","Proceed (Y/n)? Y\n","Y\n","Y\n","  Successfully uninstalled tensorflow-2.18.0\n","Collecting tensorflow==2.13\n","  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (25.2.10)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13)\n","  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.70.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (3.12.1)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13)\n","  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (18.1.1)\n","Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13)\n","  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (24.2)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.13)\n","  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.17.0)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13)\n","  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13)\n","  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (2.5.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.17.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13) (0.45.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (5.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.2)\n","Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m524.2/524.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: typing-extensions, tensorflow-estimator, protobuf, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.12.2\n","    Uninstalling typing_extensions-4.12.2:\n","      Successfully uninstalled typing_extensions-4.12.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.3\n","    Uninstalling protobuf-5.29.3:\n","      Successfully uninstalled protobuf-5.29.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.8.0\n","    Uninstalling keras-3.8.0:\n","      Successfully uninstalled keras-3.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.6.0\n","    Uninstalling gast-0.6.0:\n","      Successfully uninstalled gast-0.6.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.1\n","    Uninstalling google-auth-oauthlib-1.2.1:\n","      Successfully uninstalled google-auth-oauthlib-1.2.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.5.1+cpu requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n","tensorflow-tpu 2.18.0 requires keras>=3.5.0, but you have keras 2.13.1 which is incompatible.\n","tensorflow-tpu 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n","tensorflow-tpu 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.13.0 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.13.0 which is incompatible.\n","pyopenssl 25.0.0 requires typing-extensions>=4.9; python_version < \"3.13\" and python_version >= \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\n","altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.13.0 which is incompatible.\n","treescope 0.1.8 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n","pydantic-core 2.27.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 protobuf-4.25.6 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"a074ff823c134b9394a2ecab9981ee71","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/590.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.14.1\n"]}],"source":["!pip uninstall tensorflow\n","!pip install tensorflow==2.13\n","!pip install emoji"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1740034945155,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"GPBZctpZ7acG"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import json\n","import re\n","import random\n","import emoji\n","import sentencepiece as spm\n","import string\n","from collections import Counter\n","import time\n","from tensorflow.keras.optimizers.legacy import Adam\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy\n"]},{"cell_type":"markdown","metadata":{"id":"N4L2Saw37acH"},"source":["## 3. Dataset Collection & Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"GjqKU4_O7acH"},"source":["### 3.1 Data Collection  \n","\n","In order to pretrain the Transformer network from scratch, we will use **self-supervised learning**, which requires a large corpus of unlabeled text. We will apply a **Masked Language Model (MLM)** to pre-train the model.  \n","\n","#### **Why Telegram Channels?**  \n","Telegram is the most widely used platform for information storage in Ethiopia. For this reason, I have chosen **Telegram channels** as the primary data source. Most of the selected channels are news channels, ensuring a diverse and rich dataset.  \n","\n","#### **Data Collection Method**  \n","To collect the data, I used the **Telethon Python library** and the **Telegram API** to scrape text from selected channels.  \n","\n","#### **Selected Telegram Channels**  \n","The dataset has been collected from the following Telegram channels:  \n","\n","- [Tikvah Ethiopia](https://t.me/tikvahethiopia)  \n","- [Addis Standard Amharic](https://t.me/AddisstandardAmh)  \n","- [Tarikn Wedehuala](https://t.me/TariknWedehuala)  \n","- [Addis News](https://t.me/Addis_News)  \n","- [Zena 24 Now](https://t.me/zena24now)  \n","- [Tikvah University](https://t.me/TikvahUniversity)  \n","- [Tikvah Ethiopia Magazine](https://t.me/tikvahethmagazine)  \n","- [Tikvah Ethiopia Sport](https://t.me/tikvahethsport)  \n","- [Philosophy Thoughts](https://t.me/Philosophy_Thoughts1)  \n","- [Mudenyaz](https://t.me/Mudenyaz)  \n","- [Yemeri Terekoch](https://t.me/yemeri_terekoch)  \n","- [Bemnet Library](https://t.me/Bemnet_Library)  \n","- [Amazing Fact](https://t.me/amazing_fact_433)  \n","- [Zephilosophy](https://t.me/Zephilosophy)  \n","- [Huluezih](https://t.me/huluezih)  \n","\n","#### **Accessing Collected Data**  \n","To access the code and all the raw data collected from each channel, visit the following GitHub repository:  \n","[GitHub Repository Link](https://github.com/your-repo-link-here).\n"]},{"cell_type":"markdown","metadata":{"id":"JnUA4vfH7acH"},"source":["### 3.2 Data Loading and Cleaning"]},{"cell_type":"markdown","metadata":{"id":"hNPPrn1u7acI"},"source":["Next, we will define a function that will load data from a JSON file as an array of strings."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1740034946833,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"irp-Ussh7acI"},"outputs":[],"source":["def load_data(filepath):\n","    return_data=[]\n","    with open (filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n","        datas=json.load(file)\n","        for data in datas:\n","            return_data.append(data[\"text\"])\n","\n","    return return_data"]},{"cell_type":"markdown","metadata":{"id":"h84LYoxF7acI"},"source":["The following code shows how the news look like"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"elapsed":27,"status":"error","timestamp":1740034947216,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"FF0pSU8A7acI","outputId":"cbd1a140-295a-43be-e8c9-0ca24af9113f"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'datas/sample.json'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7450cc368d30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datas/sample.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnews\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------------------------------------------------------\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-8275bafd3998>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mreturn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datas/sample.json'"]}],"source":["sample=load_data(\"datas/sample.json\")\n","for news in sample[:5]:\n","    print(news)\n","\n","    print(\"---------------------------------------------------------------------------------\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"MqYspiHw7acJ"},"source":["Since we are working with a Telegram dataset, we aim to clean the text by removing substrings that are commonly used on the platform, such as hashtagged entities, usernames, hyperlinks,emojis, and english words. To achieve this, we will use Python's re library to perform regular expression operations. We will define specific search patterns and use the sub() method to remove matches by replacing them with an empty string (''). We will also remove unecessary multiple spaces to a single space\n","\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1740034948503,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"ZIWrHmwf7acJ"},"outputs":[],"source":["def clean_text(text):\n","    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n","    text = re.sub(r'#\\S+', '', text)\n","    text=re.sub(r'@\\S+', '', text)\n","    text=emoji.replace_emoji(text,\" \")\n","    english_pattern = re.compile(r'\\b[A-Za-z]+\\b')\n","    cleaned_text = re.sub(english_pattern, '', text)\n","    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n","\n","    return cleaned_text\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ycC9jQBC7acJ"},"source":["\n","Let's test the above function on sample data\n"]},{"cell_type":"markdown","metadata":{"id":"RcMrlouP7acJ"},"source":["let's load our training data and see how many contents we have and what the first 5 contents look like"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2462,"status":"ok","timestamp":1740034951507,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"DNfn1d4c7acJ","outputId":"088a44dc-29cb-4309-939f-c4dde217a436"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of contents: 193419\n","\n","First 5 contents: \n","\n","#áˆ˜á‰„á‹¶áŠ•á‹«\n","\n","áˆ°á‹áŠ• áˆˆáˆ˜áˆ­á‹³á‰µ áˆ°á‹ áˆ˜áˆ†áŠ• á‰ á‰‚ áŠá‹ !\n","\n","á‰µáˆ‹áŠ•á‰µ á‹¨áŠ«á‰²á‰µ 1/2017 á‹“/áˆ á‰ áŒ€áˆ˜áˆ¨á‹ á‹¨áˆ˜á‰„á‹¶áŠ•á‹« á‹¨áŠ áˆ¨áŒ‹á‹Šá‹«áŠ• áŠ¥áŠ“ á‹¨áŠ áŠ¥áˆáˆ® áˆ…áˆ™áˆ›áŠ• áˆ˜áˆ­áŒƒ áˆ›á‹•áŠ¨áˆ á‹¨á‹µáŒ‹á áˆ›áˆ°á‰£áˆ°á‰¥ á‹˜áˆ˜á‰» áŠ¥áˆµáŠ©áŠ• 120,000,000 á‰¥áˆ­ á‰°áˆ°á‰¥áˆµá‰§áˆá¢\n","\n","áˆ˜á‰„á‹¶áŠ•á‹« á‰ áˆšá‹«áˆµáŒˆáŠá‰£á‹ áˆ†áˆµá’á‰³áˆ áŒ­áˆáˆ­ á‹«áˆˆá‹ áˆ…áŠ•áƒ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹¨áŒˆáŠ•á‹˜á‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŠ áŒ‹áŒ¥áˆá‰³áˆá¢ áˆ…áŠ•áƒá‹ áˆˆáˆ›áŒ áŠ“á‰€á‰… áŒˆáŠ•á‹˜á‰¥ á‰°á‰¸áŒáˆ¨áŠ“áˆá¢ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹ˆá‹° 5 á‰¢áˆŠá‹®áŠ• á‰¥áˆ­ á‹«áˆµáˆáˆáŒ‹áˆá¢\n","\n","á‰ á‰€áŒ¥á‰³ á‹­áŠ¨á‰³á‰°áˆ‰ ğŸ‘‡\n","https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n","\n","á‹¨áˆá‰µá‰½áˆ‰á‰µáŠ• áˆáˆ‰ á‹µáŒ‹á áŠ á‹µáˆ­áŒ‰á¢\n","\n","@tikvahethiopia\n","---------------------------------------------------------------------------------\n","\n","\n","ğŸ”Š #á‹¨áˆ áˆ«á‰°áŠá‰½á‹µáˆáŒ½\n","\n","\" á‰‹áˆš áˆ áˆ«á‰°áŠá‰½ áˆ†áŠáŠ• áˆ³áˆˆ á‰ á‹°áˆá‹ áˆ›áˆ»áˆ»á‹«á‹ áŠ áˆá‰°áŠ«á‰°á‰µáŠ•áˆ \" - á‹¨áˆ€á‹‹áˆ³ á‹™áˆªá‹« á‹ˆáˆ¨á‹³ áˆ˜áŠ•áŒáˆµá‰µ áˆ áˆ«á‰°áŠá‰½\n","\n","á‹¨áˆ›áŠ­áˆ® áŠ¢áŠ®áŠ–áˆš áˆ›áˆ»áˆ»á‹« áˆªááˆ­áˆ™áŠ• á‰°áŠ¨á‰µáˆ á‹¨áˆšáŠ¨áˆ°á‰± á‹¨áŠ‘áˆ® á‹‰á‹µáŠá‰µáŠ“ á‰°á‹«á‹«á‹¥ áŒ‰á‹³á‹®á‰½áŠ• á‰³áˆ³á‰¢ á‰ áˆ›á‹µáˆ¨áŒ á‹¨áˆ˜áŠ•áŒáˆµá‰µ áˆ áˆ«á‰°áŠá‰½ á‹°áˆá‹ áˆ›áˆ»áˆ»á‹« á‰°á‹°áˆ­áŒ áŠ¨áŒ¥á‰…áˆá‰µ á‹ˆáˆ­ 2017 á‹“/áˆ áŒ€áˆáˆ® á‰°áŒá‰£áˆ«á‹Š á‹¨á‰°á‹°áˆ¨áŒˆ áˆ˜áˆ†áŠ‘ á‹­á‰³á‹ˆá‰ƒáˆá¢\n","\n","á‰ áˆ²á‹³áˆ› áŠ­áˆáˆá¤ áˆ°áˆœáŠ“á‹Š áˆ²á‹³áˆ› á‹áŠ•á¤ áˆ€á‹‹áˆ³ á‹™áˆªá‹« á‹ˆáˆ¨á‹³ á‰ á‰°áˆˆá‹«á‹© á‹¨áˆ˜áŠ•áŒáˆµá‰µ áˆ˜áˆµáˆªá‹« á‰¤á‰¶á‰½ á‹¨áˆšáˆ°áˆ© á‹¨áˆ˜áŠ•áŒáˆµá‰µ áˆ áˆ«á‰°áŠá‰½ áŒáŠ• \" áŠ¨2012 á‹“/áˆ áŒ€áˆáˆ® á‰ á‰‹áˆšáŠá‰µ á‰°á‰€áŒ¥áˆ¨áŠ• áŠ¥á‹¨áˆ°áˆ«áŠ• á‹«áˆˆáŠ• á‰¢áˆ†áŠ•áˆ á‰ áŠ á‹²áˆ± á‹¨áˆ˜áŠ•áŒáˆµá‰µ áˆ áˆ«á‰°áŠá‰½ á‹¨á‹°áˆ˜á‹ˆá‹ áˆ›áˆ»áˆ»á‹« áŠ áˆá‰°áŠ«á‰°á‰µáŠ•áˆ \" áˆ²áˆ‰ á‰…áˆ¬á‰³á‰¸á‹‰áŠ• áˆˆá‰²áŠ­á‰«áˆ… áŠ¢á‰µá‹®áŒµá‹« áŠ áˆµáŒˆá‰¥á‰°á‹‹áˆá¢\n","\n","á‰…áˆ¬á‰³á‰¸á‹‰áŠ• áŠ«á‹°áˆ¨áˆ±áŠ• áˆ˜áŠ«áŠ¨áˆ á¦\n","- á‰ áŠ¨á‰°áˆ› áˆáˆ›á‰µáŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ•á£\n","- áˆ›á‹˜áŒ‹áŒƒ á‰¤á‰¶á‰½á£\n","- á‰ á‰µáˆáˆ…áˆ­á‰µ á‹˜áˆ­á á£\n","- á‰ áˆ´á‰¶á‰½áŠ“ áˆ•áƒáŠ“á‰µ áŠ¥áŠ•á‹²áˆáˆ á‰ áˆ•á‰¥áˆ¨á‰µ áˆµáˆ« áŒ½/á‰¤á‰¶á‰½ á‹¨áˆšáˆ°áˆ© áˆ áˆ«á‰°áŠá‰½ áŠ“á‰¸á‹á¢\n","\n","\" á‰ á‹ˆá‰…á‰± á‰ áŠ áŒá‰£á‰¡ áˆ›áˆµá‰³á‹ˆá‰‚á‹« á‹ˆáŒ¥á‰¶ á‰°áˆ˜á‹áŒá‰ áŠ•áŠ“ á‰°á‹ˆá‹³á‹µáˆ¨áŠ• áˆ›áˆˆá‹á‰½áŠ• á‰°áˆ¨áŒ‹áŒáŒ¦ á‹¨á‰‹áˆšáŠá‰µ á‹°á‰¥á‹³á‰¤ á‰°áˆ°áŒ¥á‰¶áŠ• áˆ‹áˆˆá‰á‰µ áŠ áˆáˆµá‰µáŠ“ áˆµá‹µáˆµá‰µ á‹“áˆ˜á‰³á‰µ á‹°áˆá‹ áˆ²áŠ¨áˆáˆˆáŠ• á‰ á‰†á‹¨áŠ•á‰£á‰¸á‹ áˆ˜á‹°á‰¦á‰½ áˆ‹á‹­ áŠ¥á‹¨áˆ°áˆ«áŠ• á‰£áˆˆáŠ•á‰ á‰µ á‰ áŠ á‹²áˆ± á‹¨á‹°áˆá‹ áˆ›áˆ»áˆ»á‹« áŠ áˆˆáˆ˜áŠ«á‰°á‰³á‰½áŠ• áˆˆá‹˜áˆ­áˆ á‰¥á‹™ á‰½áŒáˆ®á‰½ á‹³áˆ­áŒáŠ“áˆ \" á‰¥áˆˆá‹‹áˆá¢\n","\n","\" áˆˆá‹ˆáˆ¨á‹³á‹‰ áá‰¥áˆŠáŠ­ áˆ°áˆ­á‰ªáˆµáŠ“ á‹¨áˆ°á‹‰ áˆƒá‰¥á‰µ áˆáˆ›á‰µ áŒ½/á‰¤á‰µ áŠ¥áŠ“ áˆˆáŠ­áˆáˆ‰ áá‰¥áˆŠáŠ­ áˆ°áˆ­á‰ªáˆµ á‰¢áˆ® á‰…áˆ¬á‰³á‰½áŠ•áŠ• á‰ áŠ áŠ«áˆáŠ“ á‰ á…áˆá á‰¥áŠ“á‰€áˆ­á‰¥áˆ á‰°áŒˆá‰¢á‹‰ áˆáˆ‹áˆ½ áŠ áˆá‰°áˆ°áŒ áŠ•áˆ áŒ‰á‹³á‹©áŠ• áˆˆáŠ¢á‰µá‹®áŒµá‹« áŠ¥áˆá‰£ áŒ á‰£á‰‚ á‰°á‰‹áˆ áˆˆáˆ›á‰…áˆ¨á‰¥ áˆ˜áˆ¨áŒƒ áŠ¥á‹«á‹°áˆ«áŒ€áŠ• áŠá‹ \" áˆ²áˆ‰ á‰°áŠ“áŒáˆ¨á‹‹áˆá¢\n","\n","á‰ƒáˆ‹á‰¸á‹áŠ• áˆˆá‰²áŠ­á‰«áˆ… áŠ¢á‰µá‹®áŒµá‹« á‹¨áˆ°áŒ¡á‰µ á¤ á‹¨áˆ€á‹‹áˆ³ á‹™áˆªá‹« á‹ˆáˆ¨á‹³ áá‰¥áˆŠáŠ­ áˆ°áˆ­á‰ªáˆµ áŠ¥áŠ“ á‹¨áˆ°á‹‰ áˆƒá‰¥á‰µ áˆáˆ›á‰µ áŒ½/á‰¤á‰µ áŠƒáˆ‹áŠ áŠ á‰¶ áˆƒá‹­áˆ‰ áŠ á‰¢áŠ– á¥ \" á‰ á‹ˆáˆ¨á‹³á‹‰ á‰ 2012 á‹“/áˆ á‹¨áŠá‰ áˆ¨á‹ áŠ áŒá‰£á‰¥áŠá‰µ á‰ áˆŒáˆˆá‹ á‰…áŒ¥áˆ­ á‰ áŠ áŠ•á‹µ áˆ˜á‹°á‰¥ áˆ¶áˆµá‰µáŠ“ áŠ áˆ«á‰µ áˆ°á‹á‰½áŠ• á‰ á‰°á‹°áˆ«áˆ«á‰¢áŠá‰µ á‹¨áˆ˜á‰…áŒ áˆ­ áˆáŠ”á‰³á‹á‰½ áŠ áˆáŠ• áˆˆá‰°áˆáŒ áˆ¨á‹ á‰½áŒáˆ­ á‹‹áŠáŠ› áˆáŠ­áŠ•á‹«á‰µ áˆ†áŠ—áˆ \" áˆ²áˆ‰ áŒˆáˆáŒ¸á‹‹áˆá¢\n","\n","áŠ¨á‹áŠ‘áŠ“ á‹¨áŠ­áˆáˆ‰ áá‰¥áˆáŠ­ áˆ°áˆ­á‰ªáˆµ áŒ‹áˆ­ á‰ áˆ˜áŠ“á‰ á‰¥ áˆ˜áá‰µáˆ” áŠ¥á‹«áˆáˆ‹áˆˆáŒ‰ áˆµáˆˆáˆ˜áˆ†áŠ‘áˆ áŒ á‰áˆ˜á‹‹áˆá¢\n","\n","á‰ á‹ˆá‰…á‰± á‹­áˆ…áŠ• á‰°áŒá‰£áˆ­ á‹¨áˆá€áˆ™ áŠ áˆ˜áˆ«áˆ®á‰½ áŠ¥áŠ“ á‹¨áˆ°á‹‰ áˆƒá‰¥á‰µ áˆáˆ›á‰µ áŠƒáˆ‹áŠá‹á‰½ áˆ‹á‹­ áŠ¥áˆ­áˆáŒƒ áˆ˜á‹ˆáˆ°á‹±áŠ• á‹¨áˆšáŠ“áŒˆáˆ©á‰µ áŠƒáˆ‹áŠá‹‰ á‰ á‹ˆáˆ¨á‹³á‹‰ á‰ á‹šáˆ… áˆ˜áˆáŠ­ á‰°áŒ á‰€áŒ¥áˆ¨á‹‰ á‰ áŠ á‹²áˆ± á‹¨á‹°áˆ˜á‹ˆá‹ áˆ›áˆ»áˆ»á‹« á‹«áˆáŠ«á‰°á‰±áŠ“ á‰ á‰€áŒ£á‹­ áˆ˜áá‰µáˆ” á‹¨áˆšáˆáˆˆáŒáˆ‹á‰¸á‹‰ 470 á‰ á‰°áˆˆá‹«á‹© áˆ˜áˆµáˆªá‹« á‰¤á‰¶á‰½ á‹‰áˆµáŒ¥ á‹¨á‰°áˆˆá‹© áˆ°áˆ«á‰°áŠá‰½ áˆµáˆˆáˆ˜áŠ–áˆ«á‰¸á‹‰ áŠ áŠ­áˆˆá‹‹áˆá¢\n","\n","á‹¨áˆ°áˆœáŠ“á‹Š áˆ²á‹³áˆ› á‹áŠ• áá‰¥áˆáŠ­ áˆ°áˆ­á‰ªáˆµáŠ“ á‹¨áˆ°á‹‰ áˆƒá‹­áˆ áˆáˆ›á‰µ áˆ˜áˆáˆªá‹« áŠƒáˆ‹áŠ áŠ á‰¶ á‰ á‹›á‰¥áˆ… á‰£áˆ­áˆ¶ á‰ á‰ áŠ©áˆ‹á‰¸á‹ á‰ 2011 áŠ¥áŠ“ 2012 á‰ áŠ áŠ¨á‰£á‰¢á‹ áˆ•áŒˆá‹ˆáŒ¥ á‰…áŒ¥áˆ®á‰½ áˆ˜áˆá€áˆ›á‰¸á‹áŠ• áŒˆáˆáŒ¸á‹‹áˆá¢\n","\n","á‰ á‹ˆáˆ¨á‹³á‹‰ áŠ áŒ£áˆª á‰¡á‹µáŠ• á‰°á‰‹á‰áˆ á‰ áŠ á‹²áˆ± á‹°áˆá‹ á‹«áˆá‰°áŠ«á‰°á‰±áŠ•áŠ“ á‰ á‹ˆáˆ¨á‹³á‹ á‰…áŒ¥áˆ­ á‹«áˆá‰°áˆá€áˆ˜á‰£á‰¸á‹‰ áŠ­áá‰µ áˆ˜á‹°á‰¦á‰½áŠ• á‹¨áˆ˜áˆˆá‹¨á‰µ áˆµáˆ« áˆ˜áŠ¨áŠ“á‹ˆáŠ‘áŠ• áŠ áŠ•áˆµá‰°á‹‰ á‰ áˆ€á‹‹áˆ³ á‹™áˆªá‹« á‹ˆáˆ¨á‹³ á‰¥á‰» 407 áŠ­áá‰µ áˆ˜á‹°á‰¦á‰½ áˆ˜áŠ–áˆ«á‰¸á‹‰áŠ• áˆˆáˆ›á‹ˆá‰… áˆ˜á‰»áˆ‰áŠ• áŒˆáˆá€á‹‹áˆá¢\n","\n","á‹¨áŠ­áˆáˆ‰ á‹¨á‰ áˆ‹á‹­ áŠ áˆ˜áˆ«áˆ®á‰½ á‰ áˆšá‹«áˆµá‰€áˆáŒ¡á‰µ áŠ á‰…áŒ£áŒ« áˆ˜áˆ°áˆ¨á‰µ áŠ¥áŠá‹šáˆ…áŠ• áˆ áˆ«á‰°áŠá‰½ á‰ áŠá‹šáˆ… áŠ­áá‰µ áˆ˜á‹°á‰¦á‰½ á‹¨áˆ˜á‹°áˆá‹°áˆáŠ“ áˆŒáˆá‰½áˆ áˆ•áŒ‹á‹Š áŠ áˆ˜áˆ«áŒ®á‰½ á‰ áˆ˜áˆáˆˆáŒ á‰ áŠ áŒ­áˆ­ áŒŠá‹œ á‹‰áˆµáŒ¥ áŠ¥áˆá‰£á‰µ áˆˆáˆ˜áˆµáŒ á‰µ áŠ¥á‹¨á‰°áˆ°áˆ« áˆ˜áˆ†áŠ‘áŠ• áŠ áˆµá‰³á‹á‰€á‹‹áˆá¢\n","\n","á‰²áŠ­á‰«áˆ… áŠ¢á‰µá‹®áŒµá‹« áŒ‰á‹³á‹©áŠ• áŠ¥áˆµáŠ¨áˆ˜áŒ¨áˆ¨áˆ» á‰°áŠ¨á‰³á‰µáˆ áˆ˜áˆ¨áŒƒá‹áŠ• á‹­áˆáŠ«áˆá¢\n","\n","#TikvahEthiopiaFamilyHW\n","\n","@tikvahethiopia\n","---------------------------------------------------------------------------------\n","\n","\n","á‹¨IMF áˆ›áŠ”áŒ‚áŠ•áŒ á‹³á‹­áˆ¬áŠ­á‰°áˆ¯ áˆáŠ• áŠ áˆ‰ ?\n","\n","á‹¨á‹“áˆˆáˆ áŠ á‰€á á‹¨áŒˆáŠ•á‹˜á‰¥ á‰°á‰‹áˆ (IMF) áˆ›áŠ”áŒ‚áŠ•áŒ á‹³á‹­áˆ¬áŠ­á‰°áˆ­ áŠ­áˆªáˆµá‰³áˆŠáŠ“ áŒ†áˆ­áŒ‚á‹¬á‰« á‰ áŠ¢á‰µá‹®áŒµá‹« á‹¨áˆµáˆ« á‰†á‹­á‰³ áŠ á‹µáˆ­áŒˆá‹‹áˆá¢\n","\n","á‰ á‹šáˆ…áˆ á‹ˆá‰…á‰µ áŠ¨áŒ /áˆš á‹á‰¢á‹­ áŠ áˆ…áˆ˜á‹µ (á‹¶/áˆ­) áŒ‹áˆ­ áŒ¨áˆáˆ® áŠ¨áŒá‹´áˆ«áˆ áŠ¨áá‰°áŠ› á‰£áˆˆáˆµáˆáŒ£áŠ“á‰µ áŒ‹áˆ­ áˆ˜áŠ­áˆ¨á‹‹áˆá¢\n","\n","á‹¨áŠá‰ áˆ«á‰¸á‹áŠ• á‰†á‹­á‰³ á‰ á‰°áˆ˜áˆˆáŠ¨á‰° áŠ¨áŒˆáŠ•á‹˜á‰¥ áˆšáŠ’áˆµá‰µáˆ© áŠ á‰¶ áŠ áˆ…áˆ˜á‹µ áˆ½á‹´ áŒ‹áˆ­ á‰ áŒ‹áˆ« áˆ˜áŒáˆˆáŒ« áˆ°áŒ¥á‰°á‹ áŠá‰ áˆ­á¢\n","\n","áˆáŠ• áŠ áˆ‰ ?\n","\n","á‹³á‹­áˆ¬áŠ­á‰°áˆ¯ á¤ \" á‹¨áŠ¢á‰µá‹®áŒµá‹« áˆªááˆ­áˆ áŠ¨á‰£á‹µ áŠ¥áŠ“ áŒŠá‹œ á‹¨áˆšá‹ˆáˆµá‹µ áŠá‹ á¤ áŠ¥á‰£áŠ«á‰½áˆ á‰³áŒˆáˆ± \" á‹¨áˆšáˆ áŒ¥áˆª áŠ á‰…áˆ­á‰ á‹‹áˆá¢\n","\n","áŠ¢á‰µá‹®áŒµá‹«á‹á‹«áŠ• áˆˆá‰µá‹•áŒáˆµá‰µ áŠ¥áŠ•á‹²á‹«áˆ³á‹© áŠ¥áŠ“ áŠ¨áˆ˜áŠ•áŒáˆµá‰µ á‹¨áŠ¢áŠ®áŠ–áˆš áˆ›áˆ»áˆ»á‹« áŒ¥áˆ¨á‰¶á‰½ áŒáŠ• áŠ¥áŠ•á‹²á‰†áˆ™ áŒ á‹­á‰€á‹‹áˆá¢\n","\n","áŒ†áˆ­áŒ‚á‹¬á‰« á¥ \" á‹¨áˆªááˆ­áˆ™áŠ• áŒá‰¦á‰½ áˆˆáˆ›áˆ³áŠ«á‰µ á‹¨áŠ áŠ•á‹µáŠá‰µ áŠ áˆµáˆáˆ‹áŒŠ áŠá‹ \" áˆ²áˆ‰ áŠ á…áŠ•áŠ¦á‰µ áˆ°áŒ¥á‰°á‹‹áˆá¢\n","\n","\" áŠ¢á‰µá‹®áŒµá‹« á‹¨á‰°á‰€á‰ áˆˆá‰½á‹ áˆªááˆ­áˆ áŠ¨á‰£á‹µ áŠ¥áŠ“ áŒŠá‹œ á‹¨áˆšá‹ˆáˆµá‹µ á‰¢áˆ†áŠ•áˆ áŠ¥áŒ…áŒ á‰µáˆá‰… á‹áŒ¤á‰µ á‹«áˆµáŒˆáŠ›áˆ \" áˆ²áˆ‰ á‰°áŠ“áŒáˆ¨á‹‹áˆá¢\n","\n","\" áˆ…á‹á‰¡ á‰ á‰µá‹•áŒáˆµá‰µ áŠ¥áŠ•á‹²áŒ á‰¥á‰… áŒ¥áˆªá‹¬áŠ• áŠ á‰€áˆ­á‰£áˆˆáˆ \" á‹«áˆ‰á‰µ áˆ›áŠ”áŒ‚áŠ•áŒ á‹³á‹­áˆ¬áŠ­á‰°áˆ¯ \" áˆ…á‰¥áˆ¨á‰°áˆ°á‰¡ áŠ¨áˆªááˆ­áˆ™ áŒ€áˆ­á‰£ á‰ áˆ˜áˆ°á‰£áˆ°á‰¥ á‰ áŠ áŠ•á‹µáŠá‰µ á‹µáŒ‹á áˆ›á‹µáˆ¨áŒ áŠ áˆˆá‰ á‰µ \" á‰¥áˆˆá‹‹áˆá¢\n","\n","áŒ†áˆ­áŒ‚á‹¬á‰« á¥ áŠ¢áŠ®áŠ–áˆšá‹áŠ• á‹¨á‰ áˆˆáŒ  áŠ áŒ¥áŒ‹á‰¢áŠ“ á‰¥á‰ áˆˆáˆ›á‹µáˆ¨áŒ á‰¥á‹™ á‹¨áˆšáˆ áˆ« áˆ¥áˆ« áŠ áˆˆ \" á‰¥áˆˆá‹ \" áŠ¥á‰£áŠ«á‰½áˆ áˆ˜áŠ•áŒáˆ¥á‰µ áˆ¥áˆ«á‹áŠ• áŠ¥áŠ•á‹²á‹«áŒ áŠ“á‰…á‰… á‹µáŒ‹á áŠ á‹µáˆ­áŒ‰ \" á‹¨áˆšáˆ áŒ¥áˆª áŠ á‰…áˆ­á‰ á‹‹áˆá¢\n","\n","á‹¨á‹‹áŒ‹ áŠ•áˆ¨á‰µáŠ• áˆˆáˆ˜áá‰³á‰µ á‹¨áˆšáˆ°áˆ«á‹ áˆµáˆ« á‹áˆµá‰¥áˆµá‰¥ áˆ˜áˆ†áŠ‘áŠ• á‹«áˆáˆ¸áˆ¸áŒ‰á‰µ á‹³á‹­áˆ¬áŠ­á‰°áˆ« \" á‹¨á‹‹áŒ‹ áŠ•áˆ¨á‰µáŠ• á‹ˆá‹° á‰³á‰½ áˆˆáˆ›á‹áˆ¨á‹µ áŒ áŠ•áŠ«áˆ« á‹¨áŒˆáŠ•á‹˜á‰¥áŠ“ á‹¨áŠáˆµáŠ«áˆ á–áˆŠáˆ²á‹á‰½á£ á‹¨áŠ¢áŠ®áŠ–áˆšá‹áŠ• á‹¨áˆ›áˆáˆ¨á‰µ áŠ á‰…áˆ áˆ›áˆµá‹á‰µá£ á‹¨á‹ˆáŒª áŠ•áŒá‹µáŠ“ á‹¨á‹áŒ­ áˆáŠ•á‹›áˆª áŒˆá‰¢áŠ• áˆ›áˆ³á‹°áŒ áŠ¥áŠ“ á‹¨áŒáˆ‰ áˆ´áŠ­á‰°áˆ­áŠ• áˆ›á‰¥á‰ƒá‰µ á‹­áŒ á‹­á‰ƒáˆ \" á‰¥áˆˆá‹‹áˆá¢\n","\n","áˆŒáˆ‹á‹ á‹«áŠáˆ±á‰µ áŒ‰á‹³á‹­ á‰ G20 á‹¨áŒ‹áˆ« áˆ›á‹•á‰€á áŠ¢á‰µá‹®áŒµá‹« áŠ¥á‹«áŠ«áˆ„á‹°á‰½ á‹«áˆˆá‰½á‹áŠ• á‹¨á‹•á‹³ áˆ˜áˆáˆ¶ áˆ›á‹°áˆ«áŒ€á‰µ á‹µáˆ­á‹µáˆ­ á‰ á‰°áˆ˜áˆˆáŠ¨á‰° áŠá‹á¢\n","\n","áŒ†áˆ­áŒ‚á‹¬á‰« á¤ \" á‹¨á‹•á‹³ áˆ˜áˆáˆ¶ áˆ›á‹‹á‰€áˆ­ áˆ‚á‹°á‰µ á‹¨áˆ˜áŒ¨áˆ¨áˆ» á‹°áˆ¨áŒƒ áˆ‹á‹­ á‹­áŒˆáŠ›áˆ á¤ áŠ¨áŠ¢á‰µá‹®áŒµá‹« áŠ á‰ á‹³áˆªá‹á‰½ áŒ‹áˆ­ á‰£áˆˆáŠ áŒáŠ•áŠ™áŠá‰µ á‹­áˆ… á‰…á‹µáˆšá‹« á‹¨áˆšáˆ°áŒ á‹ áŒ‰á‹³á‹­ áŠá‹ \" áˆ²áˆ‰ áŒˆáˆáŒ¸á‹‹áˆá¢ \n","\n","á‹¨IMF á•áˆ®áŒáˆ«áˆ áŠ áŠ«áˆ áˆ†áŠá‹áŠ• á‹¨á‰³áŠ­áˆµ áŠ¥áˆ­áˆáŒƒá‹á‰½áŠ• á‰ á‰°áˆ˜áˆˆáŠ¨á‰°áˆ á¤ á‹¨áŠ¢á‰µá‹®áŒµá‹« á‰£áˆˆáˆµáˆáŒ£áŠ“á‰µ áˆˆá‰¥áˆ„áˆ«á‹Š á‰ áŒ€á‰± á‹µáŒ‹á áˆˆáˆ›á‹µáˆ¨áŒ á‹ˆáˆ³áŠ á‹¨áˆ†áŠ‘ á‹¨á‰³áŠ­áˆµ áŠ á‰…áˆá‰½áŠ• áˆ˜áˆˆá‹¨á‰³á‰¸á‹áŠ• áŒ á‰áˆ˜á‹‹áˆá¢ \n","\n","áŒ†áˆ­áŒ‚á‹¬á‰« á¥ á‹¨áŠ¢á‰µá‹®áŒµá‹« áŠ áŒ á‰ƒáˆ‹á‹­ á‹¨áˆ€áŒˆáˆ­ á‹áˆµáŒ¥ áˆáˆ­á‰µ á‹•á‹µáŒˆá‰µ áŠ¨IMF á‹¨áˆ˜áŒ€áˆ˜áˆªá‹« á‰µáŠ•á‰ á‹«á‹á‰½ áˆ˜á‰¥áˆˆáŒ¡áŠ• áˆ›á‰¥áˆ«áˆ«á‰³á‰¸á‹áŠ• á‹˜áˆªá–áˆ­á‰°áˆ­ áŠ áˆµáŠá‰¥á‰§áˆá¢\n","\n","á‹¨áˆ›áŠ”áŒ‚áŠ•áŒ á‹³á‹­áˆ¬áŠ­á‰°áˆ« áŠ•áŒáŒáˆ­ á‰°áŠ¨á‰µáˆ \" áˆ˜áˆ¬á‰µ áˆ‹á‹­ áŠ«áˆˆá‹ áŠ¥á‹áŠá‰³ áŒ‹áˆ­ á‹¨áˆšáŒˆáŠ“áŠ áŠ á‹­á‹°áˆˆáˆ \" á‹¨áˆšáˆ‰ áŠ áˆµá‰°á‹«á‹¨á‰¶á‰½ áˆ²áˆ°áŒ¡áˆ á‰°áˆ˜áˆáŠ­á‰°áŠ“áˆá¢\n","\n","@tikvahethiopia\n","---------------------------------------------------------------------------------\n","\n","\n","áˆá‰³áˆµáˆ˜áˆ­á‰€á‹‰ áŠ¨á‰¤á‰°áˆ°á‰¦á‰¿ á‰°á‹°á‰¥á‰ƒ á‹¨áˆ˜áŒ£á‰½ áŠ¥áŒ®áŠ›á‹‰áŠ• áŒ­áŠ«áŠ” á‰ á‰°áˆáˆ‹á‰ á‰µ áˆáŠ”á‰³ á‹¨áŒˆá‹°áˆˆá‹‰ áŒáˆˆáˆ°á‰¥ á‰ 20 á‹“áˆ˜á‰µ áŒ½áŠ‘ áŠ¥áˆµáˆ«á‰µ á‰°á‰€áŒ£á¢\n","\n","á‰ á‹°á‰¡á‰¥ áŠ¢á‰µá‹®áŒµá‹« áŠ­áˆáˆ áŒ‹áˆ á‹áŠ• áŠ áˆ­á‰£áˆáŠ•áŒ­ áŠ¨á‰°áˆ› áŠ áˆµá‰°á‹³á‹°áˆ­ áŒ‰áˆ­á‰£ á‰ áˆšá‰£áˆ á‰€á‰ áˆŒ á‹¨áŒˆá‹› áŠ¥áŒ®áŠ›á‹‰áŠ• áŒ­áŠ«áŠ” á‰ á‰°áˆáˆ‹á‰ á‰µ áˆ˜áˆáŠ© á‰ áŠ áˆ°á‰ƒá‰‚ áˆáŠ”á‰³ á‰ áˆµáˆˆá‰µ áŠ áŠ•áŒˆá‰·áŠ• á‰ áˆ˜á‰áˆ¨áŒ¥ áˆ•á‹­á‹ˆá‰· áŠ¥áŠ•á‹²á‹«áˆá á‹«á‹°áˆ¨áŒˆá‹‰ á‹ˆáŒ£á‰µ á‰ á…áŠ‘ áŠ¥áˆµáˆ«á‰µ áˆ˜á‰€áŒ£á‰±áŠ• á‹¨áŠ áˆ­á‰£ áˆáŠ•áŒ­ áŠ¨á‰°áˆ› áŠ áˆµá‰°á‹³á‹°áˆ­ á–áˆŠáˆµ áˆ˜áˆáˆªá‹« áŠ á‹›á‹¥ áˆ/áŠ¢áŠ•áˆµá”áŠ­á‰°áˆ­ áŒ‹á‹áˆ® á‰¶áˆ›áˆµ áˆˆá‰²áŠ­á‰«áˆ… áŠ¢á‰µá‹®áŒµá‹« á‰°áŠ“áŒáˆ¨á‹‹áˆá¢\n","\n","á‹¨á‹ˆáŠ•áŒ€áˆ á‹µáˆ­áŒŠá‰± á‹¨á‰°áˆá€áˆ˜á‹‰ áŠáˆáˆ´ 16/2016 á‹“/áˆ á‰ áŠ áˆ­á‰£áˆáŠ•áŒ­ áŠ¨á‰°áˆ› áŒ‰áˆ­á‰£ á‰€á‰ áˆŒ áŠá‹á¢\n","\n","á‰°áŠ¨áˆ³áˆ½ á‹®áŠ“áˆµ áŒ«áŠá‰„ á‹¨á‰°á‰£áˆˆá‹ áŒáˆˆáˆ°á‰¥ á‹¨áŒ‚áŠ•áŠ« á‹©áŠ’á‰¨áˆ­áˆ²á‰² 1áŠ›Â  á‹“áˆ˜á‰µ á‰°áˆ›áˆª á‹¨áˆ†áŠá‰½á‹‰áŠ• áˆŸá‰½ áˆŠá‹²á‹« á‹®áˆáŠ•áˆµ áŠ¥áˆ±áŠ• áˆˆáˆ›áˆµáˆ˜áˆ¨á‰… á‹ˆá‹° áŠ áˆ­á‰£ áˆáŠ•áŒ­ áŠ¨á‰°áˆ› á‰ áˆ˜áŒ£á‰½á‰ á‰µ á‰°áŠ¨áˆ«á‹­á‰¶ á‰ áˆšáŠ–áˆ­á‰ á‰µ á‰¤á‰µ áŠ áˆ°á‰ƒá‰‚ á‹µáˆ­áŒŠá‰±áŠ• áˆ˜áˆá€áˆ™áŠ• á‹¨áˆáˆ­áˆ˜áˆ« áˆ˜á‹áŒˆá‰¡ á‹«áˆµáˆ¨á‹³áˆá¢\n","\n","á‹ˆáŒ£á‰· \" áŠ¥áŒ®áŠ›á‹¬ á‹­áˆ˜áˆ¨á‰…áˆáŠ›áˆ \" á‰ áˆšáˆ á‹°áˆµá‰³ áŠ¨á‰¤á‰°áˆ°á‰¦á‰¿ á‰°á‹°á‰¥á‰ƒ á‰°áŠ¨áˆ³áˆ½ á‰°áŠ¨áˆ«á‹­á‰¶ á‹ˆá‹° áˆšáˆ›áˆ­á‰ á‰µÂ  á‰¤á‰µ áˆ˜áŒ¥á‰³ á‰ á‹‹á‹œáˆ›á‹‰ áˆˆáˆáˆ¨á‰ƒá‹‰ á‹¨áˆšáˆ†áŠ‘ á‹¨á‹²áŠ®áˆ­á£ á‹¨á‹³á‰¦áŠ“ áˆˆáˆµáˆ‹áˆ³ áˆ˜áŒ áŒ¦á‰½áŠ“ á‰ á‰¡áŠ“ á‹áŒáŒ…á‰µ á‰¤á‰±áŠ• áŠ áˆ°áˆ›áˆáˆ« á‰ áˆáˆ½á‰±áˆ áŒá‰¢ á‹‰áˆµáŒ¥ á‹«áˆ‰ á‰°áŠ¨áˆ«á‹®á‰½áŠ• áŒ áˆ­á‰°á‹‰ áŠ¨áˆ¸áŠ™ á‰ áŠ‹áˆ‹ áˆŸá‰½ áˆ€áŒˆáˆ­ áˆ°áˆ‹áˆ á‰¥áˆ‹ á‰ á‰°áŠ›á‰½á‰ á‰µ áŠ¨áˆŒáˆŠá‰± 7 áˆ°á‹“á‰µ áŒˆá‹°áˆ› áŠ¥áˆ«áˆ·áŠ• áˆ˜áŠ¨áˆ‹áŠ¨áˆ á‰ áˆ›á‰µá‰½áˆá‰ á‰µ áˆáŠ”á‰³ á‰ á‰¢áˆ‹á‹‹ áŠ áŠ•áŒˆá‰·áŠ• áŠ áˆ­á‹¶ áˆ˜áŒá‹°áˆ‰áŠ• á‹¨áˆáˆ­áˆ˜áˆ« áˆ˜á‹áŒˆá‰¡áŠ• á‹‹á‰¢ áŠ á‹µáˆ­áŒˆá‹ á–áˆŠáˆµ áŠ á‹›á‹¡ áŒˆáˆá€á‹‹áˆá¢\n","\n","á–áˆŠáˆµ áŠ á‹›á‹¡ áŠ áŠ­áˆˆá‹ áŠ¥áŠ•á‹°áŒˆáˆˆáŒ¹á‰µ á¥ á‰ á‹ˆá‰…á‰± á‰ á‰°á‹°áˆ¨áŒˆá‹‰ áˆ›áŒ£áˆ«á‰µáˆ áˆ†áŠ á‰ áŠ­áˆµ áˆ˜á‹áŒˆá‰¡ áˆ‹á‹­ áŠ¥áŠ•á‹°áˆ°áˆáˆ¨á‹‰ á‹ˆáŠ•áŒ€áˆˆáŠ›á‹  \" á‹ˆá‹° á‹©áŠ’á‰¨áˆ­áˆ²á‰² á‰ áˆ„á‹µáˆ½á‰ á‰µ áˆŒáˆ‹ á‹¨á‹ˆáŠ•á‹µ áŒ“á‹°áŠ› á‹­á‹˜áˆ»áˆ \" á‰ áˆšáˆ áŠá‹ á‰ áˆ­ á‹˜áŒá‰¶ áŠ áˆ°á‰ƒá‰‚ á‹¨á‹ˆáŠ•áŒ€áˆ á‹µáˆ­áŒŠá‰±áŠ• á‹¨áˆáŒ¸áˆ˜á‹á¢\n","\n","á–áˆŠáˆµ á‰ á‹šáˆ… á‹˜áŒáŠ“áŠ á‹ˆáŠ•áŒ€áˆ á‹™áˆªá‹« á‰°áŒˆá‰¢á‹‰áŠ• áˆ›áŒ£áˆ«á‰µáŠ“ áˆáˆ­áˆ˜áˆ« áŠ á‹µáˆ­áŒ áˆˆá‹á‰ƒá‰¤ áˆ•áŒ áˆ›á‰…áˆ¨á‰¡áŠ• áŠ áˆµá‰³á‹á‰€á‹‹áˆá¢\n","\n","á‹á‰ƒá‰¤ áˆ•áŒáˆ áŠ­áˆµ á‰ áˆ˜áˆ˜áˆµáˆ¨á‰µ áˆˆááˆ­á‹µ á‰¤á‰± á‰°áŠ¨áˆ³áˆ½ á‹¨á‹ˆáŠ•áŒ€áˆ á‹µáˆ­áŒŠá‰±áŠ• áˆ˜áˆá€áˆ™áŠ• á‹¨áˆ°á‹‰á£ á‹¨áˆ°áŠá‹µáŠ“ á‹¨áˆ…áŠ­áˆáŠ“ áˆ›áˆµáˆ¨áŒƒá‹á‰½áŠ• á‰ áˆ›á‰…áˆ¨á‰¥ áŠ áˆµáˆ¨á‹µá‰·áˆá¢\n","\n","á‰ á‰€áˆ¨á‰¡ áˆ›áˆµáˆ¨áŒƒá‹á‰½ áŠ¥áŠ“ áˆáˆµáŠ­áˆ®á‰½ áŒáˆ« á‰€áŠ™áŠ• áˆ²á‹«áŒ£áˆ« á‹¨á‰†á‹¨á‹‰ á‹¨áŒ‹áˆ á‹áŠ• áŠ¨áá‰°áŠ›á‹‰ ááˆ­á‹µ á‰¤á‰µ á‰ á‰€áŠ• 29/5/2017 á‹“áˆ á‰ á‹‹áˆˆá‹‰ á‰½áˆá‰µ á‰°áŠ¨áˆ³áˆ½ á‹®áŠ“áˆµ áŒ¨áŠá‰„ á‰ á‰°áŠ¨áˆ°áˆ°á‰ á‰µ á‰ áŠ áˆ°á‰ƒá‰‚ áˆáŠ”á‰³ áŠá‰¥áˆµ á‹¨áˆ›áŒ¥á‹á‰µ á‹ˆáŠ•áŒ€áˆ áŒ¥á‹á‰°áŠ› áˆ˜áˆ†áŠ‘áŠ• á‰ áˆ›áˆ¨áŒ‹áŒˆáŒ¥ á‰ 20 á‹“áˆ˜á‰µ á…áŠ‘ áŠ¥áˆµáˆ«á‰µ áŠ¥áŠ•á‹²á‰€áŒ£ áˆ˜á‹ˆáˆ°áŠ‘áŠ•áˆ áŠ¢áŠ•áˆµá”áŠ­á‰°áˆ­ áŒ‹á‹áˆ® á‰¶áˆ›áˆµ áˆˆá‰²áŠ­á‰«áˆ… áŠ¢á‰µá‹®áŒµá‹« á‰°áŠ“áŒáˆ¨á‹‹áˆá¢\n","\n","#TikvahEthiopiaFamilyHW\n","\n","@tikvahethiopia\n","---------------------------------------------------------------------------------\n","\n","\n","#áˆ˜á‰„á‹¶áŠ•á‹«\n","\n","\" áˆ°á‹áŠ• áˆˆáˆ˜áˆ­á‹³á‰µ áˆ°á‹ áˆ˜áˆ†áŠ• á‰ á‰‚ áŠá‹ !! \"\n","\n","áˆ˜á‰„á‹¶áŠ•á‹« á‹¨áŠ áˆ¨áŒ‹á‹Šá‹«áŠ•áŠ“ á‹¨áŠ áŠ¥áˆáˆ® áˆ…áˆ™áˆ›áŠ• áˆ˜áˆ­áŒƒ áˆ›á‹•áŠ¨áˆ á‰ áˆšá‹«áˆµáŒˆáŠá‰£á‹ áˆ†áˆµá’á‰³áˆ áŒ­áˆáˆ­ á‹«áˆˆá‹ áˆ…áŠ•áƒ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹¨áŒˆáŠ•á‹˜á‰¥ áŠ¥áŒ¥áˆ¨á‰µ áˆµáˆˆáŒˆáŒ áˆ˜á‹ áŠ¥áŒá‹› áŠ¥áŠ•á‹²á‹°áˆ¨áŒ áˆˆáˆ˜áˆ‹á‹ áŠ¢á‰µá‹®áŒµá‹«á‹á‹«áŠ• áŒ¥áˆª áˆ˜á‰…áˆ¨á‰¡ á‹­á‰³á‹ˆáˆ³áˆá¢\n","\n","á‹›áˆ¬ â€œ á‰ áˆ°á‹­á‰ áŠ¢á‰¢áŠ¤áˆµ á‹¨á‹©á‰±á‰¥ á‰»áŠáˆ â€ á‹µáŒ‹á áˆ›á‹µáˆ¨áŒŠá‹« áˆ˜áˆ­áˆ€ áŒá‰¥áˆ­ áŠ¥á‹¨á‰°áŠ«áˆ„á‹° áŠá‹á¢\n","\n","á‹°áŒ‹áŒá‰½ áˆáˆ‰ á‹µáŒ‹á áŠ¥áŠ•á‹µá‰³á‹°áˆ­áŒ‰ áŒ¥áˆª áŠ¥áŠ“á‰€áˆ­á‰£áˆˆáŠ•á¢\n","\n","á‹¨á‹µáŒ‹á áˆ›á‹µáˆ¨áŒŠá‹« áŠ áˆ›áˆ«áŒ®á‰½ áŠ¨áˆ‹á‹­ á‰°á‹«á‹­á‹˜á‹‹áˆá¢\n","\n","áˆ˜á‰„á‹¶áŠ•á‹« â€œ áˆ…áŠ•áƒá‹ áˆˆáˆ›áŒ áŠ“á‰€á‰… áŒˆáŠ•á‹˜á‰¥ á‰°á‰¸áŒáˆ¨áŠ“áˆá¢ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹ˆá‹° 5 á‰¢áˆŠá‹®áŠ• á‰¥áˆ­ á‹«áˆµáˆáˆáŒˆáŠ“áˆ â€ áˆ›áˆˆá‰± áŠ á‹­á‹˜áŠáŒ‹áˆá¢\n","\n","á‰ á‰€áŒ¥á‰³ á‹­áŠ¨á‰³á‰°áˆ‰ ğŸ‘‡\n","https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n","\n","@tikvahethiopia\n","---------------------------------------------------------------------------------\n","\n","\n"]}],"source":["data=load_data(\"/content/drive/MyDrive/Transformer_classifier_app_1/datas/totaldata.json\")\n","number_of_contents=len(data)\n","print(f'Total number of contents: {number_of_contents}\\n')\n","print(f'First 5 contents: \\n')\n","for news in data[:5]:\n","    print(news)\n","    print(\"---------------------------------------------------------------------------------\\n\\n\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"q-ekrRqs7acJ"},"source":["Let's clean our data using clean_text function and sample our data to see the difference between the original and cleaned data"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":64970,"status":"ok","timestamp":1740035016497,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"WVUUntEo7acJ"},"outputs":[],"source":["cleaned_data=[clean_text(content) for content in data]"]},{"cell_type":"markdown","metadata":{"id":"GuFzJ-8N7acJ"},"source":["Let's see the total number of words and total number of unique words in our training data."]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5936,"status":"ok","timestamp":1740035022445,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"7rQK9VQO7acJ","outputId":"87e7e56a-502f-4d5e-ef91-8749071434a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of words in the dataset: 15290227\n","\n","Total number of unique words in the dataset: 832978\n","\n"]}],"source":["total=0\n","for news in cleaned_data:\n","    news_array=news.split()\n","    total+=len(news_array)\n","print(f'Total number of words in the dataset: {total}\\n')\n","alldata=\" \".join(cleaned_data)\n","counter=Counter(alldata.split())\n","print(f'Total number of unique words in the dataset: {len(counter)}\\n')\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1740035022450,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"DFvJoICG7acJ","outputId":"751f6870-5cc9-441a-e899-2b500d9c0fd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data at index 37430 before cleaning: \n","\n"," updateâ¬†ï¸á‹¨á‰´á’ áŠ¨á‰°áˆ› á‹¨á‹›áˆ¬ áŒ¥á‹‹á‰µ á‹µá‰£á‰¥ áŠ¥áŠ“ áŠ áŒ á‰ƒáˆ‹á‹­ á‹¨áŠ¨á‰°áˆ›á‹‹ áˆáŠ”á‰³ áŠ¨áŠ¨á‰°áˆ›á‹ áŠá‹‹áˆª áŠ áˆá‹°á‰ á‰µá¢\n","@tseabwolde @tikvahethiopia\n","\n","---------------------------------------------------------------------------------\n","\n","\n","Data at index 37430 after cleaning: \n","\n"," á‹¨á‰´á’ áŠ¨á‰°áˆ› á‹¨á‹›áˆ¬ áŒ¥á‹‹á‰µ á‹µá‰£á‰¥ áŠ¥áŠ“ áŠ áŒ á‰ƒáˆ‹á‹­ á‹¨áŠ¨á‰°áˆ›á‹‹ áˆáŠ”á‰³ áŠ¨áŠ¨á‰°áˆ›á‹ áŠá‹‹áˆª áŠ áˆá‹°á‰ á‰µá¢\n"]}],"source":["index=37430\n","print(f\"Data at index {index} before cleaning: \\n\\n\",data[index])\n","print(\"\\n---------------------------------------------------------------------------------\\n\\n\")\n","print(f\"Data at index {index} after cleaning: \\n\\n\",cleaned_data[index])"]},{"cell_type":"markdown","metadata":{"id":"JZ2NhlaK7acJ"},"source":["### 3.3 Tokenization"]},{"cell_type":"markdown","metadata":{"id":"1hCYk0Ai7acJ"},"source":["#### Next, We Will Train the Tokenizer\n","\n","Tokenization is a critical step in natural language processing (NLP) as it converts raw text into smaller, meaningful units (tokens) that can be processed by machine learning models. Effective tokenization ensures that the model can understand and interpret the text accurately, which is essential for tasks like text classification, machine translation, and sentiment analysis.\n","\n","For this task, we will use the **SentencePiece tokenizer** instead of traditional word-based tokenization. The [SentencePieceTokenizer](https://www.tensorflow.org/text/api_docs/python/text/SentencepieceTokenizer) is a powerful tool that tokenizes text into **subword units**, which offers several advantages:\n","\n","1. **Handling Complex Word Structures**: SentencePiece breaks words into smaller subword units, making it effective for handling complex word structures and morphological variations, which are common in languages like Amharic.\n","2. **Out-of-Vocabulary (OOV) Words**: By using subword tokenization, SentencePiece can handle out-of-vocabulary words more gracefully, as it can decompose them into known subword units.\n","3. **Multilingual Support**: SentencePiece is language-agnostic, making it suitable for multilingual datasets. This is particularly useful for Amharic, as it can handle the repetition of common subwords and morphological patterns unique to the language.\n","4. **Simplified Preprocessing**: SentencePiece works directly on raw text, eliminating the need for extensive preprocessing steps like word segmentation or stemming.\n","5. **Seamless Integration**: It integrates seamlessly with popular machine learning frameworks like TensorFlow and PyTorch, ensuring consistent tokenization across training and inference pipelines.\n","\n","Given these benefits, SentencePiece is an ideal choice for tokenizing Amharic text, as it can effectively capture the language's unique characteristics while simplifying the overall preprocessing workflow."]},{"cell_type":"markdown","metadata":{"id":"UvDyWgWT7acK"},"source":["Let's train sentencepiece tokenizer model first. in order to do that we need to save our cleaned data into a single corpus of text in .txt file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAdrNZ-j7acK"},"outputs":[],"source":["#with open(\"datas/cleaned_data.txt\", \"a\") as file:\n","  #  for content in cleaned_data:\n","   #     file.write(content + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gQ3i7Ra7acK","outputId":"0f121046-23e3-48a7-bce4-e41477674e3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training SentencePiece model...\n","Training complete! Check 'amharic_bpe.model' and 'amharic_bpe.vocab'.\n"]},{"name":"stderr","output_type":"stream","text":["sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: datas/cleaned_data.txt\n","  input_format: \n","  model_prefix: amharic_sp_model\n","  model_type: UNIGRAM\n","  vocab_size: 100000\n","  self_test_sample_size: 0\n","  character_coverage: 0.995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 8192\n","  num_threads: 6\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 0\n","  pretokenization_delimiter: \n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  seed_sentencepieces_file: \n","  hard_vocab_limit: 1\n","  use_all_vocab: 0\n","  unk_id: 1\n","  bos_id: 2\n","  eos_id: 3\n","  pad_id: 0\n","  unk_piece: <unk>\n","  bos_piece: <s>\n","  eos_piece: </s>\n","  pad_piece: <pad>\n","  unk_surface:  â‡ \n","  enable_differential_privacy: 0\n","  differential_privacy_noise_level: 0\n","  differential_privacy_clipping_threshold: 0\n","}\n","normalizer_spec {\n","  name: nmt_nfkc\n","  add_dummy_prefix: 1\n","  remove_extra_whitespaces: 1\n","  escape_whitespaces: 1\n","  normalization_rule_tsv: \n","}\n","denormalizer_spec {}\n","trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n","trainer_interface.cc(185) LOG(INFO) Loading corpus: datas/cleaned_data.txt\n","trainer_interface.cc(380) LOG(WARNING) Found too long line (9644 > 8192).\n","trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n","trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n","trainer_interface.cc(391) LOG(INFO) Reserved chars are found. Skipped: â•¯â–…â•°â•±â–”â–”â–”â–”â–”â–”â–”â•²â•¯â˜¼ â–•â–•â•±â•±â•±â•±â•±â•±â•±â•±â”›â–‚â•²â•² â•±â–‚â–‚â–‚â–‚â–‚â–‚â•±â•±â”â–•â•‹â–â•²â•² â–”â–â–‚â”—â”“â–‚â–•â–”â”›â–‚â”â–”â–‚â–•â–” â–•â–•â•‹â–â–•â•‹â–â–â–•â”â–â–•â•‹â–| áŠ¥áŠ› á‹¨áˆ™á‹µ áŠ¥áŠ•ï¿½ï¿½ï¿½á‹ á‰¤á‰°áˆ°á‰¦á‰½ á‰µáŠ«á‹œ á‹µáŠ•á‹›á‹œ á‹á‹›á‹œ áŠ‘á‹›á‹œ á‹‰áˆµáŒ£á‰½áŠ• áŠ á‹°áˆˆáˆ áˆá‰³ áˆá‰€áŠ› áŠ¥áŠ•á‹²á‰ƒáŒ áˆ\n","trainer_interface.cc(409) LOG(INFO) Loaded all 191827 sentences\n","trainer_interface.cc(416) LOG(INFO) Skipped 553 too long sentences.\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n","trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n","trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n","trainer_interface.cc(539) LOG(INFO) all chars count=75721594\n","trainer_interface.cc(550) LOG(INFO) Done: 99.5055% characters are covered.\n","trainer_interface.cc(560) LOG(INFO) Alphabet size=222\n","trainer_interface.cc(561) LOG(INFO) Final character coverage=0.995055\n","trainer_interface.cc(592) LOG(INFO) Done! preprocessed 191827 sentences.\n","unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n","unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=37769524\n","unigram_model_trainer.cc(312) LOG(INFO) Initialized 768596 seed sentencepieces\n","trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 191827\n","trainer_interface.cc(609) LOG(INFO) Done! 784912\n","unigram_model_trainer.cc(602) LOG(INFO) Using 784912 sentences for EM training\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=355352 obj=13.161 num_tokens=1612991 num_tokens/piece=4.53914\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=303986 obj=11.552 num_tokens=1618339 num_tokens/piece=5.32373\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=227957 obj=11.5203 num_tokens=1690775 num_tokens/piece=7.41708\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=227779 obj=11.5045 num_tokens=1695108 num_tokens/piece=7.4419\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=170832 obj=11.5413 num_tokens=1794991 num_tokens/piece=10.5073\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=170822 obj=11.5417 num_tokens=1795487 num_tokens/piece=10.5109\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=128116 obj=11.5906 num_tokens=1899315 num_tokens/piece=14.825\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=128116 obj=11.5718 num_tokens=1899287 num_tokens/piece=14.8247\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=110000 obj=11.6223 num_tokens=1952244 num_tokens/piece=17.7477\n","unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=110000 obj=11.6115 num_tokens=1952426 num_tokens/piece=17.7493\n","trainer_interface.cc(687) LOG(INFO) Saving model: amharic_sp_model.model\n","trainer_interface.cc(699) LOG(INFO) Saving vocabs: amharic_sp_model.vocab\n"]}],"source":["input_file=\"datas/cleaned_data.txt\"\n","model_prefix=\"amharic_sp_model\"\n","print(\"Training SentencePiece model...\")\n","\n","spm.SentencePieceTrainer.train(\n","    input=input_file,\n","    model_prefix=model_prefix,\n","    vocab_size=100000,\n","    model_type=\"unigram\",\n","    character_coverage=0.995,\n","    num_threads=6,\n","    max_sentence_length=8192,\n","    split_by_whitespace=True,\n","    pad_id=0,\n","    unk_id=1,\n","    bos_id=2,\n","    eos_id=3,\n","\n",")\n","print(\"Training complete! Check 'amharic_bpe.model' and 'amharic_bpe.vocab'.\")"]},{"cell_type":"markdown","metadata":{"id":"US2YzBdJ7acK"},"source":["After training the sentencepeice tokenizer the next step is to load the trainied tokenizer model"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":73,"status":"ok","timestamp":1740035022845,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"KO51vLus7acK"},"outputs":[],"source":["tokenizer=spm.SentencePieceProcessor(model_file=\"/content/drive/MyDrive/Transformer_classifier_app_1/amharic_sp_model.model\")"]},{"cell_type":"markdown","metadata":{"id":"dwRBjcNL7acK"},"source":["This code shows the process of tokenizing individual words from a given text, in this case, the first entry of the dataset."]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1740035022857,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"VpHqcmpm7acK","outputId":"3cd79999-6221-4baa-d001-82849214ef44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word\t\t-->\tTokenization\n","----------------------------------------\n","á‰ áŠ áˆ›áˆ«    \t-->\t[503]\n","áŠ­áˆáˆ     \t-->\t[41]\n","áˆ˜á‹²áŠ“     \t-->\t[2571]\n","á‰ á‰£áˆ…áˆ­    \t-->\t[3954]\n","á‹³áˆ­      \t-->\t[577]\n","áŠ¨á‰°áˆ›     \t-->\t[25]\n","á‰€á‰ áˆŒ     \t-->\t[556]\n","14      \t-->\t[589]\n","á‰µáˆ‹áŠ•á‰µ    \t-->\t[414]\n","áˆ˜áŒ‹á‰¢á‰µ    \t-->\t[915]\n","29      \t-->\t[1161]\n","á‹¨áˆ˜áŒáˆªá‰¥   \t-->\t[40582, 39560]\n","áˆ°áˆ‹á‰µ     \t-->\t[22531]\n","áˆ°áŒá‹°á‹    \t-->\t[80378]\n","áˆ²áˆ˜áˆˆáˆ±    \t-->\t[5520]\n","á‹¨áŠá‰ áˆ©    \t-->\t[296]\n","áŠ á‰£á‰µ     \t-->\t[1033]\n","áŠ¨3      \t-->\t[12, 391]\n","áˆáŒ†á‰¹     \t-->\t[8106]\n","áŠ¥áŠ•á‹²áˆáˆ   \t-->\t[56]\n","áŠ áŠ•á‹µ     \t-->\t[60]\n","áŒáˆ¨á‰¤á‰³á‰¸á‹áŠ• \t-->\t[63799, 5]\n","áŒ¨áˆáˆ®     \t-->\t[166]\n","áŠ áŒ á‰ƒáˆ‹á‹­   \t-->\t[462]\n","5       \t-->\t[189]\n","áˆ°á‹á‰½     \t-->\t[27]\n","á‰ á‰°áŠ¨áˆá‰°á‰£á‰¸á‹\t-->\t[6, 31096]\n","á‹¨áŒ¥á‹­á‰µ    \t-->\t[9820]\n","áŠ¥áˆ©áˆá‰³    \t-->\t[22829]\n","áˆ˜áŒˆá‹°áˆ‹á‰¸á‹  \t-->\t[4926]\n","á‰°áŠáŒáˆ¯áˆá¢  \t-->\t[528]\n","á‰µáˆ‹áŠ•á‰µáŠ“   \t-->\t[9146]\n","áˆáˆ½á‰µ     \t-->\t[368]\n","á‰ áŒá     \t-->\t[7180]\n","á‹¨á‰°áŒˆá‹°áˆ‰á‰µ  \t-->\t[6444]\n","á¥       \t-->\t[4, 1]\n","áŠ á‰¶      \t-->\t[44]\n","áˆ™áˆ„      \t-->\t[51148]\n","á£       \t-->\t[33]\n","áˆáŒƒá‰¸á‹    \t-->\t[4786]\n","áŠ á‰ á‰£á‹‰    \t-->\t[43, 124]\n","áˆ™áˆ„      \t-->\t[51148]\n","á£       \t-->\t[33]\n","áˆ½áŠ©áˆ­     \t-->\t[24929]\n","áˆ™áˆ„      \t-->\t[51148]\n","á£       \t-->\t[33]\n","áˆ™áˆ‹á‰µ     \t-->\t[9158]\n","áˆ™áˆ„      \t-->\t[51148]\n","áŠ¥áŠ“      \t-->\t[7]\n","áŒáˆ¨á‰¤á‰³á‰¸á‹  \t-->\t[63799]\n","áŠ á‰¶      \t-->\t[44]\n","áŠ¥áŠ•á‹µáˆªáˆµ   \t-->\t[17857]\n","á‹¨á‰°á‰£áˆ‰    \t-->\t[1376]\n","áˆ²áˆ†áŠ‘     \t-->\t[947]\n","áˆµáˆ­á‹“á‰µ    \t-->\t[769]\n","á‰€á‰¥áˆ«á‰¸á‹   \t-->\t[13051]\n","á‰ á‹›áˆ¬á‹    \t-->\t[259]\n","á‹•áˆˆá‰µ     \t-->\t[207]\n","á‰°áˆá…áˆŸáˆá¢  \t-->\t[9115]\n","áŠ¥áˆµáŠ«áˆáŠ•   \t-->\t[307]\n","áŒˆá‹³á‹®á‰½    \t-->\t[19551]\n","áˆµáˆˆáˆ˜á‹«á‹›á‰¸á‹ \t-->\t[45001]\n","á‹¨á‰°á‰£áˆˆ    \t-->\t[801]\n","áŠáŒˆáˆ­     \t-->\t[67]\n","á‹¨áˆˆáˆá¢    \t-->\t[984]\n","á‰ áŠ¨á‰°áˆ›á‹‹   \t-->\t[1197]\n","áŠ¨á‰°áŒˆá‹°áˆ‰á‰µ  \t-->\t[10342]\n","áˆ°á‹á‰½     \t-->\t[27]\n","á‰£áˆ»áŒˆáˆ­    \t-->\t[2231]\n","á‰£áˆ…áˆ­á‹³áˆ­   \t-->\t[2982]\n","áŠ¨á‰°áˆ›     \t-->\t[25]\n","áŠ á‰£á‹­     \t-->\t[4770]\n","áˆ›á‹¶      \t-->\t[8609]\n","á‹¨áˆšáŒˆáŠ˜á‹   \t-->\t[506]\n","áˆ˜áˆµáŒ‚á‹µ    \t-->\t[8041]\n","áŠ¨áá‰°áŠ›    \t-->\t[53]\n","á‹¨áˆ˜áˆ³áˆªá‹«   \t-->\t[14257]\n","á‹µá‰¥á‹°á‰£    \t-->\t[2667]\n","áŠ¥áŠ•á‹°á‰°áˆá€áˆ˜á‰ á‰µ\t-->\t[33102]\n","á‰°áŒˆáˆáŒ¿áˆá¢  \t-->\t[141]\n","áŠ¨á‹šáˆ     \t-->\t[5286]\n","áŒ‹áˆ­      \t-->\t[17]\n","á‰ á‰°á‹«á‹«á‹˜   \t-->\t[526]\n","á‹›áˆ¬      \t-->\t[57]\n","á‹¨á‰£áˆ…áˆ­    \t-->\t[1839]\n","á‹³áˆ­      \t-->\t[577]\n","áˆ™áˆµáˆŠáˆá‰½   \t-->\t[8870]\n","á‰ áŠ­áˆáˆ‰    \t-->\t[491]\n","á‰ áˆ™áˆµáˆŠáˆá‰½  \t-->\t[63342]\n","áˆ‹á‹­      \t-->\t[10]\n","áŠ áŠáŒ£áŒ¥áˆ¨á‹‹áˆ \t-->\t[94902, 20007]\n","á‹«áˆ‰á‰µáŠ•    \t-->\t[2078]\n","áŒá‹µá‹«     \t-->\t[1090]\n","áŠ¥áŠ“      \t-->\t[7]\n","áŠ¥áŒˆá‰³     \t-->\t[5724]\n","á‰ áˆ˜á‰ƒá‹ˆáˆ   \t-->\t[3574]\n","áˆ°áˆá     \t-->\t[822]\n","áˆ›á‹µáˆ¨áŒ‹á‰¸á‹áŠ• \t-->\t[2988]\n","\"       \t-->\t[14]\n","áˆ€áˆ©áŠ•     \t-->\t[33660]\n","áˆšá‹²á‹«     \t-->\t[549]\n","\"       \t-->\t[14]\n","á‹˜áŒá‰§áˆá¢   \t-->\t[427]\n","áŠ¥áˆµáŠ«áˆáŠ•   \t-->\t[307]\n","á‰ áŠ áˆ›áˆ«    \t-->\t[503]\n","áŠ­áˆáˆ     \t-->\t[41]\n","áŠ¥áˆµáˆáˆáŠ“   \t-->\t[3278]\n","áŒ‰á‹³á‹®á‰½    \t-->\t[231]\n","áŠ¨áá‰°áŠ›    \t-->\t[53]\n","áˆáŠ­áˆ­     \t-->\t[170]\n","á‰¤á‰µáˆ     \t-->\t[28, 8]\n","áˆ†áŠ      \t-->\t[289]\n","á‰ áŠ¢á‰µá‹®áŒµá‹«  \t-->\t[126]\n","áŠ¥áˆµáˆáˆáŠ“   \t-->\t[3278]\n","áŒ‰á‹³á‹®á‰½    \t-->\t[231]\n","áŒ á‰…áˆ‹á‹­    \t-->\t[158]\n","áˆáŠ­áˆ­     \t-->\t[170]\n","á‰¤á‰µ      \t-->\t[28]\n","á‹¨á‰°áˆ°áŒ     \t-->\t[2476]\n","áŠ áˆµá‰°á‹«á‹¨á‰µ  \t-->\t[620]\n","á‹¨áˆˆáˆá¢    \t-->\t[984]\n","á‰²áŠ­á‰«áˆ…    \t-->\t[1134]\n","áŠ¢á‰µá‹®áŒµá‹«   \t-->\t[54]\n","á‰ áŠ­áˆáˆ‰    \t-->\t[491]\n","á‰°áˆá…áˆ˜á‹‹áˆ  \t-->\t[32369]\n","áˆµáˆˆá‰°á‰£áˆ‰   \t-->\t[62519]\n","áŒá‹µá‹«á‹á‰½   \t-->\t[9726]\n","á£       \t-->\t[33]\n","áŒ¥á‰ƒá‰¶á‰½    \t-->\t[2225]\n","á£       \t-->\t[33]\n","á‹˜áˆ¨á‹áŠ“    \t-->\t[27038]\n","áŠ¥áŒˆá‰³á‹á‰½   \t-->\t[46541]\n","á‹¨áŠ áˆ›áˆ«    \t-->\t[409]\n","áŠ­áˆáˆ     \t-->\t[41]\n","áŠ¥áˆµáˆáˆáŠ“   \t-->\t[3278]\n","áŒ‰á‹³á‹®á‰½    \t-->\t[231]\n","áŠ¨áá‰°áŠ›    \t-->\t[53]\n","áˆáŠ­áˆ­     \t-->\t[170]\n","á‰¤á‰µ      \t-->\t[28]\n","áŠ¥áŠ“      \t-->\t[7]\n","á‹¨áˆšáˆ˜áˆˆáŠ¨á‰³á‰¸á‹\t-->\t[2664]\n","áŠ áŠ«áˆ‹á‰µáŠ•   \t-->\t[2983]\n","áˆˆáˆ›áŠáŒ‹áŒˆáˆ­  \t-->\t[12139]\n","áŒ¥áˆ¨á‰µ     \t-->\t[377]\n","áŠ¥á‹«á‹°áˆ¨áŒˆ   \t-->\t[998]\n","á‹­áŒˆáŠ›áˆá¤   \t-->\t[23033]\n","áˆáˆ‹áˆ½     \t-->\t[305]\n","áŠ¥áŠ•á‹³áŒˆáŠ˜   \t-->\t[14546]\n","á‰°áŒ¨áˆ›áˆª    \t-->\t[224]\n","áˆ˜áˆ¨áŒƒá‹á‰½áŠ•  \t-->\t[1140]\n","á‹«á‰€áˆ­á‰£áˆá¢  \t-->\t[10129]\n"]}],"source":["# printing the encoding of each word to see how subwords are tokenized\n","tokenized_text = [(list(tokenizer.tokenize(word)), word) for word in cleaned_data[3000].split()]\n","\n","print(\"Word\\t\\t-->\\tTokenization\")\n","print(\"-\"*40)\n","for element in tokenized_text:\n","    print(f\"{element[1]:<8}\\t-->\\t{element[0]}\")\n"]},{"cell_type":"markdown","metadata":{"id":"MKNYYvYw7acK"},"source":["Now let's take data from the cleaned_data  and see how the tokenization of the whole content looks like"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1740035022912,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"RvOTQIfu7acK","outputId":"19baab00-b48c-4809-e6f5-48d01fe8f428"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data at index 890 before tokenization: \" áˆ°áˆ‹áˆ áŠ¨áŠ áŠ•áŒˆá‰µ á‰ áˆ‹á‹­áŠ“ á‹áˆ áˆ‹áˆˆáˆ›áˆˆá‰µ á‹«áˆ…áˆ á‹¨áˆáŠ•áŠ“áŒˆáˆ¨á‹ áˆ³á‹­áˆ†áŠ• á‹‹áŒ‹ áŠ¨ááˆˆáŠ• á‹¨áˆáŠ“áˆ˜áŒ£á‹ áŠá‹ \" - á‰…á‹±áˆµáŠá‰³á‰¸á‹ á‹›áˆ¬ á‹¨áˆ°áˆ‹áˆ áˆšáŠ’áˆµá‰´áˆ­ áŠ áŠ•á‹µ á‹“áˆˆáˆ áŠ á‰€á áŠ®áŠ•áˆáˆ¨áŠ•áˆµ áŠ á‹˜áŒ‹áŒ…á‰¶ áŠá‰ áˆ­á¢ á‰ á‹šáˆ… áˆ˜á‹µáˆ¨áŠ­ áˆ‹á‹­áˆ á‹¨áˆ°áˆ‹áˆ áˆšáŠ’áˆµá‰µáˆ­ áŠ á‰¶ á‰¥áŠ“áˆá áŠ á‹±á‹“áˆˆáˆ á£ á‹¨áŠ¢á‰µá‹®áŒµá‹« á‹¨áˆƒá‹­áˆ›áŠ–á‰µ á‰°á‰‹áˆ›á‰µ á‹¨á‰ áˆ‹á‹­ áŒ á‰£á‰‚ áŠ á‰£á‰¶á‰½á£ á‰¥áá‹“áŠ• áŠ á‰ á‹ áˆŠá‰ƒáŠ áŒ³áŒ³áˆ³á‰µ á‹ˆáŠ¤áŒ²áˆµ á‰†áŒ¶áˆ³á‰µ á£ á‹¨áˆ˜áŠ•áŒáˆ¥á‰µ á‰£áˆˆáˆµáˆáŒ£áŠ“á‰µ á£ áŠ á‰£áˆ³á‹°áˆ®á‰½ áŒ­áˆáˆ­ á‰°áŒˆáŠá‰°á‹ áŠá‰ áˆ­á¢ á‰ áˆ˜á‹µáˆ¨áŠ© á¤ á‰¥áá‹• á‹ˆá‰…á‹±áˆµ áŠ á‰¡áŠ áˆ›á‰µá‹«áˆµ á‰€á‹³áˆ›á‹Š á“á‰µáˆ­á‹«áˆ­áŠ­ áˆ­áŠ¥áˆ° áˆŠá‰ƒáŠ áŒ³áŒ³áˆ³á‰µ á‹˜áŠ¢á‰µá‹®áŒµá‹« áˆŠá‰€ áŒ³áŒ³áˆµ á‹˜áŠ áŠ­áˆ±áˆ á‹ˆáŠ¥áŒ¨áŒŒ á‹˜áˆ˜áŠ•á‰ áˆ¨ á‰°áŠ­áˆˆáˆƒá‹­áˆ›áŠ–á‰µ áˆ˜áˆá‹•áŠ­á‰µ áŠ áˆµá‰°áˆ‹áˆáˆá‹‹áˆá¢ á‰…á‹±áˆµáŠá‰³á‰¸á‹ áˆáŠ• áŠ áˆ‰ ? (áŠ¨áˆ˜áˆá‹•áŠ­á‰³á‰¸á‹ á‹¨á‰°á‹ˆáˆ°á‹°) \" áˆ°áˆ‹áˆ á‹¨áˆ°á‹ áˆáŒ†á‰½ ááˆ‹áŒá‰µá£ á‹¨á‰¥á‹™ áˆáŠ•á‹±á‰£áŠ• á‹¨á‹¨á‹•áˆˆá‰µ áŠ“áá‰†á‰µ áŠá‹á¢ á‹¨á‰ áˆ­áŠ«á‰³ á‹˜áˆ˜áŠ“á‰µ á‰…áˆ­áˆ¶á‰½á¤ áŒŠá‹œá£ áŒˆáŠ•á‹˜á‰¥ áŠ¥áŠ“ á‹¨áˆ°á‹ áŒ‰áˆá‰ á‰µ á‹¨áˆáˆ°áˆ°á‰£á‰¸á‹ áŒáŠ•á‰£á‰³á‹á‰½ á‰ áˆ°áˆ‹áˆ áˆ›áŒ£á‰µ á‰ á‰…áŒ½á‰ á‰µ á‹­áˆáˆ­áˆ³áˆ‰á¢ áˆ°áˆ‹áˆ áŠ«áˆˆ á‹¨á‹“áˆˆáˆ áˆ€á‰¥á‰µ áˆˆáˆáˆ‰áˆ á‰ á‰‚ áŠá‹á¢ áˆ°áˆ‹áˆ áˆ›áŒ£á‰µ áŒáŠ• á‰¥á‹™ áˆ áˆ«á‹Šá‰µá£ á‰¥á‹™ á‹¨áŒ¦áˆ­ áˆ˜áˆ³áˆªá‹« áŠ¥áŠ•á‹²á‹˜áŒ‹áŒ… áŠ¥á‹«á‹°áˆ¨áŒˆ áˆ€á‰¥á‰µáŠ• á‹«á‹ˆá‹µáˆ›áˆá¢ áŒ¦áˆ­áŠá‰µ áˆ›áˆˆá‰µ áˆ€á‰¥á‰µáŠ“ áˆ•á‹­á‹ˆá‰µáŠ• á‹ˆá‹°áˆšáŠá‹µ áŠ¥áˆ³á‰µ á‹áˆµáŒ¥ áˆ˜áŒ£áˆ áŠá‹á¢ á‹¨áŠ áŠ•á‹°áŠ›áŠ“ á‹¨áˆáˆˆá‰°áŠ› á‹“áˆˆáˆ áŒ¦áˆ­áŠá‰µá£ á‰³áˆªáŠ­ á‰¥á‰» áˆ³á‹­áˆ†áŠ• áŒ á‰£áˆ³á‹ áŠ áˆáŠ•áˆ á‹¨á‹“áˆˆáˆáŠ• áˆ˜áˆáŠ­ áŠ á‰ áˆ‹áˆ½á‰¶á‰³áˆá¢ áˆ°áˆ‹áˆ á‰ á‹áˆµáŒ¥á‹‹ áŒˆáˆ«áˆáŠá‰µá£ á‰µá‹•áŒáˆ¥á‰µá£ á‰³á‹›á‹¥áŠá‰µáŠ“ á‰ á‰µáˆ…á‰µáŠ“ á‹á‰… áˆ›áˆˆá‰µ áˆµáˆˆáˆšáŒˆáŠ™ áˆ˜áˆ«áˆ« á‰µáˆ˜áˆµáˆ‹áˆˆá‰½á¤ á‰ á‹áŒ¤á‰· áŒáŠ• áˆ€áŒˆáˆ­áŠ• áŠ¨áŒ¥á‹á‰µá£ áˆ•á‹á‰¥áŠ• áŠ¨áˆ˜áŠ¨áˆ« áˆ›á‰µáˆ¨á á‹¨áˆšá‰»áˆ á‰ áˆ˜áˆ†áŠ‘ á‹‹áŒ‹á‹‹ áŠ¨á á‹«áˆˆ áŠá‹á¢ á‰…á‹µáˆµá‰µ á‰¤á‰° áŠ­áˆ­áˆµá‰²á‹«áŠ“á‰½áŠ• á¦ Â° áˆ°áˆ‹áˆ á‹¨áˆ†áŠá‹ áŠ­áˆ­áˆµá‰¶áˆµ á‹¨áˆšáˆ°á‰ áŠ­á‰£á‰µá£ Â° á‹¨áˆ°áˆ‹áˆ áˆ˜áˆáŠ¥áŠ­á‰°áŠá‰½ á‰ á‹áˆµáŒ¥á‹‹ á‹¨áˆšáˆ˜áˆ‹áˆˆáˆ±á‰£á‰µá£ Â° á‰ áŒá‰¥áˆ¨ áŠƒáŒ¢áŠ á‰µ á‹¨á‹ˆá‹°á‰á‰µ á‰ áŠ•áˆµáˆ“ áŠ¨áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­ áŒ‹áˆ­ á‹¨áˆšá‰³áˆ¨á‰á‰£á‰µ á‹¨áˆ°áˆ‹áˆ á‹µáˆá‹µá‹­ áˆµáˆˆáˆ†áŠá‰½ á‰ áˆ¥áˆ­á‹“á‰° á‰…á‹³áˆ´á‹‹ áˆ°áˆ‹áˆáŠ• á‹°áŒ‹áŒáˆ› á‰³á‹áŒƒáˆˆá‰½á¤ á‰ áŒ¸áˆá‰· áˆˆáˆ˜áˆ‹á‹ á‹“áˆˆáˆ áˆ°áˆ‹áˆáŠ• á‰µáˆˆáˆáŠ“áˆˆá‰½á¤ á‰ áŒ‰áˆáˆ‹á‰µá‹‹ áˆ‹á‹­ á‹¨áˆ°á‰€áˆˆá‰½á‹ áˆ˜áˆµá‰€áˆáˆ áˆ°áˆ‹áˆáŠ• á‹¨áˆšáˆ°á‰¥áŠ­ áŠá‹á¤ á‹¨áˆ˜áˆµá‰€áˆ‰ á‰…áˆ­á… á‹ˆá‹° áˆ‹á‹­áŠ“ á‹ˆá‹° áŒáŠ• áˆ˜áˆ†áŠ‘áˆ áŠ¨áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­áŠ“ áŠ¨áˆ°á‹ áŒ‹áˆ­ áˆ°áˆ‹áˆ áˆ˜áˆ†áŠ• áŠ¥áŠ•á‹³áˆˆá‰¥áŠ• á‹¨áˆšá‹«áˆµáŒˆáŠá‹á‰ áŠ• áŠá‹á¢ á‰³áˆªáŠ«á‰½áŠ• áŠ¥áŠ•á‹°áˆšáŠáŒáˆ¨áŠ• á‹ˆáŠ•á‹µáˆ›áˆ›á‰¾á‰½ áˆ²áŒ‹á‹°áˆ‰á£ á‰ áˆ•á‹á‰¥ áˆ˜áŠ«áŠ¨áˆ áˆ˜á‰°áˆ‹áˆˆá‰… áˆ²áˆ˜áŒ£ á‰¤á‰° áŠ­áˆ­áˆµá‰²á‹«áŠ• á‰³á‰¦á‰µ áŠ áŠ­á‰¥áˆ«á£ á‰ áŠ¥áˆ³á‰µ áˆ˜áŠ«áŠ¨áˆ áŒˆá‰¥á‰³ áˆ°áˆ‹áˆáŠ• áˆµá‰³á‹ˆáˆ­á‹µ á‹¨áŠ–áˆ¨á‰½ áŠ“á‰µá¢ á‰ áˆ€áŒˆáˆ­ á‹áˆµáŒ¥ áŒáŒ­á‰¶á‰½ á‰ á‰°áˆáŒ áˆ©á‰ á‰µ áŒŠá‹œáˆ á‹¨áˆ°áˆ‹áˆ áŒ¥áˆªáŠ• á‹«áˆ‹áˆµá‰°áˆ‹áˆˆáˆá‰½á‰ á‰µ á‰€áŠ•áŠ“ áˆ°á‹“á‰µ áŠ á‹­áŒˆáŠáˆá¡á¡ áˆ°áˆ‹áˆáŠ• á‹¨áˆ˜á‹ˆá‹«á‹« áˆ­áŠ¥áˆµ áŠ á‹µáˆ­áŒˆáŠ• áˆµáŠ•áˆ°á‰£áˆµá‰¥ á‰ áŒ¦áˆ­áŠá‰µ áˆ˜áŠ«áŠ¨áˆ á‹¨á‰°áŒ¨áŠá‰ áˆ•á‹á‰¦á‰½á£ áˆ«áˆ³á‰¸á‹áŠ• áˆ˜áŠ¨áˆ‹áŠ¨áˆ á‹¨áˆ›á‹­á‰½áˆ‰ áŠ¥áŠ“ áˆáŠ• áŠ¥á‹¨á‰°á‹°áˆ¨áŒˆ áŠ¥áŠ•á‹³áˆˆ á‰ á‹áˆ á‹¨áˆ›á‹­áŒˆáŠá‹˜á‰¡ á‹°áŠ«áˆá‰½ á‰°áˆµá‹ á‹«á‹°áˆ­áŒ‰áŠ“áˆá¢ áˆµáˆˆá‹šáˆ… áˆ°áˆ‹áˆ áŠ¨áŠ áŠ•áŒˆá‰µ á‰ áˆ‹á‹­áŠ“ á‹áˆ áˆ‹áˆˆáˆ›áˆˆá‰µ á‹«áˆ…áˆ á‹¨áˆáŠ•áŠ“áŒˆáˆ¨á‹ áˆ³á‹­áˆ†áŠ• á‹‹áŒ‹ áŠ¨ááˆˆáŠ• á‹¨áˆáŠ“áˆ˜áŒ£á‹ áˆµáˆˆáˆ†áŠ á‹­áˆ… áŒ‰á‰£áŠ¤ áŠ¨á‹á‹­á‹­á‰µ á‰£áˆ»áŒˆáˆ­ á‰ á‰°áŒá‰£áˆ­ áŒ­áˆáˆ­ á‹¨áˆ°áˆ‹áˆ á‰°áˆáˆ³áˆŒá‰µ áˆ˜áˆ†áŠ• áŠ¥áŠ•á‹°áˆšáŒˆá‰£á‹ áˆˆáˆ›áˆ³áˆ°á‰¥ áŠ¥áŠ•á‹ˆá‹³áˆˆáŠ•á¢ \" (áˆ™áˆ‰ áˆ˜áˆá‹•áŠ­á‰³á‰¸á‹ áŠ¨áˆ‹á‹­ á‰°á‹«á‹­á‹Ÿáˆ)\n","\n","---------------------------------------------------------------------------------\n","Data at index 890 after tokenization:  [14, 302, 43245, 42, 9, 2331, 37977, 512, 470, 85965, 464, 253, 26895, 82905, 15, 14, 20, 13326, 57, 413, 98, 60, 260, 169, 4331, 6235, 150, 117, 820, 10, 8, 413, 125, 44, 20762, 41831, 7207, 33, 49, 2386, 175, 3828, 1077, 8591, 11239, 13264, 4076, 4, 1, 1914, 341, 640, 1, 78, 4405, 1, 1914, 33, 824, 750, 33, 1272, 741, 33116, 976, 1712, 150, 3598, 70, 2416, 3762, 1418, 4528, 4776, 3102, 3686, 4076, 4, 1, 1914, 8056, 1537, 4, 1, 78, 1420, 9140, 341, 1534, 9197, 337, 3875, 9931, 455, 3299, 13326, 107, 713, 135, 29, 330, 78447, 3799, 34, 14, 302, 550, 737, 461, 13, 7905, 4, 82566, 11, 57955, 23146, 35, 5899, 12034, 6409, 40, 38, 13, 242, 7, 550, 6417, 11, 26756, 277, 12721, 655, 5382, 6, 41824, 69299, 32, 302, 1205, 459, 1059, 2044, 722, 35, 302, 5382, 55, 228, 19167, 228, 472, 610, 18291, 998, 30048, 95209, 32, 334, 406, 17334, 25171, 16, 457, 26524, 1762, 23, 9930, 35, 5276, 9, 2199, 260, 334, 13, 458, 76, 464, 13472, 22, 382, 459, 5, 1552, 79770, 1910, 302, 6291, 353, 4, 12544, 8, 17829, 51736, 13, 4, 90352, 9, 12318, 2654, 406, 18296, 21698, 52377, 40, 6, 37647, 2381, 55, 162, 5, 17892, 13, 11472, 12, 36295, 6815, 13053, 317, 253, 353, 642, 182, 35, 3748, 586, 18878, 218, 4, 1, 302, 532, 5930, 20707, 204, 220, 36963, 4, 1, 413, 82240, 6291, 353, 51140, 36963, 4, 1, 26825, 4445, 1, 7663, 67691, 6, 5, 78, 1, 25914, 17, 352, 39806, 937, 413, 2805, 27495, 36749, 23030, 353, 4018, 36594, 15010, 2612, 36501, 6, 88354, 2902, 260, 4018, 4, 24, 6308, 9, 36501, 6, 94522, 353, 10, 11, 55032, 1431, 1064, 8, 4018, 74659, 1286, 77950, 10479, 16, 10, 9, 16, 1160, 3091, 25914, 9, 4908, 17, 302, 397, 12955, 81805, 204, 5, 35, 30394, 64, 73782, 10677, 210, 58238, 13, 5301, 97, 197, 81257, 4822, 586, 936, 17534, 66722, 13, 3045, 97, 12996, 4018, 3755, 9326, 44290, 3145, 1114, 23, 2523, 16629, 69, 38, 8, 413, 226, 5, 99213, 4793, 47, 9, 90, 21116, 84, 4018, 30556, 14552, 5314, 2957, 67967, 3232, 97, 75389, 4144, 13, 2334, 1113, 7594, 7, 107, 778, 856, 5061, 1593, 30894, 9460, 678, 17474, 5179, 1263, 302, 43245, 42, 9, 2331, 37977, 512, 470, 85965, 464, 253, 26895, 82905, 1149, 103, 552, 12, 41082, 2231, 4329, 976, 413, 10344, 397, 7504, 21800, 11085, 14, 29, 4545, 18864, 624, 1510, 1, 73, 34]\n","\n","---------------------------------------------------------------------------------\n","Data at index 890 after detokenization: ['â–\"', 'â–áˆ°áˆ‹áˆ', 'â–áŠ¨áŠ áŠ•áŒˆá‰µ', 'â–á‰ áˆ‹á‹­', 'áŠ“', 'â–á‹áˆ', 'â–áˆ‹áˆˆáˆ›', 'áˆˆá‰µ', 'â–á‹«áˆ…áˆ', 'â–á‹¨áˆáŠ•áŠ“áŒˆáˆ¨á‹', 'â–áˆ³á‹­áˆ†áŠ•', 'â–á‹‹áŒ‹', 'â–áŠ¨ááˆˆáŠ•', 'â–á‹¨áˆáŠ“áˆ˜áŒ£á‹', 'â–áŠá‹', 'â–\"', 'â–-', 'â–á‰…á‹±áˆµáŠá‰³á‰¸á‹', 'â–á‹›áˆ¬', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–áˆšáŠ’áˆµá‰´áˆ­', 'â–áŠ áŠ•á‹µ', 'â–á‹“áˆˆáˆ', 'â–áŠ á‰€á', 'â–áŠ®áŠ•áˆáˆ¨áŠ•áˆµ', 'â–áŠ á‹˜áŒ‹áŒ…á‰¶', 'â–áŠá‰ áˆ­á¢', 'â–á‰ á‹šáˆ…', 'â–áˆ˜á‹µáˆ¨áŠ­', 'â–áˆ‹á‹­', 'áˆ', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–áˆšáŠ’áˆµá‰µáˆ­', 'â–áŠ á‰¶', 'â–á‰¥áŠ“áˆá', 'â–áŠ á‹±', 'á‹“áˆˆáˆ', 'â–á£', 'â–á‹¨áŠ¢á‰µá‹®áŒµá‹«', 'â–á‹¨áˆƒá‹­áˆ›áŠ–á‰µ', 'â–á‰°á‰‹áˆ›á‰µ', 'â–á‹¨á‰ áˆ‹á‹­', 'â–áŒ á‰£á‰‚', 'â–áŠ á‰£á‰¶á‰½á£', 'â–á‰¥áá‹“áŠ•', 'â–áŠ á‰ á‹', 'â–áˆŠá‰ƒáŠ', 'â–', 'áŒ³áŒ³', 'áˆ³á‰µ', 'â–á‹ˆ', 'áŠ¤', 'áŒ²', 'áˆµ', 'â–á‰†', 'áŒ¶', 'áˆ³á‰µ', 'â–á£', 'â–á‹¨áˆ˜áŠ•áŒáˆ¥á‰µ', 'â–á‰£áˆˆáˆµáˆáŒ£áŠ“á‰µ', 'â–á£', 'â–áŠ á‰£', 'áˆ³', 'á‹°áˆ®á‰½', 'â–áŒ­áˆáˆ­', 'â–á‰°áŒˆáŠá‰°á‹', 'â–áŠá‰ áˆ­á¢', 'â–á‰ áˆ˜á‹µáˆ¨áŠ©', 'â–á¤', 'â–á‰¥áá‹•', 'â–á‹ˆá‰…á‹±áˆµ', 'â–áŠ á‰¡áŠ', 'â–áˆ›á‰µá‹«áˆµ', 'â–á‰€á‹³áˆ›á‹Š', 'â–á“á‰µáˆ­á‹«áˆ­áŠ­', 'â–áˆ­áŠ¥áˆ°', 'â–áˆŠá‰ƒáŠ', 'â–', 'áŒ³áŒ³', 'áˆ³á‰µ', 'â–á‹˜áŠ¢á‰µá‹®áŒµá‹«', 'â–áˆŠá‰€', 'â–', 'áŒ³áŒ³', 'áˆµ', 'â–á‹˜', 'áŠ áŠ­áˆ±áˆ', 'â–á‹ˆ', 'áŠ¥', 'áŒ¨áŒŒ', 'â–á‹˜áˆ˜áŠ•', 'á‰ áˆ¨', 'â–á‰°áŠ­áˆˆáˆƒá‹­áˆ›áŠ–á‰µ', 'â–áˆ˜áˆá‹•áŠ­á‰µ', 'â–áŠ áˆµá‰°áˆ‹áˆáˆá‹‹áˆá¢', 'â–á‰…á‹±áˆµáŠá‰³á‰¸á‹', 'â–áˆáŠ•', 'â–áŠ áˆ‰', 'â–?', 'â–(', 'áŠ¨', 'áˆ˜áˆá‹•áŠ­á‰³á‰¸á‹', 'â–á‹¨á‰°á‹ˆáˆ°á‹°', ')', 'â–\"', 'â–áˆ°áˆ‹áˆ', 'â–á‹¨áˆ°á‹', 'â–áˆáŒ†á‰½', 'â–ááˆ‹áŒá‰µ', 'á£', 'â–á‹¨á‰¥á‹™', 'â–', 'áˆáŠ•á‹±á‰£áŠ•', 'â–á‹¨', 'á‹¨á‹•áˆˆá‰µ', 'â–áŠ“áá‰†á‰µ', 'â–áŠá‹á¢', 'â–á‹¨á‰ áˆ­áŠ«á‰³', 'â–á‹˜áˆ˜áŠ“á‰µ', 'â–á‰…áˆ­áˆ¶á‰½', 'á¤', 'â–áŒŠá‹œ', 'á£', 'â–áŒˆáŠ•á‹˜á‰¥', 'â–áŠ¥áŠ“', 'â–á‹¨áˆ°á‹', 'â–áŒ‰áˆá‰ á‰µ', 'â–á‹¨', 'áˆáˆ°áˆ°', 'á‰£á‰¸á‹', 'â–áŒáŠ•á‰£á‰³á‹á‰½', 'â–á‰ áˆ°áˆ‹áˆ', 'â–áˆ›áŒ£á‰µ', 'â–á‰ ', 'á‰…áŒ½á‰ á‰µ', 'â–á‹­áˆáˆ­áˆ³áˆ‰', 'á¢', 'â–áˆ°áˆ‹áˆ', 'â–áŠ«áˆˆ', 'â–á‹¨á‹“áˆˆáˆ', 'â–áˆ€á‰¥á‰µ', 'â–áˆˆáˆáˆ‰áˆ', 'â–á‰ á‰‚', 'â–áŠá‹á¢', 'â–áˆ°áˆ‹áˆ', 'â–áˆ›áŒ£á‰µ', 'â–áŒáŠ•', 'â–á‰¥á‹™', 'â–áˆ áˆ«á‹Šá‰µá£', 'â–á‰¥á‹™', 'â–á‹¨áŒ¦áˆ­', 'â–áˆ˜áˆ³áˆªá‹«', 'â–áŠ¥áŠ•á‹²á‹˜áŒ‹áŒ…', 'â–áŠ¥á‹«á‹°áˆ¨áŒˆ', 'â–áˆ€á‰¥á‰µáŠ•', 'â–á‹«á‹ˆá‹µáˆ›áˆ', 'á¢', 'â–áŒ¦áˆ­áŠá‰µ', 'â–áˆ›áˆˆá‰µ', 'â–áˆ€á‰¥á‰µáŠ“', 'â–áˆ•á‹­á‹ˆá‰µáŠ•', 'â–á‹ˆá‹°', 'áˆš', 'áŠá‹µ', 'â–áŠ¥áˆ³á‰µ', 'â–á‹áˆµáŒ¥', 'â–áˆ˜áŒ£áˆ', 'â–áŠá‹á¢', 'â–á‹¨áŠ áŠ•á‹°áŠ›', 'áŠ“', 'â–á‹¨áˆáˆˆá‰°áŠ›', 'â–á‹“áˆˆáˆ', 'â–áŒ¦áˆ­áŠá‰µ', 'á£', 'â–á‰³áˆªáŠ­', 'â–á‰¥á‰»', 'â–áˆ³á‹­áˆ†áŠ•', 'â–áŒ á‰£áˆ³', 'á‹', 'â–áŠ áˆáŠ•áˆ', 'â–á‹¨á‹“áˆˆáˆ', 'áŠ•', 'â–áˆ˜áˆáŠ­', 'â–áŠ á‰ áˆ‹áˆ½á‰¶', 'á‰³áˆá¢', 'â–áˆ°áˆ‹áˆ', 'â–á‰ á‹áˆµáŒ¥', 'á‹‹', 'â–', 'áŒˆáˆ«', 'áˆ', 'áŠá‰µá£', 'â–á‰µá‹•áŒáˆ¥á‰µ', 'á£', 'â–', 'á‰³á‹›á‹¥áŠá‰µ', 'áŠ“', 'â–á‰ á‰µáˆ…á‰µáŠ“', 'â–á‹á‰…', 'â–áˆ›áˆˆá‰µ', 'â–áˆµáˆˆáˆšáŒˆáŠ™', 'â–áˆ˜áˆ«áˆ«', 'â–á‰µáˆ˜áˆµáˆ‹áˆˆá‰½', 'á¤', 'â–á‰ ', 'á‹áŒ¤', 'á‰·', 'â–áŒáŠ•', 'â–áˆ€áŒˆáˆ­', 'áŠ•', 'â–áŠ¨áŒ¥á‹á‰µ', 'á£', 'â–áˆ•á‹á‰¥áŠ•', 'â–áŠ¨', 'áˆ˜áŠ¨áˆ«', 'â–áˆ›á‰µáˆ¨á', 'â–á‹¨áˆšá‰»áˆ', 'â–á‰ áˆ˜áˆ†áŠ‘', 'â–á‹‹áŒ‹', 'á‹‹', 'â–áŠ¨á', 'â–á‹«áˆˆ', 'â–áŠá‹á¢', 'â–á‰…á‹µáˆµá‰µ', 'â–á‰¤á‰°', 'â–áŠ­áˆ­áˆµá‰²á‹«áŠ“á‰½áŠ•', 'â–á¦', 'â–', 'Â°', 'â–áˆ°áˆ‹áˆ', 'â–á‹¨áˆ†áŠá‹', 'â–áŠ­áˆ­áˆµá‰¶áˆµ', 'â–á‹¨áˆšáˆ°', 'á‰ ', 'áŠ­', 'á‰£á‰µá£', 'â–', 'Â°', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–áˆ˜áˆáŠ¥áŠ­á‰°áŠá‰½', 'â–á‰ á‹áˆµáŒ¥', 'á‹‹', 'â–á‹¨áˆšáˆ˜áˆ‹áˆˆáˆ±', 'á‰£á‰µá£', 'â–', 'Â°', 'â–á‰ áŒá‰¥áˆ¨', 'â–áŠƒ', 'áŒ¢', 'áŠ á‰µ', 'â–á‹¨á‹ˆá‹°á‰á‰µ', 'â–á‰ ', 'áŠ•', 'áˆµ', 'áˆ“', 'â–áŠ¨áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­', 'â–áŒ‹áˆ­', 'â–á‹¨áˆš', 'á‰³áˆ¨á‰', 'á‰£á‰µ', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–á‹µáˆá‹µá‹­', 'â–áˆµáˆˆáˆ†áŠá‰½', 'â–á‰ áˆ¥áˆ­á‹“á‰°', 'â–á‰…á‹³áˆ´', 'á‹‹', 'â–áˆ°áˆ‹áˆáŠ•', 'â–á‹°áŒ‹áŒáˆ›', 'â–á‰³á‹', 'áŒƒ', 'áˆˆá‰½á¤', 'â–á‰ ', 'áŒ¸áˆá‰·', 'â–áˆˆáˆ˜áˆ‹á‹', 'â–á‹“áˆˆáˆ', 'â–áˆ°áˆ‹áˆáŠ•', 'â–', 'á‰µ', 'áˆˆáˆ', 'áŠ“', 'áˆˆá‰½á¤', 'â–á‰ ', 'áŒ‰áˆáˆ‹á‰µ', 'á‹‹', 'â–áˆ‹á‹­', 'â–á‹¨', 'áˆ°á‰€áˆˆ', 'á‰½á‹', 'â–áˆ˜áˆµá‰€áˆ', 'áˆ', 'â–áˆ°áˆ‹áˆáŠ•', 'â–á‹¨áˆšáˆ°á‰¥áŠ­', 'â–áŠá‹á¤', 'â–á‹¨áˆ˜áˆµá‰€áˆ‰', 'â–á‰…áˆ­á…', 'â–á‹ˆá‹°', 'â–áˆ‹á‹­', 'áŠ“', 'â–á‹ˆá‹°', 'â–áŒáŠ•', 'â–áˆ˜áˆ†áŠ‘áˆ', 'â–áŠ¨áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­', 'áŠ“', 'â–áŠ¨áˆ°á‹', 'â–áŒ‹áˆ­', 'â–áˆ°áˆ‹áˆ', 'â–áˆ˜áˆ†áŠ•', 'â–áŠ¥áŠ•á‹³áˆˆá‰¥áŠ•', 'â–á‹¨áˆšá‹«áˆµáŒˆáŠá‹', 'á‰ ', 'áŠ•', 'â–áŠá‹á¢', 'â–á‰³áˆªáŠ«á‰½áŠ•', 'â–áŠ¥áŠ•á‹°', 'áˆšáŠáŒáˆ¨áŠ•', 'â–á‹ˆáŠ•á‹µáˆ›áˆ›á‰¾á‰½', 'â–áˆ²', 'áŒ‹á‹°áˆ‰', 'á£', 'â–á‰ áˆ•á‹á‰¥', 'â–áˆ˜áŠ«áŠ¨áˆ', 'â–áˆ˜', 'á‰°áˆ‹áˆˆá‰…', 'â–áˆ²áˆ˜áŒ£', 'â–á‰¤á‰°', 'â–áŠ­áˆ­áˆµá‰²á‹«áŠ•', 'â–á‰³á‰¦á‰µ', 'â–áŠ áŠ­á‰¥áˆ«', 'á£', 'â–á‰ áŠ¥áˆ³á‰µ', 'â–áˆ˜áŠ«áŠ¨áˆ', 'â–áŒˆá‰¥á‰³', 'â–áˆ°áˆ‹áˆáŠ•', 'â–áˆµá‰³', 'á‹ˆáˆ­á‹µ', 'â–á‹¨áŠ–áˆ¨á‰½', 'â–áŠ“á‰µá¢', 'â–á‰ áˆ€áŒˆáˆ­', 'â–á‹áˆµáŒ¥', 'â–áŒáŒ­á‰¶á‰½', 'â–á‰ á‰°áˆáŒ áˆ©', 'á‰ á‰µ', 'â–áŒŠá‹œ', 'áˆ', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–áŒ¥áˆª', 'áŠ•', 'â–á‹«áˆ‹áˆµá‰°áˆ‹áˆˆáˆ', 'á‰½á‰ á‰µ', 'â–á‰€áŠ•', 'áŠ“', 'â–áˆ°á‹“á‰µ', 'â–áŠ á‹­áŒˆáŠáˆ', 'á¡á¡', 'â–áˆ°áˆ‹áˆáŠ•', 'â–á‹¨áˆ˜á‹ˆá‹«á‹«', 'â–áˆ­áŠ¥áˆµ', 'â–áŠ á‹µáˆ­áŒˆáŠ•', 'â–áˆµáŠ•', 'áˆ°á‰£áˆµá‰¥', 'â–á‰ áŒ¦áˆ­áŠá‰µ', 'â–áˆ˜áŠ«áŠ¨áˆ', 'â–á‹¨á‰°áŒ¨áŠá‰', 'â–áˆ•á‹á‰¦á‰½', 'á£', 'â–áˆ«áˆ³á‰¸á‹áŠ•', 'â–áˆ˜áŠ¨áˆ‹áŠ¨áˆ', 'â–á‹¨áˆ›á‹­á‰½áˆ‰', 'â–áŠ¥áŠ“', 'â–áˆáŠ•', 'â–áŠ¥á‹¨á‰°á‹°áˆ¨áŒˆ', 'â–áŠ¥áŠ•á‹³áˆˆ', 'â–á‰ á‹áˆ', 'â–á‹¨áˆ›á‹­', 'áŒˆáŠá‹˜á‰¡', 'â–á‹°áŠ«áˆá‰½', 'â–á‰°áˆµá‹', 'â–á‹«á‹°áˆ­áŒ‰', 'áŠ“áˆá¢', 'â–áˆµáˆˆá‹šáˆ…', 'â–áˆ°áˆ‹áˆ', 'â–áŠ¨áŠ áŠ•áŒˆá‰µ', 'â–á‰ áˆ‹á‹­', 'áŠ“', 'â–á‹áˆ', 'â–áˆ‹áˆˆáˆ›', 'áˆˆá‰µ', 'â–á‹«áˆ…áˆ', 'â–á‹¨áˆáŠ•áŠ“áŒˆáˆ¨á‹', 'â–áˆ³á‹­áˆ†áŠ•', 'â–á‹‹áŒ‹', 'â–áŠ¨ááˆˆáŠ•', 'â–á‹¨áˆáŠ“áˆ˜áŒ£á‹', 'â–áˆµáˆˆáˆ†áŠ', 'â–á‹­áˆ…', 'â–áŒ‰á‰£áŠ¤', 'â–áŠ¨', 'á‹á‹­á‹­á‰µ', 'â–á‰£áˆ»áŒˆáˆ­', 'â–á‰ á‰°áŒá‰£áˆ­', 'â–áŒ­áˆáˆ­', 'â–á‹¨áˆ°áˆ‹áˆ', 'â–á‰°áˆáˆ³áˆŒá‰µ', 'â–áˆ˜áˆ†áŠ•', 'â–áŠ¥áŠ•á‹°áˆšáŒˆá‰£á‹', 'â–áˆˆáˆ›áˆ³áˆ°á‰¥', 'â–áŠ¥áŠ•á‹ˆá‹³áˆˆáŠ•á¢', 'â–\"', 'â–(', 'áˆ™áˆ‰', 'â–áˆ˜áˆá‹•áŠ­á‰³á‰¸á‹', 'â–áŠ¨áˆ‹á‹­', 'â–á‰°á‹«á‹­', 'á‹Ÿ', 'áˆ', ')']\n"]}],"source":["index=890\n","print(f\"Data at index {index} before tokenization:\", cleaned_data[index])\n","print(\"\\n---------------------------------------------------------------------------------\")\n","print(f\"Data at index {index} after tokenization: \", tokenizer.encode(cleaned_data[index]))\n","print(\"\\n---------------------------------------------------------------------------------\")\n","print(f\"Data at index {index} after detokenization:\", tokenizer.encode_as_pieces(cleaned_data[index]))"]},{"cell_type":"markdown","metadata":{"id":"UJRgj09U7acK"},"source":["To pretrain our Transformer network, we will use the Masked Language Model (MLM) approach. This technique involves randomly masking a percentage of words in a sentence and replacing them with special tokens. The model then attempts to predict these masked words, enabling it to learn contextual and semantic representations effectively."]},{"cell_type":"markdown","metadata":{"id":"YJN4AUYF7acK"},"source":["I will be implementing the Masked language model (MLM) as shown in the following image.\n","\n","<img src = \"images/losses.png\" width=\"600\" height = \"400\">\n","\n","Assume you have the following text: <span style = \"color:blue\"> **áˆ°áˆ‹áˆ <span style = \"color:red\">á‹¨áˆ°á‹ áˆáŒ†á‰½ </span> ááˆ‹áŒá‰µá£ á‹¨á‰¥á‹™ áˆáŠ•á‹±á‰£áŠ• á‹¨á‹¨á‹•áˆˆá‰µ <span style = \"color:red\">áŠ“áá‰†á‰µ</span>  áŠá‹á¢** </span>     \n","\n","\n","Now as input you will mask the words in red in the text:\n","\n","<span style = \"color:blue\"> **Input:**</span> áˆ°áˆ‹áˆ  **X** ááˆ‹áŒá‰µá£ á‹¨á‰¥á‹™ áˆáŠ•á‹±á‰£áŠ• á‹¨á‹¨á‹•áˆˆá‰µ **Y** áŠá‹á¢\n","\n","<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**.\n","\n","**[EOS]** will be used to mark the end of the target sequence."]},{"cell_type":"markdown","metadata":{"id":"BPcVucnE7acK"},"source":["As you can see above, I were able to take a piece of string and tokenize it.\n","\n","Now I will create `input` and `target` pairs that will allow me to pre-train the model. The model uses the ids at the end of the vocab file as sentinels. For example, it will replace:\n","   - `vocab_size - 1` by `<Z>`\n","   - `vocab_size - 2` by `<Y>`\n","   - and so forth.\n","   \n","It assigns every word a `chr`.\n","\n","The `pretty_decode` function below, which I will use in a bit, helps in handling the type when decoding.\n","\n","Notice that:\n","```python\n","string.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","```\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1740035022914,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"SgbBA4Ek7acK"},"outputs":[],"source":["def get_sentinels(tokenizer, display=False):\n","    sentinels = {}\n","    vocab_size = tokenizer.vocab_size()\n","    for i, char in enumerate(reversed(string.ascii_letters), 1):\n","        decoded_text = tokenizer.detokenize([vocab_size - i])\n","\n","        # Sentinels, ex: <Z> - <a>\n","        sentinels[decoded_text] = f'<{char}>'\n","\n","        if display:\n","            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n","\n","    return sentinels\n","\n","\n","def pretty_decode(encoded_str_list, sentinels, tokenizer):\n","    # If already a string, just do the replacements.\n","    if isinstance(encoded_str_list, str):\n","        for token, char in sentinels.items():\n","            encoded_str_list = re.sub(re.escape(token), char, encoded_str_list)\n","        return encoded_str_list\n","\n","    # We need to decode and then prettyfy it.\n","    return pretty_decode(tokenizer.detokenize(encoded_str_list), sentinels, tokenizer)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75,"status":"ok","timestamp":1740035022991,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"WVhT-pAf7acL","outputId":"86ec9f43-1e5e-4374-e6e5-08a9f5b3da86"},"outputs":[{"output_type":"stream","name":"stdout","text":["The sentinel is <Z> and the decoded token is: áŒ‚á‹®á–áˆŠá‰³áŠ•\n","The sentinel is <Y> and the decoded token is: áŠ®áˆŒáŒƒá‰½áŠ•\n","The sentinel is <X> and the decoded token is: á‰¥áˆ®áŠ•á‹\n","The sentinel is <W> and the decoded token is: áŠ®áŠ•á‰²áŠ”\n","The sentinel is <V> and the decoded token is: áŠ áˆáŒááŒˆ\n","The sentinel is <U> and the decoded token is: áŠ á‹­áˆáˆ®áŠ á‰½áŠ•\n","The sentinel is <T> and the decoded token is: á‹¨á‰°á‹ˆáŒ áˆ¨\n","The sentinel is <S> and the decoded token is: á‹«áŠ«á‰¥á‰±\n","The sentinel is <R> and the decoded token is: á‹­á‰ áˆ¨á‰³áˆ\n","The sentinel is <Q> and the decoded token is: áŒ‚áŠ áŠ•áŒ\n","The sentinel is <P> and the decoded token is: á‹«áˆµá‰½áˆ‰á‰³áˆ\n","The sentinel is <O> and the decoded token is: ,744\n","The sentinel is <N> and the decoded token is: á‹ˆáŒ¤á‰³áˆ›\n","The sentinel is <M> and the decoded token is: áŠ¥áˆ°áŒ£á‰½áŠ‹áˆˆáˆ\n","The sentinel is <L> and the decoded token is: á‹«áˆ³áˆáŠáŠ\n","The sentinel is <K> and the decoded token is: á‰ á‰µáˆáˆ­á‰µ\n","The sentinel is <J> and the decoded token is: á‹«áˆµáˆáˆáŒ‹á‰½áŠ‹áˆ\n","The sentinel is <I> and the decoded token is: áŠ áˆáˆ†áŠáˆáŠáˆ\n","The sentinel is <H> and the decoded token is: á‰µáŒ áˆá‰…\n","The sentinel is <G> and the decoded token is: áŒ áˆáŒ á\n","The sentinel is <F> and the decoded token is: áŠ áŒ½áˆ›á‰¸á‹\n","The sentinel is <E> and the decoded token is: á‰¥á‰µá‹ˆá‹µá‰…\n","The sentinel is <D> and the decoded token is: áˆ›áˆµáˆá‰°áŠ“á‰¸á‹\n","The sentinel is <C> and the decoded token is: áŒ‹áˆ¨á‹°á‰½\n","The sentinel is <B> and the decoded token is: áŠ®áŠ•á‰²áŠáˆ­\n","The sentinel is <A> and the decoded token is: áŠ áˆµá‰°áŠá‰³\n","The sentinel is <z> and the decoded token is: áŠ¥áŠ•á‹µá‰³áŠ¨á‰¥áˆ©\n","The sentinel is <y> and the decoded token is: áˆ¥áˆáŒ¤\n","The sentinel is <x> and the decoded token is: á‹¨áˆˆáˆ¾á‰½\n","The sentinel is <w> and the decoded token is: á‹¨áˆ°á‰ áˆ°á‰ á‰½á‹\n","The sentinel is <v> and the decoded token is: áŒáˆ­á‹á‰±\n","The sentinel is <u> and the decoded token is: á‰€áˆ‹á‰…áˆˆá‹‹áˆ\n","The sentinel is <t> and the decoded token is: áˆ˜áˆˆáŒ áŒ¥\n","The sentinel is <s> and the decoded token is: áŠ áˆá‰€áˆ­áˆ\n","The sentinel is <r> and the decoded token is: á‹áŒ¥áŠ–á‰½\n","The sentinel is <q> and the decoded token is: á‰ áˆšá‹«áˆµáŠ¬á‹°\n","The sentinel is <p> and the decoded token is: áŠ¥á‹¨á‰€áˆ¨áˆ\n","The sentinel is <o> and the decoded token is: áˆ°á‰ áˆ°á‰§á‰¸\n","The sentinel is <n> and the decoded token is: á‹«áŠ­á‰¥áˆ­áˆáŠ•\n","The sentinel is <m> and the decoded token is: á‹¨á‹°á‰ á‹°á‰ á‹\n","The sentinel is <l> and the decoded token is: á‹°á‰£áˆˆá‰\n","The sentinel is <k> and the decoded token is: áˆ˜á‰¥á‰¶á‰»á‰½áŠ•\n","The sentinel is <j> and the decoded token is: á‰µáˆ…áˆáˆ­á‰µ\n","The sentinel is <i> and the decoded token is: áŠ«áˆáˆ°á‰ \n","The sentinel is <h> and the decoded token is: á‹²á•áˆ¬áˆ½áŠ•\n","The sentinel is <g> and the decoded token is: á‰°á‰†áˆ¨áˆ°\n","The sentinel is <f> and the decoded token is: á‰ áˆ›áŒ£á‰´\n","The sentinel is <e> and the decoded token is: 60.88\n","The sentinel is <d> and the decoded token is: áˆšá‹«á‹‹áŒ¡á‰µ\n","The sentinel is <c> and the decoded token is: á‰áˆˆáˆ­\n","The sentinel is <b> and the decoded token is: áŠ®áˆªá‹°áˆ©\n","The sentinel is <a> and the decoded token is: áŠ¥á‹¨á‰°á‰€áŠáˆ°\n"]}],"source":["sentinels = get_sentinels(tokenizer, display=True)"]},{"cell_type":"markdown","metadata":{"id":"9KLkLK-R7acL"},"source":["Now, let's use the `pretty_decode` function in the following sentence."]},{"cell_type":"markdown","metadata":{"id":"on_KlLvV7acQ"},"source":["<a name='1-5'></a>\n","### 3.4 - Tokenizing and Masking\n","\n","In this task, I will implement the `tokenize_and_mask` function, which tokenizes and masks input words based on a given probability. The probability is controlled by the `noise` parameter, typically set to mask around `15%` of the words in the input text. The function will generate two lists of tokenized sequences following the algorithm outlined below:"]},{"cell_type":"markdown","metadata":{"id":"5m9Hc89a7acQ"},"source":["\n","###  tokenize_and_mask\n","\n","- Start with two empty lists: `inps` and `targs`\n","- Tokenize the input text using the given tokenizer.\n","- For each `token` in the tokenized sequence:\n","  - Generate a random number(simulating a weighted coin toss)\n","  - If the random value is greater than the given threshold(noise):\n","    - Add the current token to the `inps` list\n","  - Else:\n","    - If a new sentinel must be included:\n","      - Compute the next sentinel ID using a progression.\n","      - Add a sentinel into the `inps` and `targs` to mark the position of the masked element.\n","    - Add the current token to the `targs` list.\n","\n","** There's a special case to consider. If two or more consecutive tokens get masked during the process, no need to add a new sentinel to the sequences. To account for this, use the `prev_no_mask` flag, which starts as `True` but is turned to `False` each time I mask a new element. The code that adds sentinels will only be executed if, before masking the token, the flag was in the `True` state.\n"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1740035022999,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"qmBvWkOW7acQ"},"outputs":[],"source":["def tokenize_and_mask(text,\n","                      noise=0.15,\n","                      randomizer=np.random.uniform,\n","                      tokenizer=None):\n","    \"\"\"Tokenizes and masks a given input.\n","\n","    Args:\n","        text (str or bytes): Text input.\n","        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n","        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n","        tokenizer (function, optional): Tokenizer function. Defaults to tokenize.\n","\n","    Returns:\n","        inps, targs: Lists of integers associated to inputs and targets.\n","    \"\"\"\n","\n","    # Current sentinel number (starts at 0)\n","    cur_sentinel_num = 0\n","\n","    # Inputs and targets\n","    inps, targs = [], []\n","\n","    # Vocab_size\n","    vocab_size = int(tokenizer.vocab_size())\n","\n","    # EOS token id\n","    # Must be at the end of each target!\n","    eos = tokenizer.piece_to_id(\"</s>\")\n","\n","\n","\n","    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n","    # set prev_no_mask to True\n","    prev_no_mask = True\n","\n","    # Loop over the tokenized text\n","    for token in tokenizer.tokenize(text):\n","\n","        # Generate a random value between 0 and 1\n","        rnd_val = randomizer()\n","\n","        # Check if the noise is greater than a random value (weighted coin flip)\n","        if noise > rnd_val:\n","\n","            # Check if previous token was NOT masked\n","            if prev_no_mask:\n","\n","                # Current sentinel increases by 1\n","                cur_sentinel_num += 1\n","\n","                # Compute end_id by subtracting current sentinel value out of the total vocabulary size\n","                end_id = vocab_size - cur_sentinel_num\n","\n","                # Append end_id at the end of the targets\n","                targs.append(end_id)\n","\n","                # Append end_id at the end of the inputs\n","                inps.append(end_id)\n","\n","            # Append token at the end of the targets\n","            targs.append(token)\n","\n","            # set prev_no_mask accordingly\n","            prev_no_mask = False\n","\n","        else:\n","\n","            # Append token at the end of the inputs\n","            inps.append(token)\n","\n","            # Set prev_no_mask accordingly\n","            prev_no_mask = True\n","\n","\n","    # Add EOS token to the end of the targets\n","    targs.append(eos)\n","\n","\n","\n","    return inps, targs"]},{"cell_type":"markdown","metadata":{"id":"pPv4ycWK7acQ"},"source":["I will now take random value from the cleaned_data and pass it to `tokenize_and_mask` function and see how it randomly masks and separate inputs and targets"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1740035023019,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"TgLvsoyI7acQ","outputId":"d590cc55-6fe2-4afe-974e-32989abd040d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random data before Masking : \n","\n"," á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³á‹ áŠ áˆµá‰°áˆ›áˆ›áŠ áŠá‹~áŒ…áŒáŒ…áŒ‹! . . áˆµáˆáŠ•á‰°áŠ›á‹áŠ• á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áˆˆáˆ›áŠ«áˆ„á‹µ á‹áŒáŒ…á‰± áˆ˜áŒ áŠ“á‰€á‰áŠ•áŠ“ áˆáŠ•áˆ áŠ á‹­áŠá‰µ á‹¨á€áŒ¥á‰³ á‰½áŒáˆ­ áŠ áˆˆáˆ˜áŠ–áˆ©áŠ• á‹¨áŠ¨á‰°áˆ› áˆáˆ›á‰µáŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• áˆšáŠ’áˆµá‰´áˆ­ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³ áŠ á‰¶ áŠ«áˆ³áˆáŠ• áŒáŒ á‰°áŠ“áŒˆáˆ©á¢ á‹áŒáŒ…á‰±áŠ• áŠ áˆµáˆ˜áˆáŠ­á‰¶ á‰ áŒ…áŒáŒ…áŒ‹ áˆ˜áŒáˆˆáŒ« á‹¨áˆ°áŒ¡á‰µ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³á‹ áŒ…áŒ…áŒ‹ áˆ‹á‹­ á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³á‹ áŠ áˆµá‰°áˆ›áˆ›áŠ áŠá‹\"á¤ á‹¨áŠ­áˆáˆ‰ á–áˆŠáˆµ áŠ¨áŒá‹´áˆ«áˆ á‹¨á€áŒ¥á‰³ áŠ áŠ«áˆ‹á‰µ áŒ‹áˆ­áˆ á‰ á‰…áŠ•áŒ…á‰µ áŠ¥á‹¨áˆ°áˆ« áŠá‹ á‰¥áˆˆá‹‹áˆá¢ á‰ áŠ¨á‰°áˆ›á‹‹ áŠ áˆµá‰°áˆ›áˆ›áŠ á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³ áˆ˜áŠ–áˆ©áŠ• á‹¨áŒˆáˆˆáá‰µ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³á‹ á‰°áˆ³á‰³áŠ áŠ¨á‰°áˆá‰½ á‹ˆá‹°áŒ…áŒáŒ…áŒ‹ áŒˆá‰¥á‰°á‹ á‹áŒáŒ…á‰³á‰¸á‹áŠ• áŒ€áˆáˆ¨á‹‹áˆ á‰¥áˆˆá‹‹áˆá¢ á‹áŒáŒ…á‰¶á‰½áŠ• á‰ á‰°áˆ˜áˆˆáŠ¨á‰° áŠ¨áŠáŒˆ áŒ€áˆáˆ® áŠ¥áˆµáŠ¨ áˆ¨á‰¡á‹• áŠ¨áˆšáŠ–áˆ© á‹áŒáŒ…á‰¶á‰½ áˆ˜áŠ«áŠ¨áˆ á‰ áŒ…áŒáŒ…áŒ‹ áˆµá‰´á‹²á‹¨áˆ á‹¨áˆ˜áŠ­áˆá‰» áˆµáŠáˆµáˆ­á‹á‰µá£ á‰ áŠ¨á‰°áˆá‰½ á‹¨áˆµáˆ« á‹•á‹µáˆ áˆáŒ áˆ« áŠ¢áŠ•á‰°áˆ­á•áˆ«á‹­á‹á‰½ áˆáˆ›á‰µá£ á‰ áˆ˜áˆ¬á‰µ áˆáˆ›á‰µ áˆ›áŠ”áŒ…áˆ˜áŠ•á‰µá£ á‰ á‹˜áˆ­á‰ áŠ áŒ€áŠ•á‹³á‹á‰½ áˆ›áˆˆá‰µáˆ á‰ áŠ¨á‰°áˆ› áˆáˆ›á‰µá£ áŠ áˆ¨áŠ•áŒ“á‹´ áˆáˆ›á‰µáŠ“ áŠ áŠ«á‰£á‰¢ áŒ¥á‰ á‰ƒá£ á‰ á‰¤á‰¶á‰½áŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• áŠ¥áŠ•á‹²áˆáˆ á‰°á‹«á‹«á‹¥ á‹˜áˆ­áá‰½ á‹™áˆªá‹« áŒ¥áŠ“á‰³á‹Š á…áˆáá‰½ á‹­á‰€áˆ­á‰£áˆ‰á¢ áŠ á‰¶ áŠ«áˆ³áˆáŠ• áŠ¨á‰°áˆá‰½ áˆ«áˆ³á‰¸á‹áŠ• á‹¨áˆšá‹«áˆµá‰°á‹‹á‹á‰á‰ á‰µ áŠ¤áŒá‹šá‰¢áˆ½áŠ• á‹¨áˆšáŠ«áˆ„á‹µ áˆ²áˆ†áŠ• áŠ¨á‹šáˆ… á‰ áŠá‰µ á‰ á‰°á‹°áˆ¨áŒ‰ ááˆ¨áˆá‰½ á‹¨á‰°áˆµá‰°á‹‹áˆˆá‹ á‹¨á‹µáˆá… á‰¥áŠ­áˆˆá‰µ á‰ á‹šáˆ… áŠ áˆ˜á‰µ áŠ¥áŠ•á‹³á‹­áŠ–áˆ­ áŠ¨áŠ¨á‰°áˆá‰½ áŒ‹áˆ­ áˆ˜áŒá‰£á‰£á‰µ áˆ‹á‹­ á‰°á‹°áˆ­áˆ·áˆ á‰¥áˆˆá‹‹áˆá¢ áˆ€áˆ™áˆµ á‰ áˆšáŠ–áˆ¨á‹ á‹¨áˆ›áŒ á‰ƒáˆˆá‹« áˆµáˆ­á‹“á‰µ áˆˆáˆá‹´áˆ áŠ¢áŠ•á‰°áˆ­á•áˆ«á‹­á‹á‰½á£ áˆˆáˆ´á‰µ áˆµáˆ« áˆáŒ£áˆªá‹á‰½á£ á‰ áˆáˆ‰áˆ áŠ­áˆáˆá‰½ áŠ«áˆ‰ á‹¨áˆ´áŠ­á‰°áˆ­ á‰°á‰‹áˆ›á‰µ á‰ áŠ áˆáƒá€áˆ á‰¥áˆáŒ« áˆ‹áŒˆáŠ™ áŠ¥áŠ•á‹²áˆáˆ áˆˆá‹©áŠ’á‰¨áˆ­áˆ²á‰² á‰°áˆ˜áˆ«á‰‚ áˆµáˆ« áˆáŒ£áˆªá‹á‰½ áŠ¥á‹á‰…áŠ“áŠ“ áˆ½áˆáˆ›á‰µ á‹­áˆ°áŒ£áˆ á‰°á‰¥áˆáˆá¢ á‰ á‰°áˆ˜áˆ³áˆ³á‹­ á‹¨á‹˜áŒ áŠáŠ›á‹ á‹¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áŠ á‹˜áŒ‹áŒ… á‰ áŠ¥áˆˆá‰± á‹­á‹ á‹­á‹°áˆ¨áŒ‹áˆá¤ á‹¨á‹‹áŠ•áŒ« áˆ­áŠ­áŠ­á‰¥áˆ á‹­áŠ–áˆ«áˆ á‰¥áˆˆá‹‹áˆ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³á‹á¢ áˆµáˆáŠ•á‰°áŠ›á‹áŠ• á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ á‹¨á‰°áˆˆá‹¨ áˆˆáˆ›á‹µáˆ¨áŒ áŠ¨áˆ›áˆŒá‹¥á‹« áŠ áˆˆáˆáŠ á‰€á á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áˆáˆá‹µ á‰°á‹ˆáˆµá‹·áˆ á‹«áˆ‰á‰µ áŠ á‰¶ áŠ«áˆ³áˆáŠ• ááˆ¨áˆ™ áˆˆáˆ˜áŒ€áˆ˜áˆªá‹« áŒŠá‹œ á‰ á‰³á‹³áŒŠ áŠ­áˆáˆ áˆ˜áŠ«áˆ„á‹±áˆ áˆá‹© á‹«á‹°áˆ­áŒˆá‹‹áˆ á‰¥áˆˆá‹‹áˆá¢ á‹¨áˆ±áˆ›áˆŒ áŠ­áˆáˆ áŠ¨á‰°áˆ› áˆáˆ›á‰µáŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• á‰¢áˆ® áˆ€áˆ‹áŠ á‹¶/áˆ­ á‰ á‰ áŠ©áˆ‹á‰¸á‹ áŠ­áˆáˆ‰ ááˆ¨áˆ™áŠ• áˆˆáˆ›áˆµá‰°áŠ“áŒˆá‹µ á‹áŒáŒ…á‰±áŠ• áŠ áŒ áŠ“á‰‹áˆá¤ á‰°áˆ³á‰³áŠ áŠ¨á‰°áˆá‰½áˆ á‹ˆá‹° áŒ…áŒáŒ…áŒ‹ áŠ¥á‹¨áŒˆá‰¡ áŠá‹ á‰¥áˆˆá‹‹áˆá¢ á‰¢áˆ® áˆ€áˆ‹áŠá‹ á‰ áŒ¥á‰‚á‰µ áŒáˆˆáˆ°á‰¦á‰½ áŠ¨á‹ˆáˆ«á‰µ á‰ áŠá‰µ á‰°áŠ¨áˆµá‰¶ á‹¨áŠá‰ áˆ¨á‹ á‰½áŒáˆ­ áŒˆá…á‰³á‰½áŠ•áŠ• áŠ á‰ áˆ‹áˆ½á‰¶ á‹¨áŠá‰ áˆ¨ á‰¢áˆ†áŠ•áˆ áŠ áˆáŠ• áŒáŠ• áˆáŠ•áˆ á‹¨á€áŒ¥á‰³áˆ á‹­áˆáŠ• á‹¨á‹°áˆ…áŠ•áŠá‰µ á‰½áŒáˆ­ á‹¨áˆˆáˆ á‰¥áˆˆá‹‹áˆá¢ á‹¶/áˆ­ áŠ á‰¥á‹±áˆáˆá‰³áˆ… áˆµáˆáŠ•á‰°áŠ›á‹ á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ á‹¨áŠ­áˆáˆ‹á‰½áŠ•áŠ• á‰¥áˆáˆ á‹¨áŠ¨á‰°áˆ›á‰½áŠ•áŠ• áŠ áˆµá‰°áˆ›áˆ›áŠ áˆ°áˆ‹áˆ á‹¨áˆáŠ“áˆ¨áŒ‹áŒáŒ¥á‰ á‰µáŠ“ á‰ á‰°áŒá‰£áˆ­áˆ á‹¨áˆáŠ“áˆ³á‹­á‰ á‰µ áŠ¥áŠ•á‹²áˆ†áŠ• áˆ°áŠ áˆµáˆ« áˆ°áˆ­á‰°áŠ“áˆ á‹áŒ¤á‰±áŠ•áˆ áŠ¥á‹«á‹¨áŠ• áŠá‹ á‰¥áˆˆá‹‹áˆá¢ áˆµáˆáŠ•á‰°áŠ›á‹ á‹¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áŠ¨á‹¨áŠ«á‰²á‰µ 9-14/2011 ''áˆ˜á‹°áˆ˜áˆ­ áˆˆáŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½ á‰¥áˆá…áŒáŠ“'' á‰ áˆšáˆ áˆ˜áˆª á‰ƒáˆ á‰ áŒ…áŒáŒ…áŒ‹ á‹­áŠ«áˆ„á‹³áˆá¢ áˆáŠ•áŒ­á¦\n"]}],"source":["random_data=cleaned_data[32000]\n","print(\"Random data before Masking : \\n\\n\", random_data)"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1740035023023,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"SB7GpQZN7acQ"},"outputs":[],"source":["inps_sample,targs_sample=tokenize_and_mask(random_data,noise=0.15,randomizer=np.random.uniform,tokenizer=tokenizer)\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1740035023048,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"7edbHoLp7acQ","outputId":"cbf845f1-238c-49c8-bb92-b346260a525d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs: \n","\n"," á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³á‹ áŠ áˆµá‰°áˆ›áˆ›áŠ áŠá‹ â‡ <Z> . . áˆµáˆáŠ•á‰°áŠ›á‹<Y> á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áˆˆáˆ›áŠ«áˆ„á‹µ á‹áŒáŒ…á‰±<X>áŠ“ áˆáŠ•áˆ áŠ á‹­áŠá‰µ á‹¨á€áŒ¥á‰³ á‰½áŒáˆ­ <W> á‹¨áŠ¨á‰°áˆ› <V>áŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• áˆšáŠ’áˆµá‰´áˆ­<U> á‹´áŠ¤á‰³ áŠ á‰¶ <T> áŒáŒ<S> á‹áŒáŒ…á‰±áŠ• áŠ áˆµáˆ˜áˆáŠ­á‰¶ á‰ áŒ…áŒáŒ…áŒ‹ <R> á‹¨áˆ°áŒ¡á‰µ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³á‹ áŒ…áŒ…áŒ‹ áˆ‹á‹­ á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³á‹ áŠ áˆµá‰°áˆ›áˆ›áŠ áŠá‹\"á¤ á‹¨áŠ­áˆáˆ‰ á–áˆŠáˆµ áŠ¨áŒá‹´áˆ«áˆ á‹¨á€áŒ¥á‰³ áŠ áŠ«áˆ‹á‰µ<Q>áˆ <P> áŠ¥á‹¨áˆ°áˆ«<O> áŠ áˆµá‰°áˆ›áˆ›áŠ á‹¨á€áŒ¥á‰³ áˆáŠ”á‰³ áˆ˜áŠ–áˆ©áŠ• á‹¨áŒˆáˆˆáá‰µ áˆšáŠ’áˆµá‰µáˆ­ á‹´áŠ¤á‰³á‹ á‰°áˆ³á‰³áŠ áŠ¨á‰°áˆá‰½ á‹ˆá‹°áŒ…áŒáŒ…áŒ‹ áŒˆá‰¥á‰°á‹ á‹áŒáŒ…á‰³á‰¸á‹áŠ• áŒ€áˆáˆ¨á‹‹áˆ á‰¥áˆˆá‹‹áˆá¢ á‹áŒáŒ…á‰¶á‰½áŠ• á‰ á‰°áˆ˜áˆˆáŠ¨á‰° áŠ¨áŠáŒˆ áŒ€áˆáˆ® áŠ¥áˆµáŠ¨ áˆ¨á‰¡á‹•<N> á‹áŒáŒ…á‰¶á‰½ <M> á‰ áŒ…áŒáŒ…áŒ‹<L> á‹¨áˆ˜áŠ­áˆá‰» áˆµáŠáˆµáˆ­á‹ <K>á£ á‰ áŠ¨á‰°áˆá‰½ á‹¨áˆµáˆ« á‹•á‹µáˆ <J> áŠ¢áŠ•á‰°áˆ­á•áˆ«á‹­á‹á‰½ áˆáˆ›á‰µá£ <I> áˆáˆ›á‰µ áˆ›áŠ”áŒ…áˆ˜áŠ•á‰µá£ á‰ á‹˜áˆ­á‰ áŠ áŒ€áŠ•á‹³á‹á‰½ áˆ›áˆˆá‰µáˆ á‰ áŠ¨á‰°áˆ› áˆáˆ›á‰µá£ áŠ áˆ¨áŠ•áŒ“á‹´ áˆáˆ›á‰µáŠ“ áŠ áŠ«á‰£á‰¢ áŒ¥á‰ á‰ƒá£ á‰ á‰¤á‰¶á‰½áŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• áŠ¥áŠ•á‹²áˆáˆ á‰°á‹«á‹«á‹¥ á‹˜áˆ­áá‰½ á‹™áˆªá‹« áŒ¥áŠ“á‰³á‹Š á…áˆáá‰½ á‹­á‰€áˆ­á‰£áˆ‰á¢ áŠ á‰¶ áŠ«áˆ³áˆáŠ• áŠ¨á‰°áˆá‰½ áˆ«áˆ³á‰¸á‹áŠ• á‹¨áˆšá‹«áˆµá‰°á‹‹á‹á‰á‰ á‰µ áŠ¤áŒá‹šá‰¢áˆ½áŠ• á‹¨áˆšáŠ«áˆ„á‹µ áˆ²áˆ†áŠ• áŠ¨á‹šáˆ…<H> á‰ á‰°á‹°áˆ¨áŒ‰ ááˆ¨áˆá‰½ á‹¨á‰°áˆµá‰°á‹‹áˆˆá‹<G> áŠ áˆ˜á‰µ áŠ¥áŠ•á‹³á‹­áŠ–áˆ­ áŠ¨áŠ¨á‰°áˆá‰½ áŒ‹áˆ­ áˆ˜áŒá‰£á‰£á‰µ áˆ‹á‹­ á‰°á‹°áˆ­áˆ·áˆ á‰¥áˆˆá‹‹áˆá¢ áˆ€áˆ™áˆµ á‰  <F> áˆµáˆ­á‹“á‰µ áˆˆáˆá‹´áˆ áŠ¢áŠ•á‰°áˆ­á•áˆ«á‹­á‹á‰½ <E> áˆˆáˆ´á‰µ <D> áˆáŒ£áˆªá‹á‰½á£<C> áŠ­áˆáˆá‰½ áŠ«áˆ‰ á‹¨áˆ´áŠ­á‰°áˆ­ á‰°á‰‹áˆ›á‰µ á‰ áŠ áˆáƒá€áˆ á‰¥áˆáŒ« áˆ‹áŒˆáŠ™ áŠ¥áŠ•á‹²áˆáˆ áˆˆá‹©áŠ’á‰¨áˆ­áˆ²á‰² á‰°áˆ˜áˆ«á‰‚ áˆµáˆ« áˆáŒ£áˆªá‹á‰½ áŠ¥á‹á‰…áŠ“<B> áˆ½áˆáˆ›á‰µ á‹­áˆ°áŒ£áˆ <A> á‰ á‰°áˆ˜áˆ³áˆ³á‹­ <z>á‹˜áŒ áŠáŠ›á‹ á‹¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½<y> áŠ á‹˜áŒ‹áŒ… á‰ áŠ¥áˆˆá‰±<x> á‹­á‹°áˆ¨áŒ‹áˆá¤ á‹¨á‹‹áŠ•áŒ« áˆ­áŠ­áŠ­á‰¥áˆ á‹­áŠ–áˆ«áˆ á‰¥áˆˆá‹‹áˆ áˆšáŠ’áˆµá‰µáˆ­ <w> áˆµáˆáŠ•á‰°áŠ›á‹áŠ• á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ á‹¨á‰°áˆˆá‹¨ áˆˆáˆ›á‹µáˆ¨áŒ áŠ¨<v> áŠ áˆˆáˆáŠ á‰€á á‹¨áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áˆáˆá‹µ <u> â‡ áˆ á‹«áˆ‰á‰µ áŠ á‰¶ áŠ«áˆ³áˆáŠ• ááˆ¨áˆ™ áˆˆáˆ˜áŒ€áˆ˜áˆªá‹« áŒŠá‹œ á‰ á‰³á‹³áŒŠ áŠ­áˆáˆ áˆ˜áŠ«áˆ„á‹±áˆ áˆá‹©<t> á‰¥áˆˆá‹‹áˆá¢ á‹¨áˆ±áˆ›áˆŒ áŠ­áˆáˆ áŠ¨á‰°áˆ› áˆáˆ›á‰µáŠ“ áŠ®áŠ•áˆµá‰µáˆ«áŠ­áˆ½áŠ• á‰¢áˆ® áˆ€áˆ‹áŠ á‹¶ <s>áˆ­ á‰ á‰ áŠ©áˆ‹á‰¸á‹ áŠ­áˆáˆ‰ ááˆ¨áˆ™áŠ• áˆˆáˆ›áˆµá‰°áŠ“áŒˆá‹µ á‹áŒáŒ…á‰±áŠ• áŠ áŒ áŠ“á‰‹áˆá¤ á‰°áˆ³á‰³áŠ áŠ¨á‰°áˆá‰½áˆ á‹ˆá‹° áŒ…áŒáŒ…áŒ‹ áŠ¥á‹¨áŒˆá‰¡ <r> á‰¥áˆˆá‹‹áˆá¢ á‰¢áˆ® áˆ€áˆ‹áŠá‹ á‰ áŒ¥á‰‚á‰µ áŒáˆˆáˆ°á‰¦á‰½ <q> á‰ áŠá‰µ á‰°áŠ¨áˆµá‰¶ á‹¨áŠá‰ áˆ¨á‹ á‰½áŒáˆ­ áŒˆá…á‰³á‰½áŠ•áŠ• áŠ á‰ áˆ‹áˆ½á‰¶ á‹¨áŠá‰ áˆ¨ á‰¢áˆ†áŠ•áˆ áŠ áˆáŠ• áŒáŠ• áˆáŠ•áˆ á‹¨á€áŒ¥á‰³áˆ á‹­áˆáŠ• á‹¨á‹°áˆ…áŠ•áŠá‰µ á‰½áŒáˆ­ á‹¨áˆˆáˆ á‰¥áˆˆá‹‹áˆá¢ á‹¶/áˆ­ áŠ á‰¥á‹±áˆáˆá‰³áˆ… áˆµáˆáŠ•á‰°áŠ›á‹ á‹¨áŠ¨á‰°áˆá‰½ <p> á‹¨áŠ­áˆáˆ‹á‰½áŠ•áŠ• á‰¥áˆáˆ á‹¨áŠ¨á‰°áˆ›á‰½áŠ•<o> áŠ áˆµá‰°áˆ›áˆ›áŠ áˆ°áˆ‹áˆ á‹¨áˆáŠ“áˆ¨áŒ‹áŒáŒ¥á‰ á‰µáŠ“ á‰ á‰°áŒá‰£áˆ­áˆ á‹¨áˆáŠ“áˆ³á‹­á‰ á‰µ áŠ¥áŠ•á‹²áˆ†áŠ• áˆ°áŠ áˆµáˆ« áˆ°áˆ­á‰°áŠ“áˆ á‹áŒ¤á‰±áŠ•áˆ áŠ¥á‹«á‹¨áŠ• áŠá‹ á‰¥áˆˆá‹‹áˆá¢ áˆµáˆáŠ•á‰°áŠ›á‹ á‹¨áŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½ ááˆ¨áˆ áŠ¨á‹¨áŠ«á‰²á‰µ 9-14/2011 ''áˆ˜á‹°áˆ˜áˆ­ áˆˆáŠ¢á‰µá‹®áŒµá‹« áŠ¨á‰°áˆá‰½ á‰¥áˆá…áŒáŠ“'' á‰ áˆšáˆ áˆ˜áˆª á‰ƒáˆ á‰ áŒ…áŒáŒ…áŒ‹ á‹­áŠ«áˆ„á‹³áˆá¢ áˆáŠ•áŒ­á¦\n","\n","Targets: \n","\n"," <Z>áŒ…áŒáŒ…áŒ‹!<Y>áŠ•<X> áˆ˜áŒ áŠ“á‰€á‰áŠ• <W> áŠ áˆˆáˆ˜áŠ–áˆ©áŠ• <V> áˆáˆ›á‰µ<U> áˆšáŠ’áˆµá‰µáˆ­ <T> áŠ«áˆ³áˆáŠ•<S> á‰°áŠ“áŒˆáˆ©á¢ <R> áˆ˜áŒáˆˆáŒ«<Q> áŒ‹áˆ­ <P> á‰ á‰…áŠ•áŒ…á‰µ<O> áŠá‹ á‰¥áˆˆá‹‹áˆá¢ á‰ áŠ¨á‰°áˆ›á‹‹<N> áŠ¨áˆšáŠ–áˆ© <M> áˆ˜áŠ«áŠ¨áˆ<L> áˆµá‰´á‹²á‹¨áˆ <K>á‰µ <J> áˆáŒ áˆ« <I> á‰ áˆ˜áˆ¬á‰µ<H> á‰ áŠá‰µ<G> á‹¨á‹µáˆá… á‰¥áŠ­áˆˆá‰µ á‰ á‹šáˆ… <F>áˆšáŠ–áˆ¨á‹ á‹¨áˆ›áŒ á‰ƒáˆˆá‹« <E>á£ <D> áˆµáˆ«<C> á‰ áˆáˆ‰áˆ<B>áŠ“ <A> á‰°á‰¥áˆáˆá¢ <z> á‹¨<y> ááˆ¨áˆ<x> á‹­á‹ <w> á‹´áŠ¤á‰³á‹á¢<v>áˆ›áˆŒá‹¥á‹« <u> á‰°á‹ˆáˆµ<t> á‹«á‹°áˆ­áŒˆá‹‹áˆ <s>/ <r> áŠá‹ <q> áŠ¨á‹ˆáˆ«á‰µ <p> ááˆ¨áˆ<o>áŠ•\n"]}],"source":["print('Inputs: \\n\\n', pretty_decode(inps_sample, sentinels, tokenizer))\n","print('\\nTargets: \\n\\n', pretty_decode(targs_sample, sentinels, tokenizer))"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1740035023069,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"a5r_mmJK7acQ","outputId":"05ef5ea0-2d1a-4717-90e8-9ca9df68fa0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆáˆ›áŒˆá‹ á‰¥áˆáŠ­áˆ­ áŠ¥áˆ­áˆµá‹ á‹¨áˆ˜á…áˆ€á á‰…á‹±áˆ± á‹¨á‹³á‹Šá‰µ áŠ¦áˆ®á‹®áŠ•áŠ• áˆ˜áŠ•áŒˆá‹µ á‰ áˆ˜áˆáˆ¨áŒ¥á‹ á‰ á‹­á‹ áˆˆáˆ˜áƒá á‰°áŒˆá‹µáŒƒáˆˆáˆ áŠ áˆáŠ•áˆ áˆ˜áˆ¨áŒƒá‹ áŠ¥áŠ•á‹´á‰µ áŠ¥áˆ± áŒ‹áˆ­ á‹°áˆ¨áˆ° á‹¨áˆšáˆˆá‹áŠ• á‹á‰µá‹ˆá‰³ á‰µá‰°á‹ á‰ áˆ›áŠ•áŠ›á‹áˆ áˆ˜áŠ•áŒˆá‹µ á‰€áŒ¥á‰°áŠ› áˆáˆ‹áˆ½ á‹­áˆµáŒ¡áŠ áŠ¨áˆ˜áˆµáŠ¨áˆ¨áˆ á‹ˆá‹²á‹« áŠ áˆáŠ• á‹«áˆˆáˆ áˆ˜áŠ•áŒáˆµá‰µ áˆ…áŒ‹á‹Š á‹¨áˆµáˆ« á‹˜áˆ˜áŠ‘ áˆµáˆˆáˆšá‹«á‰ á‰ƒ á‹¨á‰£áˆˆáŠ á‹°áˆ« áˆ˜áŠ•áŒáˆµá‰µ áŠ¥áŠ•á‹²á‰‹á‰‹áˆ áˆ†áŠ–áˆ áŠ áˆáŠ• á‹«áˆˆá‹ á‹¨áŠ á‰¥á‹­ áˆ˜áŠ•áŒáˆµá‰µ áŠ áˆµáˆáƒáˆš áŠ áŠ«áˆ á‹¨áˆ˜áŠ•áŒáˆµá‰µáŠ• á‹¨áŠ¥áˆˆ á‰°áŠ¥áˆˆá‰µ á‰°áŒá‰£áˆ«á‰µáŠ• áŠ¥á‹¨áŠ¨á‹ˆáŠ áˆáˆ­áŒ« áŠ¥áˆµáŠªá‹°áˆ¨áŒ áˆˆ áŠ áˆ˜á‰µ áŠ¥áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨áŒ á‰ áˆ˜áŒáˆˆáŒ«á‹ áŒ á‹­á‰€á‹‹áˆ á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨áŠ¥á‹á‰€á‰µ áŒá‹³áŠ“ áŠ á‹­áŠ‘ á‹«áˆ‹á‹¨á‹ áŒ†áˆ®á‹ á‹«áˆáˆ°áˆ›á‹ áˆá‰¡ á‹«áˆ‹áˆ°á‰ á‹ áŠ¥á‹á‰€á‰µáŠ“ á‰¥áˆáˆ€á‰µ á‹¨áˆˆáˆáŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆáŠ­ á‰ áˆ˜áˆáŠ© áˆ²á‰€á‹³á‰ á‰µ á‹¨áŠ–áˆ¨ áŠ¨áŠ¢á‰µá‹®áŒµá‹« áŠ áˆá áˆˆáŠ áˆˆáˆ áˆ²á‰³á‹°áˆ á‹¨áŠ–áˆ¨á‹áŠ“ á‹¨áˆšáŠ–áˆ¨á‹ áŠ¥á‹á‰€á‰µ á‹¨á‰°áŒˆáŠ˜á‰ á‰µ á‰³áˆ‹á‰… áŠáŒˆá‹µ áŠá‹ á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ« áˆ…á‹á‰¥ áˆ‹á‹­ á‰¥á‰» áŠá‹áˆŒáˆ‹á‹ á‹¨á‰µáˆ…áŠáŒáŠ• á‰£áŠ•á‹²áˆ« áˆˆá‰¥áˆ¶á‹¨áŠ¦áŠáŒáŠ• á‰£áŠ•á‹²áˆ« áŠ¥á‹«á‹áˆˆá‰ áˆˆá‰  á‹¨áŠ¢á‰µá‹®áŒµá‹«áŠ• áˆ°áŠ•á‹°á‰…áŠ áˆ‹áˆ› á‰ áŠ¥áŒáˆ© áˆ¨áŒáŒ¦á‰³áˆáŒ¨áˆ­á‰… áŠá‹ á‰¥áˆˆá‹ áŠ á‰ƒáŒ¥áˆˆá‹á‰³áˆá‰€á‹³á‹°á‹ áŒ¥áˆˆá‹á‰³áˆ'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":43}],"source":["tokenizer.detokenize(tokenizer.tokenize(\"áŠ áˆµá‰€á‹µáˆœ áŒ¥á‹«á‰„á‹¬ á‰ áŒ¨á‹‹áŠá‰µ á‰ á‹áˆµáŒ¥ áˆ˜áˆµáˆ˜áˆ­ áŠ¥áŠ•á‹²á‹°áˆ­áˆµá‹ áŠ á‹µáˆ­áŒŒ áá‰µáˆ…áŠ• áˆˆáˆ›áŒˆá‹ á‰¥áˆáŠ­áˆ­  áŠ¥áˆ­áˆµá‹ á‹¨áˆ˜á…áˆ€á á‰…á‹±áˆ± á‹¨á‹³á‹Šá‰µ  áŠ¦áˆ®á‹®áŠ•áŠ• áˆ˜áŠ•áŒˆá‹µ á‰ áˆ˜áˆáˆ¨áŒ¥á‹ á‰ á‹­á‹ áˆˆáˆ˜áƒá á‰°áŒˆá‹µáŒƒáˆˆáˆ  áŠ áˆáŠ•áˆ áˆ˜áˆ¨áŒƒá‹ áŠ¥áŠ•á‹´á‰µ áŠ¥áˆ± áŒ‹áˆ­ á‹°áˆ¨áˆ° á‹¨áˆšáˆˆá‹áŠ• á‹á‰µá‹ˆá‰³ á‰µá‰°á‹ á‰ áˆ›áŠ•áŠ›á‹áˆ áˆ˜áŠ•áŒˆá‹µ á‰€áŒ¥á‰°áŠ› áˆáˆ‹áˆ½ á‹­áˆµáŒ¡áŠ   áŠ¨áˆ˜áˆµáŠ¨áˆ¨áˆ   á‹ˆá‹²á‹« áŠ áˆáŠ• á‹«áˆˆáˆ áˆ˜áŠ•áŒáˆµá‰µ áˆ…áŒ‹á‹Š á‹¨áˆµáˆ« á‹˜áˆ˜áŠ‘ áˆµáˆˆáˆšá‹«á‰ á‰ƒ á‹¨á‰£áˆˆáŠ á‹°áˆ« áˆ˜áŠ•áŒáˆµá‰µ áŠ¥áŠ•á‹²á‰‹á‰‹áˆ áˆ†áŠ–áˆ áŠ áˆáŠ• á‹«áˆˆá‹ á‹¨áŠ á‰¥á‹­ áˆ˜áŠ•áŒáˆµá‰µ áŠ áˆµáˆáƒáˆš áŠ áŠ«áˆ á‹¨áˆ˜áŠ•áŒáˆµá‰µáŠ• á‹¨áŠ¥áˆˆ á‰°áŠ¥áˆˆá‰µ á‰°áŒá‰£áˆ«á‰µáŠ• áŠ¥á‹¨áŠ¨á‹ˆáŠ áˆáˆ­áŒ« áŠ¥áˆµáŠªá‹°áˆ¨áŒ áˆˆ áŠ áˆ˜á‰µ áŠ¥áŠ¥áŠá‹šáˆ…áŠ• á‹ˆáˆ³áŠ áŒ‰á‹³á‹®á‰½áŠ• á‹¨áˆšá‹«áˆµáˆá…áˆ áŠ áŠ«áˆ áŠ¥áŠ•á‹²á‰‹á‰‹áˆáŠ“ áŠ­á‰µá‰µáˆ áŠ¥áŠ•á‹²á‹°áˆ¨áŒ á‰ áˆ˜áŒáˆˆáŒ«á‹ áŒ á‹­á‰€á‹‹áˆ á‹¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‰ áŠ áŠ¥áˆáˆ® áŠ­áŠ•á‰ á‹«áˆá‰ áˆ¨áˆ¨á‰ á‰µ áŒ¥á‰ á‰¥áŠ“ ááˆáˆµááŠ“ á‹«áˆáŠ¨áˆá‰°á‹ á‹¨áŠ¥á‹á‰€á‰µ áŒá‹³áŠ“ áŠ á‹­áŠ‘ á‹«áˆ‹á‹¨á‹ áŒ†áˆ®á‹ á‹«áˆáˆ°áˆ›á‹ áˆá‰¡ á‹«áˆ‹áˆ°á‰ á‹ áŠ¥á‹á‰€á‰µáŠ“ á‰¥áˆáˆ€á‰µ á‹¨áˆˆáˆáŠ¨áŠ áˆ›áˆ« áˆ…á‹á‰¥ á‹¨áˆ€áŒˆáˆªá‰± á‹˜áˆ­áˆ á‰¥á‹™ áŠ¥á‹á‰€á‰µ áˆ˜áŠ•áŒ­á‰¶ á‹¨áˆáˆ‹á‰ á‰µáŠ¨áˆ™áˆ‹á‰±áˆ á‰ áˆ˜áˆáŠ­ á‰ áˆ˜áˆáŠ© áˆ²á‰€á‹³á‰ á‰µ á‹¨áŠ–áˆ¨ áŠ¨áŠ¢á‰µá‹®áŒµá‹« áŠ áˆá áˆˆáŠ áˆˆáˆ áˆ²á‰³á‹°áˆ á‹¨áŠ–áˆ¨á‹áŠ“ á‹¨áˆšáŠ–áˆ¨á‹ áŠ¥á‹á‰€á‰µ á‹¨á‰°áŒˆáŠ˜á‰ á‰µ á‰³áˆ‹á‰… áŠáŒˆá‹µ áŠá‹ á‹›áˆ¬ á‰ á‹¨á‰µáŠ›á‹áˆ áˆ˜áˆˆáŠªá‹« á‹­áˆáŠ• áˆ˜áˆ˜á‹˜áŠ› áŠ¢á‰µá‹®áŒµá‹«á‹ŠáŠá‰µ á‹¨áˆšáŠ•á€á‰£áˆ¨á‰€á‹ á‰ áŠ áˆ›áˆ« áˆ…á‹á‰¥ áˆ‹á‹­ á‰¥á‰» áŠá‹áˆŒáˆ‹á‹ á‹¨á‰µáˆ…áŠáŒáŠ• á‰£áŠ•á‹²áˆ« áˆˆá‰¥áˆ¶á‹¨áŠ¦áŠáŒáŠ• á‰£áŠ•á‹²áˆ« áŠ¥á‹«á‹áˆˆá‰ áˆˆá‰  á‹¨áŠ¢á‰µá‹®áŒµá‹«áŠ• áˆ°áŠ•á‹°á‰…áŠ áˆ‹áˆ› á‰ áŠ¥áŒáˆ© áˆ¨áŒáŒ¦á‰³áˆáŒ¨áˆ­á‰… áŠá‹ á‰¥áˆˆá‹ áŠ á‰ƒáŒ¥áˆˆá‹á‰³áˆá‰€á‹³á‹°á‹ áŒ¥áˆˆá‹á‰³áˆ\"))"]},{"cell_type":"markdown","metadata":{"id":"J41nwVdk7acQ"},"source":["### 3.5 Creating the training data pairs"]},{"cell_type":"markdown","metadata":{"id":"SFUzcFJ57acQ"},"source":["Now I will create pairs using the cleaned_data by iterating over the data and create(inp,targ) pairs using the function I defined above"]},{"cell_type":"markdown","metadata":{"id":"vPlnzop57acQ"},"source":["After completing data preprocessing and defining the dataset, I encountered an issue while training the model: the maximum sequence length is around 1300 tokens, causing the model to run out of memory and crash. This happens because transformer models, when trained using a masked language model (MLM) objective, have quadratic complexity (O(nÂ²)) concerning sequence length, leading to excessive memory usage for long sequences. To resolve this issue, we need to reduce the size of the input sequences by spliting a single news into multiple small news(max_size words per news). this process will reduce the size of each news but will increase the number of training datas as we split single data into multiple datas"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3767,"status":"ok","timestamp":1740035026837,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"bfruxYzd7acR","outputId":"614c73c6-00f9-4ed8-c12a-28f160829a54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of contents before reduced: 193419\n","Number of contents after reduced: 408671\n","maximum size before reduced: 836\n","maximum size after reduced: 50\n"]}],"source":["\n","max_size=50\n","\n","def reduce_size(data, max_size):\n","    for element in data:  # Loop over each sub-array in the main array\n","        sub_array = element.split()\n","        for i in range(0, len(sub_array), max_size):  # Split each sub-array into chunks\n","            yield  ' '.join(sub_array[i:i + max_size])\n","\n","cleaned_data_reduced=list(reduce_size(cleaned_data,max_size))\n","print(f'Number of contents before reduced: {len(cleaned_data)}')\n","print(f'Number of contents after reduced: {len(cleaned_data_reduced)}')\n","print(f\"maximum size before reduced: {max([len(content.split()) for content in cleaned_data])}\")\n","print(f\"maximum size after reduced: {max([len(content.split()) for content in cleaned_data_reduced])}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lMKC0tKR7acR"},"source":["let us see sample the news before and after reducing"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1740035026842,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"gl-MLanN7acR","outputId":"d7d5dfa6-dd52-4ca2-e032-359343af5820"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data before reduced: \n","\n"," áˆ°á‹áŠ• áˆˆáˆ˜áˆ­á‹³á‰µ áˆ°á‹ áˆ˜áˆ†áŠ• á‰ á‰‚ áŠá‹ ! á‰µáˆ‹áŠ•á‰µ á‹¨áŠ«á‰²á‰µ 1/2017 á‹“/áˆ á‰ áŒ€áˆ˜áˆ¨á‹ á‹¨áˆ˜á‰„á‹¶áŠ•á‹« á‹¨áŠ áˆ¨áŒ‹á‹Šá‹«áŠ• áŠ¥áŠ“ á‹¨áŠ áŠ¥áˆáˆ® áˆ…áˆ™áˆ›áŠ• áˆ˜áˆ­áŒƒ áˆ›á‹•áŠ¨áˆ á‹¨á‹µáŒ‹á áˆ›áˆ°á‰£áˆ°á‰¥ á‹˜áˆ˜á‰» áŠ¥áˆµáŠ©áŠ• 120,000,000 á‰¥áˆ­ á‰°áˆ°á‰¥áˆµá‰§áˆá¢ áˆ˜á‰„á‹¶áŠ•á‹« á‰ áˆšá‹«áˆµáŒˆáŠá‰£á‹ áˆ†áˆµá’á‰³áˆ áŒ­áˆáˆ­ á‹«áˆˆá‹ áˆ…áŠ•áƒ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹¨áŒˆáŠ•á‹˜á‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŠ áŒ‹áŒ¥áˆá‰³áˆá¢ áˆ…áŠ•áƒá‹ áˆˆáˆ›áŒ áŠ“á‰€á‰… áŒˆáŠ•á‹˜á‰¥ á‰°á‰¸áŒáˆ¨áŠ“áˆá¢ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹ˆá‹° 5 á‰¢áˆŠá‹®áŠ• á‰¥áˆ­ á‹«áˆµáˆáˆáŒ‹áˆá¢ á‰ á‰€áŒ¥á‰³ á‹­áŠ¨á‰³á‰°áˆ‰ á‹¨áˆá‰µá‰½áˆ‰á‰µáŠ• áˆáˆ‰ á‹µáŒ‹á áŠ á‹µáˆ­áŒ‰á¢\n","\n","---------------------------------------------------------------------------------\n","\n","\n","Data after reduced: \n","\n"," áˆ°á‹áŠ• áˆˆáˆ˜áˆ­á‹³á‰µ áˆ°á‹ áˆ˜áˆ†áŠ• á‰ á‰‚ áŠá‹ ! á‰µáˆ‹áŠ•á‰µ á‹¨áŠ«á‰²á‰µ 1/2017 á‹“/áˆ á‰ áŒ€áˆ˜áˆ¨á‹ á‹¨áˆ˜á‰„á‹¶áŠ•á‹« á‹¨áŠ áˆ¨áŒ‹á‹Šá‹«áŠ• áŠ¥áŠ“ á‹¨áŠ áŠ¥áˆáˆ® áˆ…áˆ™áˆ›áŠ• áˆ˜áˆ­áŒƒ áˆ›á‹•áŠ¨áˆ á‹¨á‹µáŒ‹á áˆ›áˆ°á‰£áˆ°á‰¥ á‹˜áˆ˜á‰» áŠ¥áˆµáŠ©áŠ• 120,000,000 á‰¥áˆ­ á‰°áˆ°á‰¥áˆµá‰§áˆá¢ áˆ˜á‰„á‹¶áŠ•á‹« á‰ áˆšá‹«áˆµáŒˆáŠá‰£á‹ áˆ†áˆµá’á‰³áˆ áŒ­áˆáˆ­ á‹«áˆˆá‹ áˆ…áŠ•áƒ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹¨áŒˆáŠ•á‹˜á‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŠ áŒ‹áŒ¥áˆá‰³áˆá¢ áˆ…áŠ•áƒá‹ áˆˆáˆ›áŒ áŠ“á‰€á‰… áŒˆáŠ•á‹˜á‰¥ á‰°á‰¸áŒáˆ¨áŠ“áˆá¢ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹ˆá‹° 5 á‰¢áˆŠá‹®áŠ• á‰¥áˆ­ á‹«áˆµáˆáˆáŒ‹áˆá¢ á‰ á‰€áŒ¥á‰³ á‹­áŠ¨á‰³á‰°áˆ‰ á‹¨áˆá‰µá‰½áˆ‰á‰µáŠ• áˆáˆ‰\n","\n","---------------------------------------------------------------------------------\n","\n","\n","Data after reduced: \n","\n"," á‹µáŒ‹á áŠ á‹µáˆ­áŒ‰á¢\n"]}],"source":["print(\"Data before reduced: \\n\\n\", cleaned_data[0])\n","print(\"\\n---------------------------------------------------------------------------------\\n\\n\")\n","print(\"Data after reduced: \\n\\n\", cleaned_data_reduced[0])\n","print(\"\\n---------------------------------------------------------------------------------\\n\\n\")\n","print(\"Data after reduced: \\n\\n\", cleaned_data_reduced[1])"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"hSOkpwGH7acR","executionInfo":{"status":"ok","timestamp":1740035104960,"user_tz":-180,"elapsed":78115,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"}}},"outputs":[],"source":["inputs_targets_pairs=[tokenize_and_mask(text.encode('utf-8', errors=\"ignore\").decode('utf-8'),tokenizer=tokenizer) for text in cleaned_data_reduced]\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srnYBE5h7acR","executionInfo":{"status":"ok","timestamp":1740035104978,"user_tz":-180,"elapsed":15,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"}},"outputId":"9cb27824-19f0-4476-b208-608d582dcfc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs: \n","\n"," áˆ°á‹<Z> áˆˆáˆ˜áˆ­á‹³á‰µ áˆ°á‹ áˆ˜áˆ†áŠ• á‰ á‰‚ áŠá‹ ! á‰µáˆ‹áŠ•á‰µ á‹¨áŠ«á‰²á‰µ<Y> á‹“/áˆ á‰ áŒ€áˆ˜áˆ¨á‹ á‹¨áˆ˜á‰„á‹¶áŠ•á‹« á‹¨áŠ áˆ¨áŒ‹á‹Šá‹«áŠ• áŠ¥áŠ“ á‹¨áŠ áŠ¥áˆáˆ® áˆ…áˆ™áˆ›áŠ• áˆ˜áˆ­áŒƒ áˆ›á‹•áŠ¨áˆ á‹¨á‹µáŒ‹á áˆ›áˆ°á‰£áˆ°á‰¥ á‹˜áˆ˜á‰» áŠ¥áˆµ<X>20,000,000 <W> á‰°áˆ°á‰¥áˆµá‰§áˆá¢ áˆ˜á‰„á‹¶áŠ•á‹« á‰ áˆšá‹«áˆµáŒˆáŠá‰£á‹ áˆ†áˆµá’á‰³áˆ áŒ­áˆáˆ­ <V> áˆ…áŠ•áƒ áˆˆáˆ›áŒ áŠ“á‰€á‰… á‹¨áŒˆáŠ•á‹˜á‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŠ áŒ‹áŒ¥áˆá‰³áˆá¢ áˆ…áŠ•áƒá‹ áˆˆáˆ›áŒ áŠ“á‰€á‰… áŒˆáŠ•á‹˜á‰¥ á‰°á‰¸áŒáˆ¨áŠ“áˆá¢ áˆˆáˆ›áŒ áŠ“á‰€á‰…<U> 5 á‰¢áˆŠá‹®áŠ• á‰¥áˆ­ á‹«áˆµáˆáˆáŒ‹áˆá¢ á‰ á‰€áŒ¥á‰³ á‹­áŠ¨á‰³á‰°áˆ‰ á‹¨áˆá‰µá‰½áˆ‰á‰µáŠ• áˆáˆ‰\n","\n","Targets: \n","\n"," <Z>áŠ•<Y> 1/2017<X>áŠ©áŠ• 1 <W> á‰¥áˆ­ <V> á‹«áˆˆá‹<U> á‹ˆá‹°\n","\n","---------------------------------------------------------------------------------\n","\n","\n","Inputs: \n","\n"," á‹µáŒ‹á<Z>\n","\n","Targets: \n","\n"," <Z> áŠ á‹µáˆ­áŒ‰á¢\n","\n","---------------------------------------------------------------------------------\n","\n","\n"]}],"source":["for pairs in inputs_targets_pairs[:2]:\n","    print('Inputs: \\n\\n', pretty_decode(pairs[0], sentinels, tokenizer))\n","    print('\\nTargets: \\n\\n', pretty_decode(pairs[1], sentinels, tokenizer))\n","    print(\"\\n---------------------------------------------------------------------------------\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"7KYu_VIY7acR"},"source":["Let's split the data into training and validation datasets."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ET8oqY97acR","executionInfo":{"status":"ok","timestamp":1740035104981,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"}},"outputId":"75112e6f-12a0-48db-fb47-c69dc36a6573"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of inputs and targets pairs:  408671\n","Training data size: 326936\n","Validation data size: 81735\n"]}],"source":["print(\"Total number of inputs and targets pairs: \",len(inputs_targets_pairs))\n","training_size=int(len(inputs_targets_pairs)*0.8)\n","training_data=inputs_targets_pairs[:training_size]\n","validation_data=inputs_targets_pairs[training_size:]\n","print(f\"Training data size: {len(training_data)}\")\n","print(f\"Validation data size: {len(validation_data)}\")"]},{"cell_type":"markdown","metadata":{"id":"yrQSiZ0A7acR"},"source":["For training a Tensorflow model we need to arrange the data into datasets. Now, I will get the `inputs` and the `targets` for the transformer model from the `training_data and validation_data`. Before creating the dataset, I need to be sure that all `inputs` have the same length by truncating the longer sequences and padding the shorter ones with `0`. The same must be done for the targets. The function `tf.keras.preprocessing.sequence.pad_sequences` will help us here."]},{"cell_type":"code","execution_count":49,"metadata":{"id":"davLEf4n7acR","executionInfo":{"status":"ok","timestamp":1740035108144,"user_tz":-180,"elapsed":3161,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"}}},"outputs":[],"source":["training_data_inputs_padded=tf.keras.utils.pad_sequences(\n","    [pairs[0] for pairs in training_data],\n","    maxlen=None,\n","    dtype='int32',\n","    padding='post',\n","    truncating='post',\n",")\n","training_data_targets_padded=tf.keras.utils.pad_sequences(\n","    [pairs[1] for pairs in training_data],\n","    maxlen=None,\n","    dtype='int32',\n","    padding='post',\n","    truncating='post',\n",")\n","\n","validation_data_inputs_padded=tf.keras.utils.pad_sequences(\n","    [pairs[0] for pairs in validation_data],\n","    maxlen=None,\n","    dtype='int32',\n","    padding='post',\n","    truncating='post',\n",")\n","\n","validation_data_targets_padded=tf.keras.utils.pad_sequences(\n","    [pairs[1] for pairs in validation_data],\n","    maxlen=None,\n","    dtype='int32',\n","    padding='post',\n","    truncating='post',\n",")\n","BUFFER_SIZE = 12000\n","BATCH_SIZE = 64\n","training_dataset_final=tf.data.Dataset.from_tensor_slices((training_data_inputs_padded,training_data_targets_padded))\n","validation_dataset_final=tf.data.Dataset.from_tensor_slices((validation_data_inputs_padded,validation_data_targets_padded))\n","training_dataset_final=training_dataset_final.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).cache()\n","validation_dataset_final=validation_dataset_final.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).cache()\n","\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dg1261Ko7acR","executionInfo":{"status":"ok","timestamp":1740035108151,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"}},"outputId":"b489b777-5760-4c8b-9d42-c8669047dcbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["maximum size of training data inputs: 204\n","maximum size of training data targets: 61\n","maximum size of validation data inputs: 138\n","maximum size of validation data targets: 50\n","seems good size for small memory devices\n"]}],"source":["print(f'maximum size of training data inputs: {training_data_inputs_padded.shape[1]}')\n","print(f'maximum size of training data targets: {training_data_targets_padded.shape[1]}')\n","print(f'maximum size of validation data inputs: {validation_data_inputs_padded.shape[1]}')\n","print(f'maximum size of validation data targets: {validation_data_targets_padded.shape[1]}')\n","print(\"seems good size for small memory devices\")"]},{"cell_type":"markdown","metadata":{"id":"wmPdD5eO7acR"},"source":["Let's Tokenize both the training and validation sets using our tokenizer"]},{"cell_type":"markdown","metadata":{"id":"wMHllZ0V7acR"},"source":["## 4. Pretraining the Transformer Model"]},{"cell_type":"markdown","metadata":{"id":"Nw342CHY7acR"},"source":["Now I am going to define the structure of the transformer network and pretrain it on the dataset given above. The general structure of the transformer model we will build is shown in the figure below"]},{"cell_type":"markdown","metadata":{"id":"MEDVTSl17acR"},"source":["<center> <img src = \"images/fulltransformer.png\" width=\"500\" height=\"600\"></center>"]},{"cell_type":"markdown","metadata":{"id":"JYu2cyi97acR"},"source":["## Positional Encoding\n","\n","As you can see in the figure, the input embeddings are added with positional embedding vectors to capture the position of words in a sentence. The following function creates positional encoding given the embedding vectors.\n","\n","In sequence-to-sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model. However, when you train a Transformer network using multi-head attention, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:\n","\n","$$\n","PE_{(pos, 2i)}= sin\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n","$$\n","\n","$$\n","PE_{(pos, 2i+1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n","$$\n","\n","Where:\n","\n","*   `d` is the dimension of the word embedding and positional encoding.\n","*   `pos` is the position of the word.\n","*   `i` refers to each of the different dimensions in the positional encodings, where `i = k // 2`.\n","\n","To develop some intuition about positional encodings, you can think of them broadly as a feature that contains the information about the relative positions of words. The sum of the positional encoding and word embedding is ultimately what is fed into the model.  If you just hard code the positions in, say by adding a matrix of 1's or whole numbers to the word embedding, the semantic meaning is distorted. Conversely, the values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted, and is instead enriched with positional information. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data.\n","\n","### Sine and Cosine Angles\n","\n","Notice that even though the sine and cosine positional encoding equations take in different arguments (`2i` versus `2i+1`, or even versus odd numbers) the inner terms for both equations are the same:\n","\n","$$\\theta(pos, i, d) = \\frac{pos}{10000^{\\frac{2i}{d}}}$$\n","\n","Consider the inner term as you calculate the positional encoding for a word in a sequence:\n","\n","$PE_{(pos, 0)}= sin\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i = 0` gives `i = 0`\n","\n","$PE_{(pos, 1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i + 1 = 1` gives `i = 0`\n","\n","The angle is the same for both! The angles for $PE_{(pos, 2)}$ and $PE_{(pos, 3)}$ are the same as well, since for both, `i = 1` and therefore the inner term is $\\left(\\frac{pos}{{10000}^{\\frac{2}{d}}}\\right)$. This relationship holds true for all paired sine and cosine curves:\n","\n","| k             | 0                         | 1                         | 2                         | 3                         | ... | d - 2                     | d - 1                     |\n","| ------------- | ------------------------- | ------------------------- | ------------------------- | ------------------------- | --- | ------------------------- | ------------------------- |\n","| encoding(0) = | [sin(Î¸(0, 0, d))         | cos(Î¸(0, 0, d))         | sin(Î¸(0, 1, d))         | cos(Î¸(0, 1, d))         | ... | sin(Î¸(0, d//2, d))        | cos(Î¸(0, d//2, d))        |\n","| encoding(1) = | [sin(Î¸(1, 0, d))         | cos(Î¸(1, 0, d))         | sin(Î¸(1, 1, d))         | cos(Î¸(1, 1, d))         | ... | sin(Î¸(1, d//2, d))        | cos(Î¸(1, d//2, d))        |\n","| ...           | ...                       | ...                       | ...                       | ...                       | ... | ...                       | ...                       |\n","| encoding(pos) =| [sin(Î¸(pos, 0, d))        | cos(Î¸(pos, 0, d))        | sin(Î¸(pos, 1, d))        | cos(Î¸(pos, 1, d))        | ... | sin(Î¸(pos, d//2, d))       | cos(Î¸(pos, d//2, d))]      |\n"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1740035136100,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"QwnBDKMx7acS"},"outputs":[],"source":["def positional_encoding(positions, d_model):\n","    \"\"\"\n","    Precomputes a matrix with all the positional encodings\n","\n","    Arguments:\n","        positions (int): Maximum number of positions to be encoded\n","        d_model (int): Encoding size\n","\n","    Returns:\n","        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n","    \"\"\"\n","\n","    position = np.arange(positions)[:, np.newaxis]\n","    k = np.arange(d_model)[np.newaxis, :]\n","    i = k // 2\n","\n","    # initialize a matrix angle_rads of all the angles\n","    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n","    angle_rads = position * angle_rates\n","\n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"2Diy1iuS7acS"},"source":["## 4.2 Masking"]},{"cell_type":"markdown","metadata":{"id":"NyojAbjZ7acS"},"source":["The masking we will define here is different from the masking we used while preparing the data for Masked Language modeling.\n","\n","\n","There are two types of masks that are useful when building your Transformer network: the *padding mask* and the *look-ahead mask*. Both help the softmax computation give the appropriate weights to the words in your input sentence.\n","\n","### 1.1 - Padding Mask\n","\n","Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let's say the maximum length of your model is five, it is fed the following sequences:\n","\n","    [[\"Do\", \"you\", \"know\", \"when\", \"Jane\", \"is\", \"going\", \"to\", \"visit\", \"Africa\"],\n","     [\"Jane\", \"visits\", \"Africa\", \"in\", \"September\" ],\n","     [\"Exciting\", \"!\"]\n","    ]\n","\n","which might get vectorized as:\n","\n","    [[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],\n","     [ 56, 1285, 15, 181, 545],\n","     [ 87, 600]\n","    ]\n","    \n","When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:\n","\n","    [[ 71, 121, 4, 56, 99],\n","     [ 2344, 345, 1284, 15, 0],\n","     [ 56, 1285, 15, 181, 545],\n","     [ 87, 600, 0, 0, 0],\n","    ]\n","    \n","Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length. Similarly, for sequences shorter than the maximum length, zeros will also be added for padding.\n","\n","When pasing these vectors through the attention layers, the zeros will typically disappear  (you will get completely new vectors given the mathematical operations that happen in the attention block). However, you still want the network to attend only to the first few numbers in that vector (given by the sentence length) and this is when a padding mask comes in handy. You will need to define a boolean mask that specifies to which elements you must attend (1) and which elements you must ignore (0) and you do this by looking at all the zeros in the sequence. Then you use the mask to set the values of the vectors (corresponding to the zeros in the initial vector) close to negative infinity (-1e9).\n","\n","Imagine your input vector is `[87, 600, 0, 0, 0]`. This would give you a mask of `[1, 1, 0, 0, 0]`. When your vector passes through the attention mechanism, you get another (randomly looking) vector, let's say `[1, 2, 3, 4, 5]`, which after masking becomes `[1, 2, -1e9, -1e9, -1e9]`, so that when you take the softmax, the last three elements (where there were zeros in the input) don't affect the score.\n","\n","The [MultiheadAttention](https://keras.io/api/layers/attention_layers/multi_head_attention/) layer implemented in Keras, uses this masking logic.\n","\n","**Note:** The below functions create the masking of both types."]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1740035136792,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"XQBsHyMu7acS"},"outputs":[],"source":["def create_padding_mask(decoder_token_ids):\n","    \"\"\"\n","    Creates a matrix mask for the padding cells\n","\n","    Arguments:\n","        decoder_token_ids (matrix like): matrix of size (n, m)\n","\n","    Returns:\n","        mask (tf.Tensor): binary tensor of size (n, 1, m)\n","    \"\"\"\n","    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n","\n","    # add extra dimensions to add the padding to the attention logits.\n","    # this will allow for broadcasting later when comparing sequences\n","    return seq[:, tf.newaxis, :]\n","\n","\n","def create_look_ahead_mask(sequence_length):\n","    \"\"\"\n","    Returns a lower triangular matrix filled with ones\n","\n","    Arguments:\n","        sequence_length (int): matrix size\n","\n","    Returns:\n","        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n","    \"\"\"\n","    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n","    return mask"]},{"cell_type":"markdown","metadata":{"id":"oOvektBz7acS"},"source":["\n","## 4.3 - Self-Attention\n","\n","As the authors of the Transformers paper state, \"Attention is All You Need\".\n","\n","<center><img src=\"images/attention.png\" alt=\"Encoder\" width=\"600\"/></center>\n","\n","<center><caption><font color='purple'><b>Figure 1: Self-Attention calculation visualization</font></</caption></center>\n","    \n","\n","The use of self-attention paired with traditional convolutional networks allows for parallelization which speeds up training. we will implement **scaled dot product attention** which takes in a query, key, value, and a mask as inputs to return rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:\n","$$\n","\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{4}\\\n","$$\n","\n","* $Q$ is the matrix of queries\n","* $K$ is the matrix of keys\n","* $V$ is the matrix of values\n","* $M$ is the optional mask you choose to apply\n","* ${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode\n","\n","\n","This will be handled by Tensorlfow so we will not searately define a function to handel self-attention.\n"]},{"cell_type":"markdown","metadata":{"id":"MdFkl1Vb7acS"},"source":["## 4.4 Encoder"]},{"cell_type":"markdown","metadata":{"id":"jlut9EQh7acS"},"source":["Now we will define the encoder part of the transformer using multi-head attention and feed forward.\n","The structure of the model we will implement will look like the following figure.\n","\n","<center><img src=\"images/encoders.png\" alt=\"Encoder\" width=\"400\" /> </center>"]},{"cell_type":"markdown","metadata":{"id":"51A7eVcV7acS"},"source":["As you can see in the above figure inside the Encoder there is a feed forward layer. Here we will use 2 Dense layers as part of the Feed Forward Network"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1740035137185,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"V_mNKCrA7acS"},"outputs":[],"source":["def FullyConnected(embedding_dim, fully_connected_dim):\n","    \"\"\"\n","    Returns a sequential model consisting of two dense layers. The first dense layer has\n","    fully_connected_dim neurons and is activated by relu. The second dense layer has\n","    embedding_dim and no activation.\n","\n","    Arguments:\n","        embedding_dim (int): output dimension\n","        fully_connected_dim (int): dimension of the hidden layer\n","\n","    Returns:\n","        _ (tf.keras.Model): sequential model\n","    \"\"\"\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, d_model)\n","        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"Zcb9F-X17acS"},"source":["Next we will define the encoder layer class that contains both the multi-head attention and the FullyConnected layer"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1740035137388,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"ZyLHDdxY7acS"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    \"\"\"\n","    The encoder layer is composed by a multi-head self-attention mechanism,\n","    followed by a simple, positionwise fully connected feed-forward network.\n","    This architecture includes a residual connection around each of the two\n","    sub-layers, followed by layer normalization.\n","    \"\"\"\n","    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n","                 dropout_rate=0.1, layernorm_eps=1e-6):\n","\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = tf.keras.layers.MultiHeadAttention(\n","            num_heads=num_heads,\n","            key_dim=embedding_dim,\n","            dropout=dropout_rate\n","        )\n","\n","        self.ffn = FullyConnected(\n","            embedding_dim=embedding_dim,\n","            fully_connected_dim=fully_connected_dim\n","        )\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n","\n","        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        \"\"\"\n","        Forward pass for the Encoder Layer\n","\n","        Arguments:\n","            x (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n","            training (bool): Boolean, set to true to activate\n","                        the training mode for dropout layers\n","            mask (tf.Tensor): Boolean mask to ensure that the padding is not\n","                    treated as part of the input\n","        Returns:\n","            encoder_layer_out (tf.Tensor): Tensor of shape (batch_size, input_seq_len, embedding_dim)\n","        \"\"\"\n","        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n","        self_mha_output = self.mha(x, x, x, mask)  # Self attention (batch_size, input_seq_len, fully_connected_dim)\n","\n","        # skip connection\n","        # apply layer normalization on sum of the input and the attention output to get the\n","        # output of the multi-head attention layer\n","        skip_x_attention = self.layernorm1(x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n","\n","        # pass the output of the multi-head attention layer through a ffn\n","        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n","\n","        # apply dropout layer to ffn output during training\n","        # use `training=training`\n","        ffn_output = self.dropout_ffn(ffn_output, training=training)\n","\n","        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output\n","        # to get the output of the encoder layer\n","        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n","\n","        return encoder_layer_out\n"]},{"cell_type":"markdown","metadata":{"id":"wh_UYRj_7acS"},"source":["Now let's define the full Encoder Layer including the Embedding of the tokens and addition of positional embedding with Dropout layer before entering the Encoder"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1740035137626,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"0YNq9SXP7acT"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","    \"\"\"\n","    The entire Encoder starts by passing the input to an embedding layer\n","    and using positional encoding to then pass the output through a stack of\n","    encoder Layers\n","\n","    \"\"\"\n","    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n","               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dim)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                self.embedding_dim)\n","\n","\n","        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n","                                        num_heads=num_heads,\n","                                        fully_connected_dim=fully_connected_dim,\n","                                        dropout_rate=dropout_rate,\n","                                        layernorm_eps=layernorm_eps)\n","                           for _ in range(self.num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        \"\"\"\n","        Forward pass for the Encoder\n","\n","        Arguments:\n","            x (tf.Tensor): Tensor of shape (batch_size, seq_len)\n","            training (bool): Boolean, set to true to activate\n","                        the training mode for dropout layers\n","            mask (tf.Tensor): Boolean mask to ensure that the padding is not\n","                    treated as part of the input\n","\n","        Returns:\n","            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding dim)\n","        \"\"\"\n","        seq_len = tf.shape(x)[1]\n","\n","        # Pass input through the Embedding layer\n","        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n","        # Scale embedding by multiplying it by the square root of the embedding dimension\n","        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n","        # Add the position encoding to embedding\n","        x += self.pos_encoding[:, :seq_len, :]\n","        # Pass the encoded embedding through a dropout layer\n","        # use `training=training`\n","        x = self.dropout(x, training=training)\n","        # Pass the output through the stack of encoding layers\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x  # (batch_size, input_seq_len, embedding_dim)"]},{"cell_type":"markdown","metadata":{"id":"0Wg-1ZE-7acT"},"source":["## 4.6 Decoder"]},{"cell_type":"markdown","metadata":{"id":"CKxEn63w7acT"},"source":["Now we will define the decoder part of the transformer using masked multi-head attention, multi-head attention and feed forward.\n","\n","<b>N.B  pre-training transformer with both Encoder and decoder with MLM is not common task as most models like BERT which are pretrained using masked language modeling(MLM) need only encoders. But here I used both encoder and decoders so that the model can be further pre-trained or fine-tuned for tasks that need both encoder and decoder, like Neural Machine translation as well.</b>\n","\n","The structure of the decoder layer we will implement will look like the following figure.\n","\n","<center><img src=\"images/decoders.png\" alt=\"Encoder\" width=\"400\" /> </center>"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1740035137805,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"jvClpbGW7acT"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    \"\"\"\n","    The decoder layer is composed by two multi-head attention blocks,\n","    one that takes the new input and uses self-attention, and the other\n","    one that combines it with the output of the encoder, followed by a\n","    fully connected block.\n","    \"\"\"\n","    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=num_heads,\n","            key_dim=embedding_dim,\n","            dropout=dropout_rate\n","        )\n","\n","        self.mha2 = tf.keras.layers.MultiHeadAttention(\n","            num_heads=num_heads,\n","            key_dim=embedding_dim,\n","            dropout=dropout_rate\n","        )\n","\n","        self.ffn = FullyConnected(\n","            embedding_dim=embedding_dim,\n","            fully_connected_dim=fully_connected_dim\n","        )\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n","\n","        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        \"\"\"\n","        Forward pass for the Decoder Layer\n","\n","        Arguments:\n","            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n","            enc_output (tf.Tensor): Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n","            training (bool): Boolean, set to true to activate\n","                        the training mode for dropout layers\n","            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n","            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n","        Returns:\n","            out3 (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n","            attn_weights_block1 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, target_seq_len)\n","            attn_weights_block2 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n","        \"\"\"\n","\n","\n","        # enc_output.shape == (batch_size, input_seq_len, fully_connected_dim)\n","\n","        # BLOCK 1\n","        # calculate self-attention and return attention scores as attn_weights_block1.\n","        # Dropout will be applied during training\n","        mult_attn_out1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask, return_attention_scores=True)\n","\n","        # apply layer normalization (layernorm1) to the sum of the attention output and the input\n","        Q1 = self.layernorm1(mult_attn_out1 + x)\n","\n","        # BLOCK 2\n","        # calculate self-attention using the Q from the first block and K and V from the encoder output.\n","        # Dropout will be applied during training\n","        # Return attention scores as attn_weights_block2\n","        mult_attn_out2, attn_weights_block2 = self.mha2(Q1,enc_output,enc_output, padding_mask, return_attention_scores=True)\n","\n","        # # apply layer normalization (layernorm2) to the sum of the attention output and the Q from the first block\n","        mult_attn_out2 = self.layernorm2(mult_attn_out2+Q1)\n","\n","        #BLOCK 3\n","        # pass the output of the second block through a ffn\n","        ffn_output = self.ffn(mult_attn_out2)\n","\n","        # apply a dropout layer to the ffn output\n","        # use `training=training`\n","        ffn_output =self.dropout_ffn(ffn_output)\n","\n","        # apply layer normalization (layernorm3) to the sum of the ffn output and the output of the second block\n","        out3 =self.layernorm3(ffn_output+mult_attn_out2)\n","\n","\n","        return out3, attn_weights_block1, attn_weights_block2\n"]},{"cell_type":"markdown","metadata":{"id":"C7Px98eA7acT"},"source":["Now let's define the full Decoder Layer"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1740035137995,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"CZZNFBOk7acT"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","    \"\"\"\n","    The entire Encoder starts by passing the target input to an embedding layer\n","    and using positional encoding to then pass the output through a stack of\n","    decoder Layers\n","\n","    \"\"\"\n","    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n","               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n","        super(Decoder, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.embedding_dim)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n","\n","        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n","                                        num_heads=num_heads,\n","                                        fully_connected_dim=fully_connected_dim,\n","                                        dropout_rate=dropout_rate,\n","                                        layernorm_eps=layernorm_eps)\n","                           for _ in range(self.num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","    def call(self, x, enc_output, training,\n","           look_ahead_mask, padding_mask):\n","        \"\"\"\n","        Forward  pass for the Decoder\n","\n","        Arguments:\n","            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len)\n","            enc_output (tf.Tensor):  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n","            training (bool): Boolean, set to true to activate\n","                        the training mode for dropout layers\n","            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n","            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n","        Returns:\n","            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n","            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights\n","                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n","        \"\"\"\n","\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","\n","        # create word embeddings\n","        x = self.embedding(x)\n","\n","        # scale embeddings by multiplying by the square root of their dimension\n","        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n","\n","        # add positional encodings to word embedding\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        # apply a dropout layer to x\n","        # use `training=training`\n","        x = self.dropout(x)\n","\n","        # use a for loop to pass x through a stack of decoder layers and update attention_weights\n","        for i in range(self.num_layers):\n","            # pass x and the encoder output through a stack of decoder layers and save the attention weights\n","            # of block 1 and 2\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                                   look_ahead_mask=look_ahead_mask,\n","                                                   padding_mask=padding_mask)\n","\n","            #update attention_weights dictionary with the attention weights of block 1 and block 2\n","            attention_weights[f'decoder_layer{i+1}_block1_self_att'] = block1\n","            attention_weights[f'decoder_layer{i+1}_block2_decenc_att'] = block2\n","\n","\n","        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n","        return x, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"liAk-WEx7acT"},"source":["## 4.6 Transformer"]},{"cell_type":"markdown","metadata":{"id":"cjhJQo7J7acT"},"source":["Now we will combine both the encoder and the decoder layers defined above into a single transformer model. The full structure of the model we will form is depicted below. In the code, in addition to encoder and decoder we will add a final Dense layer with softmax  activation."]},{"cell_type":"markdown","metadata":{"id":"bkebyrde7acT"},"source":["<center><img src=\"images/transformer.png\" width=\"3\" height=\"2\"/></center>"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1740035138321,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"47fZ8qJE7acT"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","    \"\"\"\n","    Complete transformer with an Encoder and a Decoder\n","    \"\"\"\n","    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n","               target_vocab_size, max_positional_encoding_input,\n","               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers=num_layers,\n","                               embedding_dim=embedding_dim,\n","                               num_heads=num_heads,\n","                               fully_connected_dim=fully_connected_dim,\n","                               input_vocab_size=input_vocab_size,\n","                               maximum_position_encoding=max_positional_encoding_input,\n","                               dropout_rate=dropout_rate,\n","                               layernorm_eps=layernorm_eps)\n","\n","        self.decoder = Decoder(num_layers=num_layers,\n","                               embedding_dim=embedding_dim,\n","                               num_heads=num_heads,\n","                               fully_connected_dim=fully_connected_dim,\n","                               target_vocab_size=target_vocab_size,\n","                               maximum_position_encoding=max_positional_encoding_target,\n","                               dropout_rate=dropout_rate,\n","                               layernorm_eps=layernorm_eps)\n","\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n","\n","    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        \"\"\"\n","        Forward pass for the entire Transformer\n","        Arguments:\n","            input_sentence (tf.Tensor): Tensor of shape (batch_size, input_seq_len)\n","                              An array of the indexes of the words in the input sentence\n","            output_sentence (tf.Tensor): Tensor of shape (batch_size, target_seq_len)\n","                              An array of the indexes of the words in the output sentence\n","            training (bool): Boolean, set to true to activate\n","                        the training mode for dropout layers\n","            enc_padding_mask (tf.Tensor): Boolean mask to ensure that the padding is not\n","                    treated as part of the input\n","            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n","            dec_padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n","        Returns:\n","            final_output (tf.Tensor): The final output of the model\n","            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights for the decoder\n","                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n","\n","        \"\"\"\n","\n","\n","        enc_output = self.encoder(input_sentence, training, enc_padding_mask)\n","        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n","        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training,\n","           look_ahead_mask, dec_padding_mask)\n","        final_output = self.final_layer(dec_output)\n","\n","\n","        return final_output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"KWoDzuju7acT"},"source":["## 4.7 Intialize Model"]},{"cell_type":"markdown","metadata":{"id":"vSs0X8NM7acT"},"source":["Now we will intialize our model to pre-train it on the data we defined. Most of the parameter values we will use here are taken form the <a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need</a> paper"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1740035138582,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"DcWVkZrv7acU","outputId":"b2035a90-2909-4fbc-a3aa-3603d20e107b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum positional encoding length for input: 204\n","Maximum positional encoding length for target: 61\n"]}],"source":["#let's find the maximum length in our training data to set it as the maximum positional encoding\n","POSITIONAL_ENCODING_INPUT_LENGTH =training_data_inputs_padded.shape[1]\n","POSITIONAL_ENCODING_TARGET_LENGTH =training_data_targets_padded.shape[1]\n","print(f\"Maximum positional encoding length for input: {POSITIONAL_ENCODING_INPUT_LENGTH}\")\n","print(f\"Maximum positional encoding length for target: {POSITIONAL_ENCODING_TARGET_LENGTH}\")\n","\n"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":122,"status":"ok","timestamp":1740035138714,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"QN5IXbsD7acU"},"outputs":[],"source":["# Define the model parameters\n","NUM_LAYERS = 6\n","EMBEDDING_DIM = 512\n","FULLY_CONNECTED_DIM = 2048\n","NUM_HEADS= 8\n","vocab_size = tokenizer.vocab_size()\n","\n","\n","# Initialize the model\n","transformer = Transformer(\n","    NUM_LAYERS,\n","    EMBEDDING_DIM,\n","    NUM_HEADS,\n","    FULLY_CONNECTED_DIM,\n","    vocab_size,\n","    vocab_size,\n","    POSITIONAL_ENCODING_INPUT_LENGTH,\n","    POSITIONAL_ENCODING_TARGET_LENGTH,\n",")"]},{"cell_type":"markdown","metadata":{"id":"uA2a9Qng7acU"},"source":["## 4.8 Pre-training"]},{"cell_type":"markdown","metadata":{"id":"PJhm0Fxg7acU"},"source":["\n","We have finished defining our model and processing our traning and validation datas. The next step will be training !\n"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1740035138930,"user":{"displayName":"Mahder Tesfaye","userId":"17772783101485914098"},"user_tz":-180},"id":"eMiekH0J7acU"},"outputs":[],"source":["\n","# Define the loss function and optimizer\n","loss_object = SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n","optimizer = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","# Define metrics to track loss and accuracy\n","train_loss = Mean(name='train_loss')\n","train_accuracy = SparseCategoricalAccuracy(name='train_accuracy')\n","val_loss = Mean(name='val_loss')\n","val_accuracy = SparseCategoricalAccuracy(name='val_accuracy')\n","\n","# Function to calculate the loss\n","def loss_function(real, pred, mask):\n","    \"\"\"\n","    Arguments:\n","        real (tf.Tensor): Ground truth labels\n","        pred (tf.Tensor): Model predictions\n","        mask (tf.Tensor): Mask to ignore padding tokens\n","    Returns:\n","        loss (tf.Tensor): Computed loss\n","    \"\"\"\n","    loss_ = loss_object(real, pred)\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n","\n","# Function to create masks for the input and target sequences\n","def create_masks(inp, tar):\n","    \"\"\"\n","    Arguments:\n","        inp (tf.Tensor): Input sequence\n","        tar (tf.Tensor): Target sequence\n","    Returns:\n","        enc_padding_mask (tf.Tensor): Padding mask for encoder\n","        look_ahead_mask (tf.Tensor): Look-ahead mask for decoder\n","        dec_padding_mask (tf.Tensor): Padding mask for decoder\n","    \"\"\"\n","    enc_padding_mask = create_padding_mask(inp)\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_padding_mask = create_padding_mask(inp)\n","    return enc_padding_mask, look_ahead_mask, dec_padding_mask\n","\n","# Training step function\n","@tf.function\n","def train_step(inp, tar):\n","    \"\"\"\n","    Arguments:\n","        inp (tf.Tensor): Input sequence\n","        tar (tf.Tensor): Target sequence\n","    \"\"\"\n","    tar_inp = tar[:, :-1]  # Shifted target input for teacher forcing\n","    tar_real = tar[:, 1:]  # Actual target output\n","\n","    # Create masks\n","    enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        # Forward pass\n","        predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, look_ahead_mask, dec_padding_mask)\n","        # Compute loss\n","        loss = loss_function(tar_real, predictions, create_padding_mask(tar_real))\n","\n","    # Compute gradients and update weights\n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    # Update metrics\n","    train_loss(loss)\n","    train_accuracy(tar_real, predictions)\n","\n","# Validation step function\n","@tf.function\n","def val_step(inp, tar):\n","    \"\"\"\n","    Arguments:\n","        inp (tf.Tensor): Input sequence\n","        tar (tf.Tensor): Target sequence\n","    \"\"\"\n","    tar_inp = tar[:, :-1]  # Shifted target input for teacher forcing\n","    tar_real = tar[:, 1:]  # Actual target output\n","\n","    # Create masks\n","    enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    # Forward pass\n","    predictions, _ = transformer(inp, tar_inp, False, enc_padding_mask, look_ahead_mask, dec_padding_mask)\n","    # Compute loss\n","    loss = loss_function(tar_real, predictions, create_padding_mask(tar_real))\n","\n","    # Update metrics\n","    val_loss(loss)\n","    val_accuracy(tar_real, predictions)\n","\n","# Training loop\n"]},{"cell_type":"markdown","metadata":{"id":"Mk6rCvJW_7oF"},"source":["Let's baby sit the training with 3 epoch each time and save the weights then continue for 3 steps and so until we reach good accuracy and low loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6_9Hj5y7acU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0b36881-48b2-4d88-ffe9-39b47b6aa2ad"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1, Batch 0, Loss: 734.7012329101562, Accuracy: 0.0\n"]}],"source":["#First training\n","train_losses = []\n","val_losses = []\n","\n","EPOCHS = 1\n","step=1\n","for epoch in range(EPOCHS):\n","    # Reset metrics at the start of each epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    val_loss.reset_states()\n","    val_accuracy.reset_states()\n","\n","    # Training loop\n","    for (batch, (inp, tar)) in enumerate(training_dataset_final):\n","        train_step(inp, tar)\n","        if batch % 100 == 0:\n","            print(f'Epoch {epoch + 1}, Batch {batch}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result()}')\n","\n","    # Validation loop\n","    for (batch, (inp, tar)) in enumerate(validation_dataset_final):\n","        val_step(inp, tar)\n","\n","    # Append loss values to the lists\n","    train_losses.append(train_loss.result())\n","    val_losses.append(val_loss.result())\n","\n","    # Print metrics at the end of each epoch\n","    print(f'Epoch {epoch + 1}, Train Loss: {train_loss.result()}, Train Accuracy: {train_accuracy.result()}')\n","    print(f'Epoch {epoch + 1}, Val Loss: {val_loss.result()}, Val Accuracy: {val_accuracy.result()}')\n","    transformer.save_weights(f\"/content/drive/MyDrive/Transformer_classifier_app_1/model_weights/model_weights_{step}.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i61EqmoUBm2E"},"outputs":[],"source":["# Plot the training and validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Over Epochs')\n","plt.legend()\n","\n","# Save the plot as an image file\n","plt.savefig(f'/content/drive/MyDrive/Transformer_classifier_app_1/loss_images/training_validation_loss{step}.png')\n","\n","# Optionally, display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Knydgh-QGMva"},"outputs":[],"source":["#next steps\n","train_losses = []\n","val_losses = []\n","\n","EPOCHS = 1\n","step=1\n","transformer.load_weights(f\"/content/drive/MyDrive/Transformer_classifier_app_1/model_weights/model_weights_{step-1}.h5\")\n","for epoch in range(EPOCHS):\n","    # Reset metrics at the start of each epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    val_loss.reset_states()\n","    val_accuracy.reset_states()\n","\n","    # Training loop\n","    for (batch, (inp, tar)) in enumerate(training_dataset_final):\n","        train_step(inp, tar)\n","        if batch % 100 == 0:\n","            print(f'Epoch {epoch + 1}, Batch {batch}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result()}')\n","\n","    # Validation loop\n","    for (batch, (inp, tar)) in enumerate(validation_dataset_final):\n","        val_step(inp, tar)\n","\n","    # Append loss values to the lists\n","    train_losses.append(train_loss.result())\n","    val_losses.append(val_loss.result())\n","\n","    # Print metrics at the end of each epoch\n","    print(f'Epoch {epoch + 1}, Train Loss: {train_loss.result()}, Train Accuracy: {train_accuracy.result()}')\n","    print(f'Epoch {epoch + 1}, Val Loss: {val_loss.result()}, Val Accuracy: {val_accuracy.result()}')\n","    transformer.save_weights(f\"/content/drive/MyDrive/Transformer_classifier_app_1/model_weights/model_weights_{step}.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07QrKDa0Gk66"},"outputs":[],"source":["# Plot the training and validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Over Epochs')\n","plt.legend()\n","\n","# Save the plot as an image file\n","plt.savefig(f'/content/drive/MyDrive/Transformer_classifier_app_1/loss_images/training_validation_loss{step}.png')\n","\n","# Optionally, display the plot\n","plt.show()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":0}