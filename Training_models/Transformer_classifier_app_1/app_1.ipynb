{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1><b>Pretraining a Transformer Model from Scratch on an Amharic Dataset and Fine-Tuning for Amharic Hate Speech Recognition Task</b></h1>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "1. [Introduction](#introduction)  \n",
    "2. [Importing Packages](#importing-packages)  \n",
    "3. [Dataset Collection & Preprocessing](#dataset-collection--preprocessing)  \n",
    "   - 3.1 [Data Collection](#data-collection)  \n",
    "   - 3.2 [Data Cleaning](#data-cleaning)  \n",
    "   - 3.3 [Tokenization](#tokenization)  \n",
    "   - 3.4 [Tokenizing and Masking](#tokenizing-and-masking)  \n",
    "   - 3.5 [Creating Training Data Pairs](#creating-training-data-pairs)  \n",
    "4. [Pretraining the Transformer Model](#pretraining-the-transformer-model)  \n",
    "   - 4.1 [Positional Encoding](#positional-encoding)  \n",
    "   - 4.2 [Masking](#masking)  \n",
    "   - 4.3 [Self Attention](#self-attention)  \n",
    "   - 4.4 [Encoder](#encoder)  \n",
    "   - 4.5 [Decoder](#decoder)  \n",
    "   - 4.6 [Transformer](#transformer)  \n",
    "   - 4.7 [Initialize_Model](#initialize-model)  \n",
    "   - 4.8 [Pre-training](#pre-training)  \n",
    "5. [Fine-Tuning for Hate Speech Recognition](#fine-tuning-for-hate-speech-recognition)  \n",
    "6. [Evaluation](#evaluation)  \n",
    "7. [Deployment on Mahder AI App](#deployment-on-mahder-ai-app)  \n",
    "8. [Conclusion](#conclusion)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction  \n",
    "\n",
    "In this notebook, I will pretrain a Transformer network on an Amharic dataset collected from a variety of Telegram channels, using the Masked Language Model (MLM). The primary objective of pretraining is to enable the model to learn contextualized word and phrase representations, thereby enhancing its understanding of language semantics. The Transformer’s self-attention mechanism plays a crucial role by allowing the model to dynamically weigh different parts of the input sequence, effectively capturing long-range dependencies in the data.  \n",
    "\n",
    "After pretraining, I will fine-tune the model on a labeled dataset of hate speech and deploy the resulting model in the **Mahder AI** app.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Importing the Packages\n",
    "\n",
    "Let's start by importing all the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import emoji\n",
    "import sentencepiece as spm\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Collection  \n",
    "\n",
    "In order to pretrain the Transformer network from scratch, we will use **self-supervised learning**, which requires a large corpus of unlabeled text. We will apply a **Masked Language Model (MLM)** to pre-train the model.  \n",
    "\n",
    "#### **Why Telegram Channels?**  \n",
    "Telegram is the most widely used platform for information storage in Ethiopia. For this reason, I have chosen **Telegram channels** as the primary data source. Most of the selected channels are news channels, ensuring a diverse and rich dataset.  \n",
    "\n",
    "#### **Data Collection Method**  \n",
    "To collect the data, I used the **Telethon Python library** and the **Telegram API** to scrape text from selected channels.  \n",
    "\n",
    "#### **Selected Telegram Channels**  \n",
    "The dataset has been collected from the following Telegram channels:  \n",
    "\n",
    "- [Tikvah Ethiopia](https://t.me/tikvahethiopia)  \n",
    "- [Addis Standard Amharic](https://t.me/AddisstandardAmh)  \n",
    "- [Tarikn Wedehuala](https://t.me/TariknWedehuala)  \n",
    "- [Addis News](https://t.me/Addis_News)  \n",
    "- [Zena 24 Now](https://t.me/zena24now)  \n",
    "- [Tikvah University](https://t.me/TikvahUniversity)  \n",
    "- [Tikvah Ethiopia Magazine](https://t.me/tikvahethmagazine)  \n",
    "- [Tikvah Ethiopia Sport](https://t.me/tikvahethsport)  \n",
    "- [Philosophy Thoughts](https://t.me/Philosophy_Thoughts1)  \n",
    "- [Mudenyaz](https://t.me/Mudenyaz)  \n",
    "- [Yemeri Terekoch](https://t.me/yemeri_terekoch)  \n",
    "- [Bemnet Library](https://t.me/Bemnet_Library)  \n",
    "- [Amazing Fact](https://t.me/amazing_fact_433)  \n",
    "- [Zephilosophy](https://t.me/Zephilosophy)  \n",
    "- [Huluezih](https://t.me/huluezih)  \n",
    "\n",
    "#### **Accessing Collected Data**  \n",
    "To access the code and all the raw data collected from each channel, visit the following GitHub repository:  \n",
    "[GitHub Repository Link](https://github.com/your-repo-link-here).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a function that will load data from a JSON file as an array of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    return_data=[]\n",
    "    with open (filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "        datas=json.load(file)\n",
    "        for data in datas:\n",
    "            return_data.append(data[\"text\"])\n",
    "            \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how the news look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#መቄዶንያ\n",
      "\n",
      "ሰውን ለመርዳት ሰው መሆን በቂ ነው !\n",
      "\n",
      "ትላንት የካቲት 1/2017 ዓ/ም በጀመረው የመቄዶንያ የአረጋዊያን እና የአእምሮ ህሙማን መርጃ ማዕከል የድጋፍ ማሰባሰብ ዘመቻ እስኩን 120,000,000 ብር ተሰብስቧል።\n",
      "\n",
      "መቄዶንያ በሚያስገነባው ሆስፒታል ጭምር ያለው ህንፃ ለማጠናቀቅ የገንዘብ እጥረት አጋጥሞታል። ህንፃው ለማጠናቀቅ ገንዘብ ተቸግረናል። ለማጠናቀቅ ወደ 5 ቢሊዮን ብር ያስፈልጋል።\n",
      "\n",
      "በቀጥታ ይከታተሉ 👇\n",
      "https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n",
      "\n",
      "የምትችሉትን ሁሉ ድጋፍ አድርጉ።\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🔊 #የሠራተኞችድምጽ\n",
      "\n",
      "\" ቋሚ ሠራተኞች ሆነን ሳለ በደሞዝ ማሻሻያው አልተካተትንም \" - የሀዋሳ ዙሪያ ወረዳ መንግስት ሠራተኞች\n",
      "\n",
      "የማክሮ ኢኮኖሚ ማሻሻያ ሪፎርሙን ተከትሎ የሚከሰቱ የኑሮ ዉድነትና ተያያዥ ጉዳዮችን ታሳቢ በማድረግ የመንግስት ሠራተኞች ደሞዝ ማሻሻያ ተደርጎ ከጥቅምት ወር 2017 ዓ/ም ጀምሮ ተግባራዊ የተደረገ መሆኑ ይታወቃል።\n",
      "\n",
      "በሲዳማ ክልል፤ ሰሜናዊ ሲዳማ ዞን፤ ሀዋሳ ዙሪያ ወረዳ በተለያዩ የመንግስት መስሪያ ቤቶች የሚሰሩ የመንግስት ሠራተኞች ግን \" ከ2012 ዓ/ም ጀምሮ በቋሚነት ተቀጥረን እየሰራን ያለን ቢሆንም በአዲሱ የመንግስት ሠራተኞች የደመወዝ ማሻሻያ አልተካተትንም \" ሲሉ ቅሬታቸዉን ለቲክቫህ ኢትዮጵያ አስገብተዋል።\n",
      "\n",
      "ቅሬታቸዉን ካደረሱን መካከል ፦\n",
      "- በከተማ ልማትና ኮንስትራክሽን፣\n",
      "- ማዘጋጃ ቤቶች፣\n",
      "- በትምህርት ዘርፍ ፣\n",
      "- በሴቶችና ሕፃናት እንዲሁም በሕብረት ስራ ጽ/ቤቶች የሚሰሩ ሠራተኞች ናቸው።\n",
      "\n",
      "\" በወቅቱ በአግባቡ ማስታወቂያ ወጥቶ ተመዝግበንና ተወዳድረን ማለፋችን ተረጋግጦ የቋሚነት ደብዳቤ ተሰጥቶን ላለፉት አምስትና ስድስት ዓመታት ደሞዝ ሲከፈለን በቆየንባቸው መደቦች ላይ እየሰራን ባለንበት በአዲሱ የደሞዝ ማሻሻያ አለመካተታችን ለዘርፈ ብዙ ችግሮች ዳርጎናል \" ብለዋል።\n",
      "\n",
      "\" ለወረዳዉ ፐብሊክ ሰርቪስና የሰዉ ሃብት ልማት ጽ/ቤት እና ለክልሉ ፐብሊክ ሰርቪስ ቢሮ ቅሬታችንን በአካልና በፅሁፍ ብናቀርብም ተገቢዉ ምላሽ አልተሰጠንም ጉዳዩን ለኢትዮጵያ እምባ ጠባቂ ተቋም ለማቅረብ መረጃ እያደራጀን ነው \" ሲሉ ተናግረዋል።\n",
      "\n",
      "ቃላቸውን ለቲክቫህ ኢትዮጵያ የሰጡት ፤ የሀዋሳ ዙሪያ ወረዳ ፐብሊክ ሰርቪስ እና የሰዉ ሃብት ልማት ጽ/ቤት ኃላፊ አቶ ሃይሉ አቢኖ ፥ \" በወረዳዉ በ2012 ዓ/ም የነበረው አግባብነት በሌለው ቅጥር በአንድ መደብ ሶስትና አራት ሰዎችን በተደራራቢነት የመቅጠር ሁኔታዎች አሁን ለተፈጠረው ችግር ዋነኛ ምክንያት ሆኗል \" ሲሉ ገልጸዋል።\n",
      "\n",
      "ከዞኑና የክልሉ ፐብልክ ሰርቪስ ጋር በመናበብ መፍትሔ እያፈላለጉ ስለመሆኑም ጠቁመዋል።\n",
      "\n",
      "በወቅቱ ይህን ተግባር የፈፀሙ አመራሮች እና የሰዉ ሃብት ልማት ኃላፊዎች ላይ እርምጃ መወሰዱን የሚናገሩት ኃላፊዉ በወረዳዉ በዚህ መልክ ተጠቀጥረዉ በአዲሱ የደመወዝ ማሻሻያ ያልካተቱና በቀጣይ መፍትሔ የሚፈለግላቸዉ 470 በተለያዩ መስሪያ ቤቶች ዉስጥ የተለዩ ሰራተኞች ስለመኖራቸዉ አክለዋል።\n",
      "\n",
      "የሰሜናዊ ሲዳማ ዞን ፐብልክ ሰርቪስና የሰዉ ሃይል ልማት መምሪያ ኃላፊ አቶ በዛብህ ባርሶ በበኩላቸው በ2011 እና 2012 በአከባቢው ሕገወጥ ቅጥሮች መፈፀማቸውን ገልጸዋል።\n",
      "\n",
      "በወረዳዉ አጣሪ ቡድን ተቋቁሞ በአዲሱ ደሞዝ ያልተካተቱንና በወረዳው ቅጥር ያልተፈፀመባቸዉ ክፍት መደቦችን የመለየት ስራ መከናወኑን አንስተዉ በሀዋሳ ዙሪያ ወረዳ ብቻ 407 ክፍት መደቦች መኖራቸዉን ለማወቅ መቻሉን ገልፀዋል።\n",
      "\n",
      "የክልሉ የበላይ አመራሮች በሚያስቀምጡት አቅጣጫ መሰረት እነዚህን ሠራተኞች በነዚህ ክፍት መደቦች የመደልደልና ሌሎችም ሕጋዊ አመራጮች በመፈለግ በአጭር ጊዜ ዉስጥ እልባት ለመስጠት እየተሰራ መሆኑን አስታውቀዋል።\n",
      "\n",
      "ቲክቫህ ኢትዮጵያ ጉዳዩን እስከመጨረሻ ተከታትሎ መረጃውን ይልካል።\n",
      "\n",
      "#TikvahEthiopiaFamilyHW\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "የIMF ማኔጂንግ ዳይሬክተሯ ምን አሉ ?\n",
      "\n",
      "የዓለም አቀፍ የገንዘብ ተቋም (IMF) ማኔጂንግ ዳይሬክተር ክሪስታሊና ጆርጂዬቫ በኢትዮጵያ የስራ ቆይታ አድርገዋል።\n",
      "\n",
      "በዚህም ወቅት ከጠ/ሚ ዐቢይ አህመድ (ዶ/ር) ጋር ጨምሮ ከፌዴራል ከፍተኛ ባለስልጣናት ጋር መክረዋል።\n",
      "\n",
      "የነበራቸውን ቆይታ በተመለከተ ከገንዘብ ሚኒስትሩ አቶ አህመድ ሽዴ ጋር በጋራ መግለጫ ሰጥተው ነበር።\n",
      "\n",
      "ምን አሉ ?\n",
      "\n",
      "ዳይሬክተሯ ፤ \" የኢትዮጵያ ሪፎርም ከባድ እና ጊዜ የሚወስድ ነው ፤ እባካችሁ ታገሱ \" የሚል ጥሪ አቅርበዋል።\n",
      "\n",
      "ኢትዮጵያውያን ለትዕግስት እንዲያሳዩ እና ከመንግስት የኢኮኖሚ ማሻሻያ ጥረቶች ጎን እንዲቆሙ ጠይቀዋል።\n",
      "\n",
      "ጆርጂዬቫ ፥ \" የሪፎርሙን ግቦች ለማሳካት የአንድነት አስፈላጊ ነው \" ሲሉ አፅንኦት ሰጥተዋል።\n",
      "\n",
      "\" ኢትዮጵያ የተቀበለችው ሪፎርም ከባድ እና ጊዜ የሚወስድ ቢሆንም እጅግ ትልቅ ውጤት ያስገኛል \" ሲሉ ተናግረዋል።\n",
      "\n",
      "\" ህዝቡ በትዕግስት እንዲጠብቅ ጥሪዬን አቀርባለሁ \" ያሉት ማኔጂንግ ዳይሬክተሯ \" ህብረተሰቡ ከሪፎርሙ ጀርባ በመሰባሰብ በአንድነት ድጋፍ ማድረግ አለበት \" ብለዋል።\n",
      "\n",
      "ጆርጂዬቫ ፥ ኢኮኖሚውን የበለጠ አጥጋቢና ብቁ ለማድረግ ብዙ የሚሠራ ሥራ አለ \" ብለው \" እባካችሁ መንግሥት ሥራውን እንዲያጠናቅቅ ድጋፍ አድርጉ \" የሚል ጥሪ አቅርበዋል።\n",
      "\n",
      "የዋጋ ንረትን ለመፍታት የሚሰራው ስራ ውስብስብ መሆኑን ያልሸሸጉት ዳይሬክተራ \" የዋጋ ንረትን ወደ ታች ለማውረድ ጠንካራ የገንዘብና የፊስካል ፖሊሲዎች፣ የኢኮኖሚውን የማምረት አቅም ማስፋት፣ የወጪ ንግድና የውጭ ምንዛሪ ገቢን ማሳደግ እና የግሉ ሴክተርን ማብቃት ይጠይቃል \" ብለዋል።\n",
      "\n",
      "ሌላው ያነሱት ጉዳይ በG20 የጋራ ማዕቀፍ ኢትዮጵያ እያካሄደች ያለችውን የዕዳ መልሶ ማደራጀት ድርድር በተመለከተ ነው።\n",
      "\n",
      "ጆርጂዬቫ ፤ \" የዕዳ መልሶ ማዋቀር ሂደት የመጨረሻ ደረጃ ላይ ይገኛል ፤ ከኢትዮጵያ አበዳሪዎች ጋር ባለኝ ግንኙነት ይህ ቅድሚያ የሚሰጠው ጉዳይ ነው \" ሲሉ ገልጸዋል። \n",
      "\n",
      "የIMF ፕሮግራም አካል ሆነውን የታክስ እርምጃዎችን በተመለከተም ፤ የኢትዮጵያ ባለስልጣናት ለብሄራዊ በጀቱ ድጋፍ ለማድረግ ወሳኝ የሆኑ የታክስ አቅሞችን መለየታቸውን ጠቁመዋል። \n",
      "\n",
      "ጆርጂዬቫ ፥ የኢትዮጵያ አጠቃላይ የሀገር ውስጥ ምርት ዕድገት ከIMF የመጀመሪያ ትንበያዎች መብለጡን ማብራራታቸውን ዘሪፖርተር አስነብቧል።\n",
      "\n",
      "የማኔጂንግ ዳይሬክተራ ንግግር ተከትሎ \" መሬት ላይ ካለው እውነታ ጋር የሚገናኝ አይደለም \" የሚሉ አስተያየቶች ሲሰጡም ተመልክተናል።\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "ልታስመርቀዉ ከቤተሰቦቿ ተደብቃ የመጣች እጮኛዉን ጭካኔ በተሞላበት ሁኔታ የገደለዉ ግለሰብ በ20 ዓመት ጽኑ እስራት ተቀጣ።\n",
      "\n",
      "በደቡብ ኢትዮጵያ ክልል ጋሞ ዞን አርባምንጭ ከተማ አስተዳደር ጉርባ በሚባል ቀበሌ የገዛ እጮኛዉን ጭካኔ በተሞላበት መልኩ በአሰቃቂ ሁኔታ በስለት አንገቷን በመቁረጥ ሕይወቷ እንዲያልፍ ያደረገዉ ወጣት በፅኑ እስራት መቀጣቱን የአርባ ምንጭ ከተማ አስተዳደር ፖሊስ መምሪያ አዛዥ ም/ኢንስፔክተር ጋፋሮ ቶማስ ለቲክቫህ ኢትዮጵያ ተናግረዋል።\n",
      "\n",
      "የወንጀል ድርጊቱ የተፈፀመዉ ነሐሴ 16/2016 ዓ/ም በአርባምንጭ ከተማ ጉርባ ቀበሌ ነው።\n",
      "\n",
      "ተከሳሽ ዮናስ ጫፊቄ የተባለው ግለሰብ የጂንካ ዩኒቨርሲቲ 1ኛ  ዓመት ተማሪ የሆነችዉን ሟች ሊዲያ ዮሐንስ እሱን ለማስመረቅ ወደ አርባ ምንጭ ከተማ በመጣችበት ተከራይቶ በሚኖርበት ቤት አሰቃቂ ድርጊቱን መፈፀሙን የምርመራ መዝገቡ ያስረዳል።\n",
      "\n",
      "ወጣቷ \" እጮኛዬ ይመረቅልኛል \" በሚል ደስታ ከቤተሰቦቿ ተደብቃ ተከሳሽ ተከራይቶ ወደ ሚማርበት  ቤት መጥታ በዋዜማዉ ለምረቃዉ የሚሆኑ የዲኮር፣ የዳቦና ለስላሳ መጠጦችና በቡና ዝግጅት ቤቱን አሰማምራ በምሽቱም ግቢ ዉስጥ ያሉ ተከራዮችን ጠርተዉ ከሸኙ በኋላ ሟች ሀገር ሰላም ብላ በተኛችበት ከሌሊቱ 7 ሰዓት ገደማ እራሷን መከላከል በማትችልበት ሁኔታ በቢላዋ አንገቷን አርዶ መግደሉን የምርመራ መዝገቡን ዋቢ አድርገው ፖሊስ አዛዡ ገልፀዋል።\n",
      "\n",
      "ፖሊስ አዛዡ አክለው እንደገለጹት ፥ በወቅቱ በተደረገዉ ማጣራትም ሆነ በክስ መዝገቡ ላይ እንደሰፈረዉ ወንጀለኛው  \" ወደ ዩኒቨርሲቲ በሄድሽበት ሌላ የወንድ ጓደኛ ይዘሻል \" በሚል ነው በር ዘግቶ አሰቃቂ የወንጀል ድርጊቱን የፈጸመው።\n",
      "\n",
      "ፖሊስ በዚህ ዘግናኝ ወንጀል ዙሪያ ተገቢዉን ማጣራትና ምርመራ አድርጎ ለዐቃቤ ሕግ ማቅረቡን አስታውቀዋል።\n",
      "\n",
      "ዐቃቤ ሕግም ክስ በመመስረት ለፍርድ ቤቱ ተከሳሽ የወንጀል ድርጊቱን መፈፀሙን የሰዉ፣ የሰነድና የህክምና ማስረጃዎችን በማቅረብ አስረድቷል።\n",
      "\n",
      "በቀረቡ ማስረጃዎች እና ምስክሮች ግራ ቀኙን ሲያጣራ የቆየዉ የጋሞ ዞን ከፍተኛዉ ፍርድ ቤት በቀን 29/5/2017 ዓም በዋለዉ ችሎት ተከሳሽ ዮናስ ጨፊቄ በተከሰሰበት በአሰቃቂ ሁኔታ ነብስ የማጥፋት ወንጀል ጥፋተኛ መሆኑን በማረጋገጥ በ20 ዓመት ፅኑ እስራት እንዲቀጣ መወሰኑንም ኢንስፔክተር ጋፋሮ ቶማስ ለቲክቫህ ኢትዮጵያ ተናግረዋል።\n",
      "\n",
      "#TikvahEthiopiaFamilyHW\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "#መቄዶንያ\n",
      "\n",
      "\" ሰውን ለመርዳት ሰው መሆን በቂ ነው !! \"\n",
      "\n",
      "መቄዶንያ የአረጋዊያንና የአእምሮ ህሙማን መርጃ ማዕከል በሚያስገነባው ሆስፒታል ጭምር ያለው ህንፃ ለማጠናቀቅ የገንዘብ እጥረት ስለገጠመው እግዛ እንዲደረግ ለመላው ኢትዮጵያውያን ጥሪ መቅረቡ ይታወሳል።\n",
      "\n",
      "ዛሬ “ በሰይፉ ኢቢኤስ የዩቱብ ቻነል ” ድጋፍ ማድረጊያ መርሀ ግብር እየተካሄደ ነው።\n",
      "\n",
      "ደጋጎች ሁሉ ድጋፍ እንድታደርጉ ጥሪ እናቀርባለን።\n",
      "\n",
      "የድጋፍ ማድረጊያ አማራጮች ከላይ ተያይዘዋል።\n",
      "\n",
      "መቄዶንያ “ ህንፃው ለማጠናቀቅ ገንዘብ ተቸግረናል። ለማጠናቀቅ ወደ 5 ቢሊዮን ብር ያስፈልገናል ” ማለቱ አይዘነጋም።\n",
      "\n",
      "በቀጥታ ይከታተሉ 👇\n",
      "https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample=load_data(\"datas/sample.json\")\n",
    "for news in sample[:5]:\n",
    "    print(news)\n",
    "    \n",
    "    print(\"---------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with a Telegram dataset, we aim to clean the text by removing substrings that are commonly used on the platform, such as hashtagged entities, usernames, hyperlinks,emojis, and english words. To achieve this, we will use Python's re library to perform regular expression operations. We will define specific search patterns and use the sub() method to remove matches by replacing them with an empty string (''). We will also remove unecessary multiple spaces to a single space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text=re.sub(r'@\\S+', '', text)\n",
    "    text=emoji.replace_emoji(text,\" \")\n",
    "    english_pattern = re.compile(r'\\b[A-Za-z]+\\b')   \n",
    "    cleaned_text = re.sub(english_pattern, '', text)    \n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the above function on sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's load our training data and see how many contents we have and what the first 5 contents look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of contents: 193419\n",
      "\n",
      "First 5 contents: \n",
      "\n",
      "#መቄዶንያ\n",
      "\n",
      "ሰውን ለመርዳት ሰው መሆን በቂ ነው !\n",
      "\n",
      "ትላንት የካቲት 1/2017 ዓ/ም በጀመረው የመቄዶንያ የአረጋዊያን እና የአእምሮ ህሙማን መርጃ ማዕከል የድጋፍ ማሰባሰብ ዘመቻ እስኩን 120,000,000 ብር ተሰብስቧል።\n",
      "\n",
      "መቄዶንያ በሚያስገነባው ሆስፒታል ጭምር ያለው ህንፃ ለማጠናቀቅ የገንዘብ እጥረት አጋጥሞታል። ህንፃው ለማጠናቀቅ ገንዘብ ተቸግረናል። ለማጠናቀቅ ወደ 5 ቢሊዮን ብር ያስፈልጋል።\n",
      "\n",
      "በቀጥታ ይከታተሉ 👇\n",
      "https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n",
      "\n",
      "የምትችሉትን ሁሉ ድጋፍ አድርጉ።\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🔊 #የሠራተኞችድምጽ\n",
      "\n",
      "\" ቋሚ ሠራተኞች ሆነን ሳለ በደሞዝ ማሻሻያው አልተካተትንም \" - የሀዋሳ ዙሪያ ወረዳ መንግስት ሠራተኞች\n",
      "\n",
      "የማክሮ ኢኮኖሚ ማሻሻያ ሪፎርሙን ተከትሎ የሚከሰቱ የኑሮ ዉድነትና ተያያዥ ጉዳዮችን ታሳቢ በማድረግ የመንግስት ሠራተኞች ደሞዝ ማሻሻያ ተደርጎ ከጥቅምት ወር 2017 ዓ/ም ጀምሮ ተግባራዊ የተደረገ መሆኑ ይታወቃል።\n",
      "\n",
      "በሲዳማ ክልል፤ ሰሜናዊ ሲዳማ ዞን፤ ሀዋሳ ዙሪያ ወረዳ በተለያዩ የመንግስት መስሪያ ቤቶች የሚሰሩ የመንግስት ሠራተኞች ግን \" ከ2012 ዓ/ም ጀምሮ በቋሚነት ተቀጥረን እየሰራን ያለን ቢሆንም በአዲሱ የመንግስት ሠራተኞች የደመወዝ ማሻሻያ አልተካተትንም \" ሲሉ ቅሬታቸዉን ለቲክቫህ ኢትዮጵያ አስገብተዋል።\n",
      "\n",
      "ቅሬታቸዉን ካደረሱን መካከል ፦\n",
      "- በከተማ ልማትና ኮንስትራክሽን፣\n",
      "- ማዘጋጃ ቤቶች፣\n",
      "- በትምህርት ዘርፍ ፣\n",
      "- በሴቶችና ሕፃናት እንዲሁም በሕብረት ስራ ጽ/ቤቶች የሚሰሩ ሠራተኞች ናቸው።\n",
      "\n",
      "\" በወቅቱ በአግባቡ ማስታወቂያ ወጥቶ ተመዝግበንና ተወዳድረን ማለፋችን ተረጋግጦ የቋሚነት ደብዳቤ ተሰጥቶን ላለፉት አምስትና ስድስት ዓመታት ደሞዝ ሲከፈለን በቆየንባቸው መደቦች ላይ እየሰራን ባለንበት በአዲሱ የደሞዝ ማሻሻያ አለመካተታችን ለዘርፈ ብዙ ችግሮች ዳርጎናል \" ብለዋል።\n",
      "\n",
      "\" ለወረዳዉ ፐብሊክ ሰርቪስና የሰዉ ሃብት ልማት ጽ/ቤት እና ለክልሉ ፐብሊክ ሰርቪስ ቢሮ ቅሬታችንን በአካልና በፅሁፍ ብናቀርብም ተገቢዉ ምላሽ አልተሰጠንም ጉዳዩን ለኢትዮጵያ እምባ ጠባቂ ተቋም ለማቅረብ መረጃ እያደራጀን ነው \" ሲሉ ተናግረዋል።\n",
      "\n",
      "ቃላቸውን ለቲክቫህ ኢትዮጵያ የሰጡት ፤ የሀዋሳ ዙሪያ ወረዳ ፐብሊክ ሰርቪስ እና የሰዉ ሃብት ልማት ጽ/ቤት ኃላፊ አቶ ሃይሉ አቢኖ ፥ \" በወረዳዉ በ2012 ዓ/ም የነበረው አግባብነት በሌለው ቅጥር በአንድ መደብ ሶስትና አራት ሰዎችን በተደራራቢነት የመቅጠር ሁኔታዎች አሁን ለተፈጠረው ችግር ዋነኛ ምክንያት ሆኗል \" ሲሉ ገልጸዋል።\n",
      "\n",
      "ከዞኑና የክልሉ ፐብልክ ሰርቪስ ጋር በመናበብ መፍትሔ እያፈላለጉ ስለመሆኑም ጠቁመዋል።\n",
      "\n",
      "በወቅቱ ይህን ተግባር የፈፀሙ አመራሮች እና የሰዉ ሃብት ልማት ኃላፊዎች ላይ እርምጃ መወሰዱን የሚናገሩት ኃላፊዉ በወረዳዉ በዚህ መልክ ተጠቀጥረዉ በአዲሱ የደመወዝ ማሻሻያ ያልካተቱና በቀጣይ መፍትሔ የሚፈለግላቸዉ 470 በተለያዩ መስሪያ ቤቶች ዉስጥ የተለዩ ሰራተኞች ስለመኖራቸዉ አክለዋል።\n",
      "\n",
      "የሰሜናዊ ሲዳማ ዞን ፐብልክ ሰርቪስና የሰዉ ሃይል ልማት መምሪያ ኃላፊ አቶ በዛብህ ባርሶ በበኩላቸው በ2011 እና 2012 በአከባቢው ሕገወጥ ቅጥሮች መፈፀማቸውን ገልጸዋል።\n",
      "\n",
      "በወረዳዉ አጣሪ ቡድን ተቋቁሞ በአዲሱ ደሞዝ ያልተካተቱንና በወረዳው ቅጥር ያልተፈፀመባቸዉ ክፍት መደቦችን የመለየት ስራ መከናወኑን አንስተዉ በሀዋሳ ዙሪያ ወረዳ ብቻ 407 ክፍት መደቦች መኖራቸዉን ለማወቅ መቻሉን ገልፀዋል።\n",
      "\n",
      "የክልሉ የበላይ አመራሮች በሚያስቀምጡት አቅጣጫ መሰረት እነዚህን ሠራተኞች በነዚህ ክፍት መደቦች የመደልደልና ሌሎችም ሕጋዊ አመራጮች በመፈለግ በአጭር ጊዜ ዉስጥ እልባት ለመስጠት እየተሰራ መሆኑን አስታውቀዋል።\n",
      "\n",
      "ቲክቫህ ኢትዮጵያ ጉዳዩን እስከመጨረሻ ተከታትሎ መረጃውን ይልካል።\n",
      "\n",
      "#TikvahEthiopiaFamilyHW\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "የIMF ማኔጂንግ ዳይሬክተሯ ምን አሉ ?\n",
      "\n",
      "የዓለም አቀፍ የገንዘብ ተቋም (IMF) ማኔጂንግ ዳይሬክተር ክሪስታሊና ጆርጂዬቫ በኢትዮጵያ የስራ ቆይታ አድርገዋል።\n",
      "\n",
      "በዚህም ወቅት ከጠ/ሚ ዐቢይ አህመድ (ዶ/ር) ጋር ጨምሮ ከፌዴራል ከፍተኛ ባለስልጣናት ጋር መክረዋል።\n",
      "\n",
      "የነበራቸውን ቆይታ በተመለከተ ከገንዘብ ሚኒስትሩ አቶ አህመድ ሽዴ ጋር በጋራ መግለጫ ሰጥተው ነበር።\n",
      "\n",
      "ምን አሉ ?\n",
      "\n",
      "ዳይሬክተሯ ፤ \" የኢትዮጵያ ሪፎርም ከባድ እና ጊዜ የሚወስድ ነው ፤ እባካችሁ ታገሱ \" የሚል ጥሪ አቅርበዋል።\n",
      "\n",
      "ኢትዮጵያውያን ለትዕግስት እንዲያሳዩ እና ከመንግስት የኢኮኖሚ ማሻሻያ ጥረቶች ጎን እንዲቆሙ ጠይቀዋል።\n",
      "\n",
      "ጆርጂዬቫ ፥ \" የሪፎርሙን ግቦች ለማሳካት የአንድነት አስፈላጊ ነው \" ሲሉ አፅንኦት ሰጥተዋል።\n",
      "\n",
      "\" ኢትዮጵያ የተቀበለችው ሪፎርም ከባድ እና ጊዜ የሚወስድ ቢሆንም እጅግ ትልቅ ውጤት ያስገኛል \" ሲሉ ተናግረዋል።\n",
      "\n",
      "\" ህዝቡ በትዕግስት እንዲጠብቅ ጥሪዬን አቀርባለሁ \" ያሉት ማኔጂንግ ዳይሬክተሯ \" ህብረተሰቡ ከሪፎርሙ ጀርባ በመሰባሰብ በአንድነት ድጋፍ ማድረግ አለበት \" ብለዋል።\n",
      "\n",
      "ጆርጂዬቫ ፥ ኢኮኖሚውን የበለጠ አጥጋቢና ብቁ ለማድረግ ብዙ የሚሠራ ሥራ አለ \" ብለው \" እባካችሁ መንግሥት ሥራውን እንዲያጠናቅቅ ድጋፍ አድርጉ \" የሚል ጥሪ አቅርበዋል።\n",
      "\n",
      "የዋጋ ንረትን ለመፍታት የሚሰራው ስራ ውስብስብ መሆኑን ያልሸሸጉት ዳይሬክተራ \" የዋጋ ንረትን ወደ ታች ለማውረድ ጠንካራ የገንዘብና የፊስካል ፖሊሲዎች፣ የኢኮኖሚውን የማምረት አቅም ማስፋት፣ የወጪ ንግድና የውጭ ምንዛሪ ገቢን ማሳደግ እና የግሉ ሴክተርን ማብቃት ይጠይቃል \" ብለዋል።\n",
      "\n",
      "ሌላው ያነሱት ጉዳይ በG20 የጋራ ማዕቀፍ ኢትዮጵያ እያካሄደች ያለችውን የዕዳ መልሶ ማደራጀት ድርድር በተመለከተ ነው።\n",
      "\n",
      "ጆርጂዬቫ ፤ \" የዕዳ መልሶ ማዋቀር ሂደት የመጨረሻ ደረጃ ላይ ይገኛል ፤ ከኢትዮጵያ አበዳሪዎች ጋር ባለኝ ግንኙነት ይህ ቅድሚያ የሚሰጠው ጉዳይ ነው \" ሲሉ ገልጸዋል። \n",
      "\n",
      "የIMF ፕሮግራም አካል ሆነውን የታክስ እርምጃዎችን በተመለከተም ፤ የኢትዮጵያ ባለስልጣናት ለብሄራዊ በጀቱ ድጋፍ ለማድረግ ወሳኝ የሆኑ የታክስ አቅሞችን መለየታቸውን ጠቁመዋል። \n",
      "\n",
      "ጆርጂዬቫ ፥ የኢትዮጵያ አጠቃላይ የሀገር ውስጥ ምርት ዕድገት ከIMF የመጀመሪያ ትንበያዎች መብለጡን ማብራራታቸውን ዘሪፖርተር አስነብቧል።\n",
      "\n",
      "የማኔጂንግ ዳይሬክተራ ንግግር ተከትሎ \" መሬት ላይ ካለው እውነታ ጋር የሚገናኝ አይደለም \" የሚሉ አስተያየቶች ሲሰጡም ተመልክተናል።\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "ልታስመርቀዉ ከቤተሰቦቿ ተደብቃ የመጣች እጮኛዉን ጭካኔ በተሞላበት ሁኔታ የገደለዉ ግለሰብ በ20 ዓመት ጽኑ እስራት ተቀጣ።\n",
      "\n",
      "በደቡብ ኢትዮጵያ ክልል ጋሞ ዞን አርባምንጭ ከተማ አስተዳደር ጉርባ በሚባል ቀበሌ የገዛ እጮኛዉን ጭካኔ በተሞላበት መልኩ በአሰቃቂ ሁኔታ በስለት አንገቷን በመቁረጥ ሕይወቷ እንዲያልፍ ያደረገዉ ወጣት በፅኑ እስራት መቀጣቱን የአርባ ምንጭ ከተማ አስተዳደር ፖሊስ መምሪያ አዛዥ ም/ኢንስፔክተር ጋፋሮ ቶማስ ለቲክቫህ ኢትዮጵያ ተናግረዋል።\n",
      "\n",
      "የወንጀል ድርጊቱ የተፈፀመዉ ነሐሴ 16/2016 ዓ/ም በአርባምንጭ ከተማ ጉርባ ቀበሌ ነው።\n",
      "\n",
      "ተከሳሽ ዮናስ ጫፊቄ የተባለው ግለሰብ የጂንካ ዩኒቨርሲቲ 1ኛ  ዓመት ተማሪ የሆነችዉን ሟች ሊዲያ ዮሐንስ እሱን ለማስመረቅ ወደ አርባ ምንጭ ከተማ በመጣችበት ተከራይቶ በሚኖርበት ቤት አሰቃቂ ድርጊቱን መፈፀሙን የምርመራ መዝገቡ ያስረዳል።\n",
      "\n",
      "ወጣቷ \" እጮኛዬ ይመረቅልኛል \" በሚል ደስታ ከቤተሰቦቿ ተደብቃ ተከሳሽ ተከራይቶ ወደ ሚማርበት  ቤት መጥታ በዋዜማዉ ለምረቃዉ የሚሆኑ የዲኮር፣ የዳቦና ለስላሳ መጠጦችና በቡና ዝግጅት ቤቱን አሰማምራ በምሽቱም ግቢ ዉስጥ ያሉ ተከራዮችን ጠርተዉ ከሸኙ በኋላ ሟች ሀገር ሰላም ብላ በተኛችበት ከሌሊቱ 7 ሰዓት ገደማ እራሷን መከላከል በማትችልበት ሁኔታ በቢላዋ አንገቷን አርዶ መግደሉን የምርመራ መዝገቡን ዋቢ አድርገው ፖሊስ አዛዡ ገልፀዋል።\n",
      "\n",
      "ፖሊስ አዛዡ አክለው እንደገለጹት ፥ በወቅቱ በተደረገዉ ማጣራትም ሆነ በክስ መዝገቡ ላይ እንደሰፈረዉ ወንጀለኛው  \" ወደ ዩኒቨርሲቲ በሄድሽበት ሌላ የወንድ ጓደኛ ይዘሻል \" በሚል ነው በር ዘግቶ አሰቃቂ የወንጀል ድርጊቱን የፈጸመው።\n",
      "\n",
      "ፖሊስ በዚህ ዘግናኝ ወንጀል ዙሪያ ተገቢዉን ማጣራትና ምርመራ አድርጎ ለዐቃቤ ሕግ ማቅረቡን አስታውቀዋል።\n",
      "\n",
      "ዐቃቤ ሕግም ክስ በመመስረት ለፍርድ ቤቱ ተከሳሽ የወንጀል ድርጊቱን መፈፀሙን የሰዉ፣ የሰነድና የህክምና ማስረጃዎችን በማቅረብ አስረድቷል።\n",
      "\n",
      "በቀረቡ ማስረጃዎች እና ምስክሮች ግራ ቀኙን ሲያጣራ የቆየዉ የጋሞ ዞን ከፍተኛዉ ፍርድ ቤት በቀን 29/5/2017 ዓም በዋለዉ ችሎት ተከሳሽ ዮናስ ጨፊቄ በተከሰሰበት በአሰቃቂ ሁኔታ ነብስ የማጥፋት ወንጀል ጥፋተኛ መሆኑን በማረጋገጥ በ20 ዓመት ፅኑ እስራት እንዲቀጣ መወሰኑንም ኢንስፔክተር ጋፋሮ ቶማስ ለቲክቫህ ኢትዮጵያ ተናግረዋል።\n",
      "\n",
      "#TikvahEthiopiaFamilyHW\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "#መቄዶንያ\n",
      "\n",
      "\" ሰውን ለመርዳት ሰው መሆን በቂ ነው !! \"\n",
      "\n",
      "መቄዶንያ የአረጋዊያንና የአእምሮ ህሙማን መርጃ ማዕከል በሚያስገነባው ሆስፒታል ጭምር ያለው ህንፃ ለማጠናቀቅ የገንዘብ እጥረት ስለገጠመው እግዛ እንዲደረግ ለመላው ኢትዮጵያውያን ጥሪ መቅረቡ ይታወሳል።\n",
      "\n",
      "ዛሬ “ በሰይፉ ኢቢኤስ የዩቱብ ቻነል ” ድጋፍ ማድረጊያ መርሀ ግብር እየተካሄደ ነው።\n",
      "\n",
      "ደጋጎች ሁሉ ድጋፍ እንድታደርጉ ጥሪ እናቀርባለን።\n",
      "\n",
      "የድጋፍ ማድረጊያ አማራጮች ከላይ ተያይዘዋል።\n",
      "\n",
      "መቄዶንያ “ ህንፃው ለማጠናቀቅ ገንዘብ ተቸግረናል። ለማጠናቀቅ ወደ 5 ቢሊዮን ብር ያስፈልገናል ” ማለቱ አይዘነጋም።\n",
      "\n",
      "በቀጥታ ይከታተሉ 👇\n",
      "https://www.youtube.com/live/q0bMjwt9PvM?feature=shared\n",
      "\n",
      "@tikvahethiopia\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=load_data(\"datas/totaldata.json\")\n",
    "number_of_contents=len(data)\n",
    "print(f'Total number of contents: {number_of_contents}\\n')\n",
    "print(f'First 5 contents: \\n')\n",
    "for news in data[:5]:\n",
    "    print(news)\n",
    "    print(\"---------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean our data using clean_text function and sample our data to see the difference between the original and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=[clean_text(content) for content in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the total number of words and total number of unique words in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the dataset: 15290227\n",
      "\n",
      "Total number of unique words in the dataset: 832978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for news in cleaned_data:\n",
    "    news_array=news.split()\n",
    "    total+=len(news_array)\n",
    "print(f'Total number of words in the dataset: {total}\\n')\n",
    "alldata=\" \".join(cleaned_data)\n",
    "counter=Counter(alldata.split())\n",
    "print(f'Total number of unique words in the dataset: {len(counter)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data at index 37430 before cleaning: \n",
      "\n",
      " update⬆️የቴፒ ከተማ የዛሬ ጥዋት ድባብ እና አጠቃላይ የከተማዋ ሁኔታ ከከተማው ነዋሪ አምደበት።\n",
      "@tseabwolde @tikvahethiopia\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Data at index 37430 after cleaning: \n",
      "\n",
      " የቴፒ ከተማ የዛሬ ጥዋት ድባብ እና አጠቃላይ የከተማዋ ሁኔታ ከከተማው ነዋሪ አምደበት።\n"
     ]
    }
   ],
   "source": [
    "index=37430\n",
    "print(f\"Data at index {index} before cleaning: \\n\\n\",data[index])\n",
    "print(\"\\n---------------------------------------------------------------------------------\\n\\n\")\n",
    "print(f\"Data at index {index} after cleaning: \\n\\n\",cleaned_data[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, We Will Train the Tokenizer\n",
    "\n",
    "Tokenization is a critical step in natural language processing (NLP) as it converts raw text into smaller, meaningful units (tokens) that can be processed by machine learning models. Effective tokenization ensures that the model can understand and interpret the text accurately, which is essential for tasks like text classification, machine translation, and sentiment analysis.\n",
    "\n",
    "For this task, we will use the **SentencePiece tokenizer** instead of traditional word-based tokenization. The [SentencePieceTokenizer](https://www.tensorflow.org/text/api_docs/python/text/SentencepieceTokenizer) is a powerful tool that tokenizes text into **subword units**, which offers several advantages:\n",
    "\n",
    "1. **Handling Complex Word Structures**: SentencePiece breaks words into smaller subword units, making it effective for handling complex word structures and morphological variations, which are common in languages like Amharic.\n",
    "2. **Out-of-Vocabulary (OOV) Words**: By using subword tokenization, SentencePiece can handle out-of-vocabulary words more gracefully, as it can decompose them into known subword units.\n",
    "3. **Multilingual Support**: SentencePiece is language-agnostic, making it suitable for multilingual datasets. This is particularly useful for Amharic, as it can handle the repetition of common subwords and morphological patterns unique to the language.\n",
    "4. **Simplified Preprocessing**: SentencePiece works directly on raw text, eliminating the need for extensive preprocessing steps like word segmentation or stemming.\n",
    "5. **Seamless Integration**: It integrates seamlessly with popular machine learning frameworks like TensorFlow and PyTorch, ensuring consistent tokenization across training and inference pipelines.\n",
    "\n",
    "Given these benefits, SentencePiece is an ideal choice for tokenizing Amharic text, as it can effectively capture the language's unique characteristics while simplifying the overall preprocessing workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train sentencepiece tokenizer model first. in order to do that we need to save our cleaned data into a single corpus of text in .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"datas/cleaned_data.txt\", \"a\") as file:\n",
    "  #  for content in cleaned_data:\n",
    "   #     file.write(content + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SentencePiece model...\n",
      "Training complete! Check 'amharic_bpe.model' and 'amharic_bpe.vocab'.\n"
     ]
    }
   ],
   "source": [
    "input_file=\"datas/cleaned_data.txt\"\n",
    "model_prefix=\"amharic_sp_model\"\n",
    "print(\"Training SentencePiece model...\")\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=input_file,\n",
    "    model_prefix=model_prefix,\n",
    "    vocab_size=100000,  \n",
    "    model_type=\"unigram\",  \n",
    "    character_coverage=0.995, \n",
    "    num_threads=6,  \n",
    "    max_sentence_length=8192, \n",
    "    split_by_whitespace=True,\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3,\n",
    "    \n",
    ")\n",
    "print(\"Training complete! Check 'amharic_bpe.model' and 'amharic_bpe.vocab'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the sentencepeice tokenizer the next step is to load the trainied tokenizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=spm.SentencePieceProcessor(model_file=\"amharic_sp_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows the process of tokenizing individual words from a given text, in this case, the first entry of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t-->\tTokenization\n",
      "----------------------------------------\n",
      "በአማራ    \t-->\t[1726]\n",
      "ክልል     \t-->\t[232]\n",
      "መዲና     \t-->\t[5826]\n",
      "በባህር    \t-->\t[6029]\n",
      "ዳር      \t-->\t[1547]\n",
      "ከተማ     \t-->\t[138]\n",
      "ቀበሌ     \t-->\t[1545]\n",
      "14      \t-->\t[1416]\n",
      "ትላንት    \t-->\t[1487]\n",
      "መጋቢት    \t-->\t[2829]\n",
      "29      \t-->\t[2395]\n",
      "የመግሪብ   \t-->\t[65, 1861, 63806]\n",
      "ሰላት     \t-->\t[33875]\n",
      "ሰግደው    \t-->\t[35304, 477]\n",
      "ሲመለሱ    \t-->\t[10897]\n",
      "የነበሩ    \t-->\t[813]\n",
      "አባት     \t-->\t[3025]\n",
      "ከ3      \t-->\t[10, 63881]\n",
      "ልጆቹ     \t-->\t[14460]\n",
      "እንዲሁም   \t-->\t[341]\n",
      "አንድ     \t-->\t[288]\n",
      "ጎረቤታቸውን \t-->\t[13729, 414]\n",
      "ጨምሮ     \t-->\t[764]\n",
      "አጠቃላይ   \t-->\t[1702]\n",
      "5       \t-->\t[282]\n",
      "ሰዎች     \t-->\t[145]\n",
      "በተከፈተባቸው\t-->\t[57975]\n",
      "የጥይት    \t-->\t[16952]\n",
      "እሩምታ    \t-->\t[35094]\n",
      "መገደላቸው  \t-->\t[10259]\n",
      "ተነግሯል።  \t-->\t[1870]\n",
      "ትላንትና   \t-->\t[14406]\n",
      "ምሽት     \t-->\t[1432]\n",
      "በግፍ     \t-->\t[13623]\n",
      "የተገደሉት  \t-->\t[11758]\n",
      "፥       \t-->\t[63778, 1]\n",
      "አቶ      \t-->\t[259]\n",
      "ሙሄ      \t-->\t[63271]\n",
      "፣       \t-->\t[163]\n",
      "ልጃቸው    \t-->\t[9830]\n",
      "አበባዉ    \t-->\t[250, 63899]\n",
      "ሙሄ      \t-->\t[63271]\n",
      "፣       \t-->\t[163]\n",
      "ሽኩር     \t-->\t[36738]\n",
      "ሙሄ      \t-->\t[63271]\n",
      "፣       \t-->\t[163]\n",
      "ሙላት     \t-->\t[16086]\n",
      "ሙሄ      \t-->\t[63271]\n",
      "እና      \t-->\t[24]\n",
      "ጎረቤታቸው  \t-->\t[13729, 247]\n",
      "አቶ      \t-->\t[259]\n",
      "እንድሪስ   \t-->\t[27390]\n",
      "የተባሉ    \t-->\t[3574]\n",
      "ሲሆኑ     \t-->\t[2709]\n",
      "ስርዓት    \t-->\t[2487]\n",
      "ቀብራቸው   \t-->\t[24146]\n",
      "በዛሬው    \t-->\t[1090]\n",
      "ዕለት     \t-->\t[880]\n",
      "ተፈፅሟል።  \t-->\t[15961]\n",
      "እስካሁን   \t-->\t[1212]\n",
      "ገዳዮች    \t-->\t[29580]\n",
      "ስለመያዛቸው \t-->\t[2568, 15698]\n",
      "የተባለ    \t-->\t[1962]\n",
      "ነገር     \t-->\t[390]\n",
      "የለም።    \t-->\t[2970]\n",
      "በከተማዋ   \t-->\t[3427]\n",
      "ከተገደሉት  \t-->\t[17735]\n",
      "ሰዎች     \t-->\t[145]\n",
      "ባሻገር    \t-->\t[5139]\n",
      "ባህርዳር   \t-->\t[6569]\n",
      "ከተማ     \t-->\t[138]\n",
      "አባይ     \t-->\t[9055]\n",
      "ማዶ      \t-->\t[13789]\n",
      "የሚገኘው   \t-->\t[1789]\n",
      "መስጂድ    \t-->\t[14946]\n",
      "ከፍተኛ    \t-->\t[313]\n",
      "የመሳሪያ   \t-->\t[23344]\n",
      "ድብደባ    \t-->\t[5713]\n",
      "እንደተፈፀመበት\t-->\t[45567]\n",
      "ተገልጿል።  \t-->\t[685]\n",
      "ከዚሁ     \t-->\t[10618]\n",
      "ጋር      \t-->\t[94]\n",
      "በተያያዘ   \t-->\t[1804]\n",
      "ዛሬ      \t-->\t[322]\n",
      "የባህር    \t-->\t[4062]\n",
      "ዳር      \t-->\t[1547]\n",
      "ሙስሊሞች   \t-->\t[16778]\n",
      "በክልሉ    \t-->\t[1782]\n",
      "በሙስሊሞች  \t-->\t[5, 45791]\n",
      "ላይ      \t-->\t[30]\n",
      "አነጣጥረዋል \t-->\t[3637, 3586, 3614]\n",
      "ያሉትን    \t-->\t[4749]\n",
      "ግድያ     \t-->\t[2482]\n",
      "እና      \t-->\t[24]\n",
      "እገታ     \t-->\t[10792]\n",
      "በመቃወም   \t-->\t[7940]\n",
      "ሰልፍ     \t-->\t[2615]\n",
      "ማድረጋቸውን \t-->\t[6725]\n",
      "\"       \t-->\t[57]\n",
      "ሀሩን     \t-->\t[44512]\n",
      "ሚዲያ     \t-->\t[1353]\n",
      "\"       \t-->\t[57]\n",
      "ዘግቧል።   \t-->\t[1611]\n",
      "እስካሁን   \t-->\t[1212]\n",
      "በአማራ    \t-->\t[1726]\n",
      "ክልል     \t-->\t[232]\n",
      "እስልምና   \t-->\t[7312]\n",
      "ጉዳዮች    \t-->\t[1011]\n",
      "ከፍተኛ    \t-->\t[313]\n",
      "ምክር     \t-->\t[754]\n",
      "ቤትም     \t-->\t[12876]\n",
      "ሆነ      \t-->\t[526]\n",
      "በኢትዮጵያ  \t-->\t[605]\n",
      "እስልምና   \t-->\t[7312]\n",
      "ጉዳዮች    \t-->\t[1011]\n",
      "ጠቅላይ    \t-->\t[736]\n",
      "ምክር     \t-->\t[754]\n",
      "ቤት      \t-->\t[170]\n",
      "የተሰጠ    \t-->\t[4046]\n",
      "አስተያየት  \t-->\t[2116]\n",
      "የለም።    \t-->\t[2970]\n",
      "ቲክቫህ    \t-->\t[3268]\n",
      "ኢትዮጵያ   \t-->\t[211]\n",
      "በክልሉ    \t-->\t[1782]\n",
      "ተፈፅመዋል  \t-->\t[49497]\n",
      "ስለተባሉ   \t-->\t[3927, 2528]\n",
      "ግድያዎች   \t-->\t[20150]\n",
      "፣       \t-->\t[163]\n",
      "ጥቃቶች    \t-->\t[5466]\n",
      "፣       \t-->\t[163]\n",
      "ዘረፋና    \t-->\t[37608]\n",
      "እገታዎች   \t-->\t[61313]\n",
      "የአማራ    \t-->\t[1564]\n",
      "ክልል     \t-->\t[232]\n",
      "እስልምና   \t-->\t[7312]\n",
      "ጉዳዮች    \t-->\t[1011]\n",
      "ከፍተኛ    \t-->\t[313]\n",
      "ምክር     \t-->\t[754]\n",
      "ቤት      \t-->\t[170]\n",
      "እና      \t-->\t[24]\n",
      "የሚመለከታቸው\t-->\t[6967]\n",
      "አካላትን   \t-->\t[5897]\n",
      "ለማነጋገር  \t-->\t[20151]\n",
      "ጥረት     \t-->\t[1474]\n",
      "እያደረገ   \t-->\t[2747]\n",
      "ይገኛል፤   \t-->\t[31579]\n",
      "ምላሽ     \t-->\t[1223]\n",
      "እንዳገኘ   \t-->\t[18773]\n",
      "ተጨማሪ    \t-->\t[969]\n",
      "መረጃዎችን  \t-->\t[3226]\n",
      "ያቀርባል።  \t-->\t[17440]\n"
     ]
    }
   ],
   "source": [
    "# printing the encoding of each word to see how subwords are tokenized\n",
    "tokenized_text = [(list(tokenizer.tokenize(word)), word) for word in cleaned_data[3000].split()]\n",
    "\n",
    "print(\"Word\\t\\t-->\\tTokenization\")\n",
    "print(\"-\"*40)\n",
    "for element in tokenized_text:\n",
    "    print(f\"{element[1]:<8}\\t-->\\t{element[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take data from the cleaned_data  and see how the tokenization of the whole content looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data at index 890 before tokenization: \" ሰላም ከአንገት በላይና ዝም ላለማለት ያህል የምንናገረው ሳይሆን ዋጋ ከፍለን የምናመጣው ነው \" - ቅዱስነታቸው ዛሬ የሰላም ሚኒስቴር አንድ ዓለም አቀፍ ኮንፈረንስ አዘጋጅቶ ነበር። በዚህ መድረክ ላይም የሰላም ሚኒስትር አቶ ብናልፍ አዱዓለም ፣ የኢትዮጵያ የሃይማኖት ተቋማት የበላይ ጠባቂ አባቶች፣ ብፁዓን አበው ሊቃነ ጳጳሳት ወኤጲስ ቆጶሳት ፣ የመንግሥት ባለስልጣናት ፣ አባሳደሮች ጭምር ተገኝተው ነበር። በመድረኩ ፤ ብፁዕ ወቅዱስ አቡነ ማትያስ ቀዳማዊ ፓትርያርክ ርእሰ ሊቃነ ጳጳሳት ዘኢትዮጵያ ሊቀ ጳጳስ ዘአክሱም ወእጨጌ ዘመንበረ ተክለሃይማኖት መልዕክት አስተላልፈዋል። ቅዱስነታቸው ምን አሉ ? (ከመልዕክታቸው የተወሰደ) \" ሰላም የሰው ልጆች ፍላጎት፣ የብዙ ምንዱባን የየዕለት ናፍቆት ነው። የበርካታ ዘመናት ቅርሶች፤ ጊዜ፣ ገንዘብ እና የሰው ጉልበት የፈሰሰባቸው ግንባታዎች በሰላም ማጣት በቅጽበት ይፈርሳሉ። ሰላም ካለ የዓለም ሀብት ለሁሉም በቂ ነው። ሰላም ማጣት ግን ብዙ ሠራዊት፣ ብዙ የጦር መሳሪያ እንዲዘጋጅ እያደረገ ሀብትን ያወድማል። ጦርነት ማለት ሀብትና ሕይወትን ወደሚነድ እሳት ውስጥ መጣል ነው። የአንደኛና የሁለተኛ ዓለም ጦርነት፣ ታሪክ ብቻ ሳይሆን ጠባሳው አሁንም የዓለምን መልክ አበላሽቶታል። ሰላም በውስጥዋ ገራምነት፣ ትዕግሥት፣ ታዛዥነትና በትህትና ዝቅ ማለት ስለሚገኙ መራራ ትመስላለች፤ በውጤቷ ግን ሀገርን ከጥፋት፣ ሕዝብን ከመከራ ማትረፍ የሚቻል በመሆኑ ዋጋዋ ከፍ ያለ ነው። ቅድስት ቤተ ክርስቲያናችን ፦ ° ሰላም የሆነው ክርስቶስ የሚሰበክባት፣ ° የሰላም መልእክተኞች በውስጥዋ የሚመላለሱባት፣ ° በግብረ ኃጢአት የወደቁት በንስሓ ከእግዚአብሔር ጋር የሚታረቁባት የሰላም ድልድይ ስለሆነች በሥርዓተ ቅዳሴዋ ሰላምን ደጋግማ ታውጃለች፤ በጸሎቷ ለመላው ዓለም ሰላምን ትለምናለች፤ በጉልላትዋ ላይ የሰቀለችው መስቀልም ሰላምን የሚሰብክ ነው፤ የመስቀሉ ቅርፅ ወደ ላይና ወደ ጎን መሆኑም ከእግዚአብሔርና ከሰው ጋር ሰላም መሆን እንዳለብን የሚያስገነዝበን ነው። ታሪካችን እንደሚነግረን ወንድማማቾች ሲጋደሉ፣ በሕዝብ መካከል መተላለቅ ሲመጣ ቤተ ክርስቲያን ታቦት አክብራ፣ በእሳት መካከል ገብታ ሰላምን ስታወርድ የኖረች ናት። በሀገር ውስጥ ግጭቶች በተፈጠሩበት ጊዜም የሰላም ጥሪን ያላስተላለፈችበት ቀንና ሰዓት አይገኝም፡፡ ሰላምን የመወያያ ርእስ አድርገን ስንሰባስብ በጦርነት መካከል የተጨነቁ ሕዝቦች፣ ራሳቸውን መከላከል የማይችሉ እና ምን እየተደረገ እንዳለ በውል የማይገነዘቡ ደካሞች ተስፋ ያደርጉናል። ስለዚህ ሰላም ከአንገት በላይና ዝም ላለማለት ያህል የምንናገረው ሳይሆን ዋጋ ከፍለን የምናመጣው ስለሆነ ይህ ጉባኤ ከውይይት ባሻገር በተግባር ጭምር የሰላም ተምሳሌት መሆን እንደሚገባው ለማሳሰብ እንወዳለን። \" (ሙሉ መልዕክታቸው ከላይ ተያይዟል)\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Data at index 890 after tokenization:  [14, 302, 43245, 42, 9, 2331, 37977, 512, 470, 85965, 464, 253, 26895, 82905, 15, 14, 20, 13326, 57, 413, 98, 60, 260, 169, 4331, 6235, 150, 117, 820, 10, 8, 413, 125, 44, 20762, 41831, 7207, 33, 49, 2386, 175, 3828, 1077, 8591, 11239, 13264, 4076, 4, 1, 1914, 341, 640, 1, 78, 4405, 1, 1914, 33, 824, 750, 33, 1272, 741, 33116, 976, 1712, 150, 3598, 70, 2416, 3762, 1418, 4528, 4776, 3102, 3686, 4076, 4, 1, 1914, 8056, 1537, 4, 1, 78, 1420, 9140, 341, 1534, 9197, 337, 3875, 9931, 455, 3299, 13326, 107, 713, 135, 29, 330, 78447, 3799, 34, 14, 302, 550, 737, 461, 13, 7905, 4, 82566, 11, 57955, 23146, 35, 5899, 12034, 6409, 40, 38, 13, 242, 7, 550, 6417, 11, 26756, 277, 12721, 655, 5382, 6, 41824, 69299, 32, 302, 1205, 459, 1059, 2044, 722, 35, 302, 5382, 55, 228, 19167, 228, 472, 610, 18291, 998, 30048, 95209, 32, 334, 406, 17334, 25171, 16, 457, 26524, 1762, 23, 9930, 35, 5276, 9, 2199, 260, 334, 13, 458, 76, 464, 13472, 22, 382, 459, 5, 1552, 79770, 1910, 302, 6291, 353, 4, 12544, 8, 17829, 51736, 13, 4, 90352, 9, 12318, 2654, 406, 18296, 21698, 52377, 40, 6, 37647, 2381, 55, 162, 5, 17892, 13, 11472, 12, 36295, 6815, 13053, 317, 253, 353, 642, 182, 35, 3748, 586, 18878, 218, 4, 1, 302, 532, 5930, 20707, 204, 220, 36963, 4, 1, 413, 82240, 6291, 353, 51140, 36963, 4, 1, 26825, 4445, 1, 7663, 67691, 6, 5, 78, 1, 25914, 17, 352, 39806, 937, 413, 2805, 27495, 36749, 23030, 353, 4018, 36594, 15010, 2612, 36501, 6, 88354, 2902, 260, 4018, 4, 24, 6308, 9, 36501, 6, 94522, 353, 10, 11, 55032, 1431, 1064, 8, 4018, 74659, 1286, 77950, 10479, 16, 10, 9, 16, 1160, 3091, 25914, 9, 4908, 17, 302, 397, 12955, 81805, 204, 5, 35, 30394, 64, 73782, 10677, 210, 58238, 13, 5301, 97, 197, 81257, 4822, 586, 936, 17534, 66722, 13, 3045, 97, 12996, 4018, 3755, 9326, 44290, 3145, 1114, 23, 2523, 16629, 69, 38, 8, 413, 226, 5, 99213, 4793, 47, 9, 90, 21116, 84, 4018, 30556, 14552, 5314, 2957, 67967, 3232, 97, 75389, 4144, 13, 2334, 1113, 7594, 7, 107, 778, 856, 5061, 1593, 30894, 9460, 678, 17474, 5179, 1263, 302, 43245, 42, 9, 2331, 37977, 512, 470, 85965, 464, 253, 26895, 82905, 1149, 103, 552, 12, 41082, 2231, 4329, 976, 413, 10344, 397, 7504, 21800, 11085, 14, 29, 4545, 18864, 624, 1510, 1, 73, 34]\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Data at index 890 after detokenization: ['▁\"', '▁ሰላም', '▁ከአንገት', '▁በላይ', 'ና', '▁ዝም', '▁ላለማ', 'ለት', '▁ያህል', '▁የምንናገረው', '▁ሳይሆን', '▁ዋጋ', '▁ከፍለን', '▁የምናመጣው', '▁ነው', '▁\"', '▁-', '▁ቅዱስነታቸው', '▁ዛሬ', '▁የሰላም', '▁ሚኒስቴር', '▁አንድ', '▁ዓለም', '▁አቀፍ', '▁ኮንፈረንስ', '▁አዘጋጅቶ', '▁ነበር።', '▁በዚህ', '▁መድረክ', '▁ላይ', 'ም', '▁የሰላም', '▁ሚኒስትር', '▁አቶ', '▁ብናልፍ', '▁አዱ', 'ዓለም', '▁፣', '▁የኢትዮጵያ', '▁የሃይማኖት', '▁ተቋማት', '▁የበላይ', '▁ጠባቂ', '▁አባቶች፣', '▁ብፁዓን', '▁አበው', '▁ሊቃነ', '▁', 'ጳጳ', 'ሳት', '▁ወ', 'ኤ', 'ጲ', 'ስ', '▁ቆ', 'ጶ', 'ሳት', '▁፣', '▁የመንግሥት', '▁ባለስልጣናት', '▁፣', '▁አባ', 'ሳ', 'ደሮች', '▁ጭምር', '▁ተገኝተው', '▁ነበር።', '▁በመድረኩ', '▁፤', '▁ብፁዕ', '▁ወቅዱስ', '▁አቡነ', '▁ማትያስ', '▁ቀዳማዊ', '▁ፓትርያርክ', '▁ርእሰ', '▁ሊቃነ', '▁', 'ጳጳ', 'ሳት', '▁ዘኢትዮጵያ', '▁ሊቀ', '▁', 'ጳጳ', 'ስ', '▁ዘ', 'አክሱም', '▁ወ', 'እ', 'ጨጌ', '▁ዘመን', 'በረ', '▁ተክለሃይማኖት', '▁መልዕክት', '▁አስተላልፈዋል።', '▁ቅዱስነታቸው', '▁ምን', '▁አሉ', '▁?', '▁(', 'ከ', 'መልዕክታቸው', '▁የተወሰደ', ')', '▁\"', '▁ሰላም', '▁የሰው', '▁ልጆች', '▁ፍላጎት', '፣', '▁የብዙ', '▁', 'ምንዱባን', '▁የ', 'የዕለት', '▁ናፍቆት', '▁ነው።', '▁የበርካታ', '▁ዘመናት', '▁ቅርሶች', '፤', '▁ጊዜ', '፣', '▁ገንዘብ', '▁እና', '▁የሰው', '▁ጉልበት', '▁የ', 'ፈሰሰ', 'ባቸው', '▁ግንባታዎች', '▁በሰላም', '▁ማጣት', '▁በ', 'ቅጽበት', '▁ይፈርሳሉ', '።', '▁ሰላም', '▁ካለ', '▁የዓለም', '▁ሀብት', '▁ለሁሉም', '▁በቂ', '▁ነው።', '▁ሰላም', '▁ማጣት', '▁ግን', '▁ብዙ', '▁ሠራዊት፣', '▁ብዙ', '▁የጦር', '▁መሳሪያ', '▁እንዲዘጋጅ', '▁እያደረገ', '▁ሀብትን', '▁ያወድማል', '።', '▁ጦርነት', '▁ማለት', '▁ሀብትና', '▁ሕይወትን', '▁ወደ', 'ሚ', 'ነድ', '▁እሳት', '▁ውስጥ', '▁መጣል', '▁ነው።', '▁የአንደኛ', 'ና', '▁የሁለተኛ', '▁ዓለም', '▁ጦርነት', '፣', '▁ታሪክ', '▁ብቻ', '▁ሳይሆን', '▁ጠባሳ', 'ው', '▁አሁንም', '▁የዓለም', 'ን', '▁መልክ', '▁አበላሽቶ', 'ታል።', '▁ሰላም', '▁በውስጥ', 'ዋ', '▁', 'ገራ', 'ም', 'ነት፣', '▁ትዕግሥት', '፣', '▁', 'ታዛዥነት', 'ና', '▁በትህትና', '▁ዝቅ', '▁ማለት', '▁ስለሚገኙ', '▁መራራ', '▁ትመስላለች', '፤', '▁በ', 'ውጤ', 'ቷ', '▁ግን', '▁ሀገር', 'ን', '▁ከጥፋት', '፣', '▁ሕዝብን', '▁ከ', 'መከራ', '▁ማትረፍ', '▁የሚቻል', '▁በመሆኑ', '▁ዋጋ', 'ዋ', '▁ከፍ', '▁ያለ', '▁ነው።', '▁ቅድስት', '▁ቤተ', '▁ክርስቲያናችን', '▁፦', '▁', '°', '▁ሰላም', '▁የሆነው', '▁ክርስቶስ', '▁የሚሰ', 'በ', 'ክ', 'ባት፣', '▁', '°', '▁የሰላም', '▁መልእክተኞች', '▁በውስጥ', 'ዋ', '▁የሚመላለሱ', 'ባት፣', '▁', '°', '▁በግብረ', '▁ኃ', 'ጢ', 'አት', '▁የወደቁት', '▁በ', 'ን', 'ስ', 'ሓ', '▁ከእግዚአብሔር', '▁ጋር', '▁የሚ', 'ታረቁ', 'ባት', '▁የሰላም', '▁ድልድይ', '▁ስለሆነች', '▁በሥርዓተ', '▁ቅዳሴ', 'ዋ', '▁ሰላምን', '▁ደጋግማ', '▁ታው', 'ጃ', 'ለች፤', '▁በ', 'ጸሎቷ', '▁ለመላው', '▁ዓለም', '▁ሰላምን', '▁', 'ት', 'ለም', 'ና', 'ለች፤', '▁በ', 'ጉልላት', 'ዋ', '▁ላይ', '▁የ', 'ሰቀለ', 'ችው', '▁መስቀል', 'ም', '▁ሰላምን', '▁የሚሰብክ', '▁ነው፤', '▁የመስቀሉ', '▁ቅርፅ', '▁ወደ', '▁ላይ', 'ና', '▁ወደ', '▁ጎን', '▁መሆኑም', '▁ከእግዚአብሔር', 'ና', '▁ከሰው', '▁ጋር', '▁ሰላም', '▁መሆን', '▁እንዳለብን', '▁የሚያስገነዝ', 'በ', 'ን', '▁ነው።', '▁ታሪካችን', '▁እንደ', 'ሚነግረን', '▁ወንድማማቾች', '▁ሲ', 'ጋደሉ', '፣', '▁በሕዝብ', '▁መካከል', '▁መ', 'ተላለቅ', '▁ሲመጣ', '▁ቤተ', '▁ክርስቲያን', '▁ታቦት', '▁አክብራ', '፣', '▁በእሳት', '▁መካከል', '▁ገብታ', '▁ሰላምን', '▁ስታ', 'ወርድ', '▁የኖረች', '▁ናት።', '▁በሀገር', '▁ውስጥ', '▁ግጭቶች', '▁በተፈጠሩ', 'በት', '▁ጊዜ', 'ም', '▁የሰላም', '▁ጥሪ', 'ን', '▁ያላስተላለፈ', 'ችበት', '▁ቀን', 'ና', '▁ሰዓት', '▁አይገኝም', '፡፡', '▁ሰላምን', '▁የመወያያ', '▁ርእስ', '▁አድርገን', '▁ስን', 'ሰባስብ', '▁በጦርነት', '▁መካከል', '▁የተጨነቁ', '▁ሕዝቦች', '፣', '▁ራሳቸውን', '▁መከላከል', '▁የማይችሉ', '▁እና', '▁ምን', '▁እየተደረገ', '▁እንዳለ', '▁በውል', '▁የማይ', 'ገነዘቡ', '▁ደካሞች', '▁ተስፋ', '▁ያደርጉ', 'ናል።', '▁ስለዚህ', '▁ሰላም', '▁ከአንገት', '▁በላይ', 'ና', '▁ዝም', '▁ላለማ', 'ለት', '▁ያህል', '▁የምንናገረው', '▁ሳይሆን', '▁ዋጋ', '▁ከፍለን', '▁የምናመጣው', '▁ስለሆነ', '▁ይህ', '▁ጉባኤ', '▁ከ', 'ውይይት', '▁ባሻገር', '▁በተግባር', '▁ጭምር', '▁የሰላም', '▁ተምሳሌት', '▁መሆን', '▁እንደሚገባው', '▁ለማሳሰብ', '▁እንወዳለን።', '▁\"', '▁(', 'ሙሉ', '▁መልዕክታቸው', '▁ከላይ', '▁ተያይ', 'ዟ', 'ል', ')']\n"
     ]
    }
   ],
   "source": [
    "index=890\n",
    "print(f\"Data at index {index} before tokenization:\", cleaned_data[index])\n",
    "print(\"\\n---------------------------------------------------------------------------------\")\n",
    "print(f\"Data at index {index} after tokenization: \", tokenizer.encode(cleaned_data[index]))\n",
    "print(\"\\n---------------------------------------------------------------------------------\")\n",
    "print(f\"Data at index {index} after detokenization:\", tokenizer.encode_as_pieces(cleaned_data[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pretrain our Transformer network, we will use the Masked Language Model (MLM) approach. This technique involves randomly masking a percentage of words in a sentence and replacing them with special tokens. The model then attempts to predict these masked words, enabling it to learn contextual and semantic representations effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be implementing the Masked language model (MLM) as shown in the following image. \n",
    "\n",
    "<img src = \"images/losses.png\" width=\"600\" height = \"400\">\n",
    "\n",
    "Assume you have the following text: <span style = \"color:blue\"> **ሰላም <span style = \"color:red\">የሰው ልጆች </span> ፍላጎት፣ የብዙ ምንዱባን የየዕለት <span style = \"color:red\">ናፍቆት</span>  ነው።** </span>     \n",
    "\n",
    "\n",
    "Now as input you will mask the words in red in the text: \n",
    "\n",
    "<span style = \"color:blue\"> **Input:**</span> ሰላም  **X** ፍላጎት፣ የብዙ ምንዱባን የየዕለት **Y** ነው።\n",
    "\n",
    "<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**. \n",
    "\n",
    "**[EOS]** will be used to mark the end of the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, I were able to take a piece of string and tokenize it. \n",
    "\n",
    "Now I will create `input` and `target` pairs that will allow me to pre-train the model. The model uses the ids at the end of the vocab file as sentinels. For example, it will replace: \n",
    "   - `vocab_size - 1` by `<Z>`\n",
    "   - `vocab_size - 2` by `<Y>`\n",
    "   - and so forth. \n",
    "   \n",
    "It assigns every word a `chr`.\n",
    "\n",
    "The `pretty_decode` function below, which I will use in a bit, helps in handling the type when decoding. \n",
    "\n",
    "Notice that:\n",
    "```python\n",
    "string.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinels(tokenizer, display=False):\n",
    "    sentinels = {}\n",
    "    vocab_size = tokenizer.vocab_size()\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = tokenizer.detokenize([vocab_size - i])\n",
    "        \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'    \n",
    "    \n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "\n",
    "    return sentinels\n",
    "\n",
    "\n",
    "def pretty_decode(encoded_str_list, sentinels, tokenizer):\n",
    "    # If already a string, just do the replacements.\n",
    "    if isinstance(encoded_str_list, str):\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = re.sub(re.escape(token), char, encoded_str_list)\n",
    "        return encoded_str_list\n",
    "  \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(tokenizer.detokenize(encoded_str_list), sentinels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentinel is <Z> and the decoded token is: ጂዮፖሊታን\n",
      "The sentinel is <Y> and the decoded token is: ኮሌጃችን\n",
      "The sentinel is <X> and the decoded token is: ብሮንዝ\n",
      "The sentinel is <W> and the decoded token is: ኮንቲኔ\n",
      "The sentinel is <V> and the decoded token is: አፈግፍገ\n",
      "The sentinel is <U> and the decoded token is: አይምሮአችን\n",
      "The sentinel is <T> and the decoded token is: የተወጠረ\n",
      "The sentinel is <S> and the decoded token is: ያካብቱ\n",
      "The sentinel is <R> and the decoded token is: ይበረታል\n",
      "The sentinel is <Q> and the decoded token is: ጂአንግ\n",
      "The sentinel is <P> and the decoded token is: ያስችሉታል\n",
      "The sentinel is <O> and the decoded token is: ,744\n",
      "The sentinel is <N> and the decoded token is: ወጤታማ\n",
      "The sentinel is <M> and the decoded token is: እሰጣችኋለሁ\n",
      "The sentinel is <L> and the decoded token is: ያሳምነኝ\n",
      "The sentinel is <K> and the decoded token is: በትምርት\n",
      "The sentinel is <J> and the decoded token is: ያስፈልጋችኋል\n",
      "The sentinel is <I> and the decoded token is: አልሆነልኝም\n",
      "The sentinel is <H> and the decoded token is: ትጠልቅ\n",
      "The sentinel is <G> and the decoded token is: ጠፈጠፍ\n",
      "The sentinel is <F> and the decoded token is: አጽማቸው\n",
      "The sentinel is <E> and the decoded token is: ብትወድቅ\n",
      "The sentinel is <D> and the decoded token is: ማስፈተናቸው\n",
      "The sentinel is <C> and the decoded token is: ጋረደች\n",
      "The sentinel is <B> and the decoded token is: ኮንቲነር\n",
      "The sentinel is <A> and the decoded token is: አስተኝታ\n",
      "The sentinel is <z> and the decoded token is: እንድታከብሩ\n",
      "The sentinel is <y> and the decoded token is: ሥልጤ\n",
      "The sentinel is <x> and the decoded token is: የለሾች\n",
      "The sentinel is <w> and the decoded token is: የሰበሰበችው\n",
      "The sentinel is <v> and the decoded token is: ግርፋቱ\n",
      "The sentinel is <u> and the decoded token is: ቀላቅለዋል\n",
      "The sentinel is <t> and the decoded token is: መለጠጥ\n",
      "The sentinel is <s> and the decoded token is: አልቀርም\n",
      "The sentinel is <r> and the decoded token is: ውጥኖች\n",
      "The sentinel is <q> and the decoded token is: በሚያስኬደ\n",
      "The sentinel is <p> and the decoded token is: እየቀረፈ\n",
      "The sentinel is <o> and the decoded token is: ሰበሰቧቸ\n",
      "The sentinel is <n> and the decoded token is: ያክብርልን\n",
      "The sentinel is <m> and the decoded token is: የደበደበው\n",
      "The sentinel is <l> and the decoded token is: ደባለቁ\n",
      "The sentinel is <k> and the decoded token is: መብቶቻችን\n",
      "The sentinel is <j> and the decoded token is: ትህምርት\n",
      "The sentinel is <i> and the decoded token is: ካልሰበ\n",
      "The sentinel is <h> and the decoded token is: ዲፕሬሽን\n",
      "The sentinel is <g> and the decoded token is: ተቆረሰ\n",
      "The sentinel is <f> and the decoded token is: በማጣቴ\n",
      "The sentinel is <e> and the decoded token is: 60.88\n",
      "The sentinel is <d> and the decoded token is: ሚያዋጡት\n",
      "The sentinel is <c> and the decoded token is: ፉለር\n",
      "The sentinel is <b> and the decoded token is: ኮሪደሩ\n",
      "The sentinel is <a> and the decoded token is: እየተቀነሰ\n"
     ]
    }
   ],
   "source": [
    "sentinels = get_sentinels(tokenizer, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the `pretty_decode` function in the following sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-5'></a>\n",
    "### 3.4 - Tokenizing and Masking\n",
    "\n",
    "In this task, I will implement the `tokenize_and_mask` function, which tokenizes and masks input words based on a given probability. The probability is controlled by the `noise` parameter, typically set to mask around `15%` of the words in the input text. The function will generate two lists of tokenized sequences following the algorithm outlined below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  tokenize_and_mask\n",
    "\n",
    "- Start with two empty lists: `inps` and `targs`\n",
    "- Tokenize the input text using the given tokenizer.\n",
    "- For each `token` in the tokenized sequence:\n",
    "  - Generate a random number(simulating a weighted coin toss)\n",
    "  - If the random value is greater than the given threshold(noise):\n",
    "    - Add the current token to the `inps` list\n",
    "  - Else:\n",
    "    - If a new sentinel must be included:\n",
    "      - Compute the next sentinel ID using a progression.\n",
    "      - Add a sentinel into the `inps` and `targs` to mark the position of the masked element.\n",
    "    - Add the current token to the `targs` list.\n",
    "\n",
    "** There's a special case to consider. If two or more consecutive tokens get masked during the process, no need to add a new sentinel to the sequences. To account for this, use the `prev_no_mask` flag, which starts as `True` but is turned to `False` each time I mask a new element. The code that adds sentinels will only be executed if, before masking the token, the flag was in the `True` state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_mask(text, \n",
    "                      noise=0.15, \n",
    "                      randomizer=np.random.uniform, \n",
    "                      tokenizer=None):\n",
    "    \"\"\"Tokenizes and masks a given input.\n",
    "\n",
    "    Args:\n",
    "        text (str or bytes): Text input.\n",
    "        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n",
    "        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n",
    "        tokenizer (function, optional): Tokenizer function. Defaults to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        inps, targs: Lists of integers associated to inputs and targets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Current sentinel number (starts at 0)\n",
    "    cur_sentinel_num = 0\n",
    "    \n",
    "    # Inputs and targets\n",
    "    inps, targs = [], []\n",
    "\n",
    "    # Vocab_size\n",
    "    vocab_size = int(tokenizer.vocab_size())\n",
    "    \n",
    "    # EOS token id \n",
    "    # Must be at the end of each target!\n",
    "    eos = tokenizer.piece_to_id(\"</s>\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n",
    "    # set prev_no_mask to True\n",
    "    prev_no_mask = True\n",
    "    \n",
    "    # Loop over the tokenized text\n",
    "    for token in tokenizer.tokenize(text):\n",
    "        \n",
    "        # Generate a random value between 0 and 1\n",
    "        rnd_val = randomizer() \n",
    "        \n",
    "        # Check if the noise is greater than a random value (weighted coin flip)\n",
    "        if noise > rnd_val:\n",
    "            \n",
    "            # Check if previous token was NOT masked\n",
    "            if prev_no_mask:\n",
    "                \n",
    "                # Current sentinel increases by 1\n",
    "                cur_sentinel_num += 1\n",
    "                \n",
    "                # Compute end_id by subtracting current sentinel value out of the total vocabulary size\n",
    "                end_id = vocab_size - cur_sentinel_num\n",
    "                \n",
    "                # Append end_id at the end of the targets\n",
    "                targs.append(end_id)\n",
    "                \n",
    "                # Append end_id at the end of the inputs\n",
    "                inps.append(end_id)\n",
    "                \n",
    "            # Append token at the end of the targets\n",
    "            targs.append(token)\n",
    "            \n",
    "            # set prev_no_mask accordingly\n",
    "            prev_no_mask = False\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Append token at the end of the inputs\n",
    "            inps.append(token)\n",
    "            \n",
    "            # Set prev_no_mask accordingly\n",
    "            prev_no_mask = True\n",
    "    \n",
    "    \n",
    "    # Add EOS token to the end of the targets\n",
    "    targs.append(eos)\n",
    "    \n",
    "\n",
    "    \n",
    "    return inps, targs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now take random value from the cleaned_data and pass it to `tokenize_and_mask` function and see how it randomly masks and separate inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random data before Masking : \n",
      "\n",
      " የፀጥታ ሁኔታው አስተማማኝ ነው~ጅግጅጋ! . . ስምንተኛውን የከተሞች ፎረም ለማካሄድ ዝግጅቱ መጠናቀቁንና ምንም አይነት የፀጥታ ችግር አለመኖሩን የከተማ ልማትና ኮንስትራክሽን ሚኒስቴር ሚኒስትር ዴኤታ አቶ ካሳሁን ጎፌ ተናገሩ። ዝግጅቱን አስመልክቶ በጅግጅጋ መግለጫ የሰጡት ሚኒስትር ዴኤታው ጅጅጋ ላይ የፀጥታ ሁኔታው አስተማማኝ ነው\"፤ የክልሉ ፖሊስ ከፌዴራል የፀጥታ አካላት ጋርም በቅንጅት እየሰራ ነው ብለዋል። በከተማዋ አስተማማኝ የፀጥታ ሁኔታ መኖሩን የገለፁት ሚኒስትር ዴኤታው ተሳታፊ ከተሞች ወደጅግጅጋ ገብተው ዝግጅታቸውን ጀምረዋል ብለዋል። ዝግጅቶችን በተመለከተ ከነገ ጀምሮ እስከ ረቡዕ ከሚኖሩ ዝግጅቶች መካከል በጅግጅጋ ስቴዲየም የመክፈቻ ስነስርዐት፣ በከተሞች የስራ ዕድል ፈጠራ ኢንተርፕራይዞች ልማት፣ በመሬት ልማት ማኔጅመንት፣ በዘርፉ አጀንዳዎች ማለትም በከተማ ልማት፣ አረንጓዴ ልማትና አካባቢ ጥበቃ፣ በቤቶችና ኮንስትራክሽን እንዲሁም ተያያዥ ዘርፎች ዙሪያ ጥናታዊ ፅሁፎች ይቀርባሉ። አቶ ካሳሁን ከተሞች ራሳቸውን የሚያስተዋውቁበት ኤግዚቢሽን የሚካሄድ ሲሆን ከዚህ በፊት በተደረጉ ፎረሞች የተስተዋለው የድምፅ ብክለት በዚህ አመት እንዳይኖር ከከተሞች ጋር መግባባት ላይ ተደርሷል ብለዋል። ሀሙስ በሚኖረው የማጠቃለያ ስርዓት ለሞዴል ኢንተርፕራይዞች፣ ለሴት ስራ ፈጣሪዎች፣ በሁሉም ክልሎች ካሉ የሴክተር ተቋማት በአፈፃፀም ብልጫ ላገኙ እንዲሁም ለዩኒቨርሲቲ ተመራቂ ስራ ፈጣሪዎች እውቅናና ሽልማት ይሰጣል ተብሏል። በተመሳሳይ የዘጠነኛው የኢትዮጵያ ከተሞች ፎረም አዘጋጅ በእለቱ ይፋ ይደረጋል፤ የዋንጫ ርክክብም ይኖራል ብለዋል ሚኒስትር ዴኤታው። ስምንተኛውን የከተሞች ፎረም የተለየ ለማድረግ ከማሌዥያ አለምአቀፍ የከተሞች ፎረም ልምድ ተወስዷል ያሉት አቶ ካሳሁን ፎረሙ ለመጀመሪያ ጊዜ በታዳጊ ክልል መካሄዱም ልዩ ያደርገዋል ብለዋል። የሱማሌ ክልል ከተማ ልማትና ኮንስትራክሽን ቢሮ ሀላፊ ዶ/ር በበኩላቸው ክልሉ ፎረሙን ለማስተናገድ ዝግጅቱን አጠናቋል፤ ተሳታፊ ከተሞችም ወደ ጅግጅጋ እየገቡ ነው ብለዋል። ቢሮ ሀላፊው በጥቂት ግለሰቦች ከወራት በፊት ተከስቶ የነበረው ችግር ገፅታችንን አበላሽቶ የነበረ ቢሆንም አሁን ግን ምንም የፀጥታም ይሁን የደህንነት ችግር የለም ብለዋል። ዶ/ር አብዱልፈታህ ስምንተኛው የከተሞች ፎረም የክልላችንን ብሎም የከተማችንን አስተማማኝ ሰላም የምናረጋግጥበትና በተግባርም የምናሳይበት እንዲሆን ሰፊ ስራ ሰርተናል ውጤቱንም እያየን ነው ብለዋል። ስምንተኛው የኢትዮጵያ ከተሞች ፎረም ከየካቲት 9-14/2011 ''መደመር ለኢትዮጵያ ከተሞች ብልፅግና'' በሚል መሪ ቃል በጅግጅጋ ይካሄዳል። ምንጭ፦\n"
     ]
    }
   ],
   "source": [
    "random_data=cleaned_data[32000]\n",
    "print(\"Random data before Masking : \\n\\n\", random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps_sample,targs_sample=tokenize_and_mask(random_data,noise=0.15,randomizer=np.random.uniform,tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "\n",
      " የፀጥታ ሁኔታው አስተማማኝ ነው ⁇ ጅግጅጋ! . . ስምንተኛውን<Z> ፎረም ለማካሄድ ዝግጅቱ መጠናቀቁንና<Y> አይነት የፀጥታ ችግር አለመኖሩን የከተማ ልማትና ኮንስትራክሽን ሚኒስቴር ሚኒስትር ዴኤታ አቶ ካሳሁን ጎፌ ተናገሩ። ዝግጅቱን አስመልክቶ በጅግጅጋ መግለጫ የሰጡት<X> ዴኤታው ጅጅጋ ላይ የፀጥታ ሁኔታው አስተማማኝ ነው\"፤ የክልሉ ፖሊስ ከፌዴራል የፀጥታ አካላት ጋር <W> በቅንጅት እየሰራ ነው ብለዋል። በከተማዋ አስተማማኝ የፀጥታ ሁኔታ መኖሩን የገለፁት <V> ዴኤታው ተሳታፊ ከተሞች ወደጅግጅጋ ገብተው<U> ጀምረዋል ብለዋል። ዝግጅቶችን በተመለከተ ከነገ <T> እስከ ረቡዕ ከሚኖሩ ዝግጅቶች መካከል በጅግጅጋ<S> የመክፈቻ ስነስርዐት፣ <R> የስራ<Q> ልማት፣ በመሬት ልማት ማኔጅመንት፣ በዘርፉ አጀንዳዎች ማለትም በከተማ ልማት፣ አረንጓዴ ልማትና አካባቢ ጥበቃ፣ በቤቶችና <P> እንዲሁም ተያያዥ ዘርፎች ዙሪያ ጥናታዊ ፅሁፎች ይቀርባሉ። አቶ<O> ከተሞች ራሳቸውን የሚያስተዋውቁበት<N> የሚካሄድ ሲሆን ከዚህ በፊት <M> ፎረሞች የተስተዋለው የድምፅ ብክለት በዚህ<L> እንዳይኖር ከከተሞች ጋር መግባባት ላይ ተደርሷል ብለዋል። ሀሙስ በሚኖረው የማጠቃለያ ስርዓት ለሞዴል ኢንተርፕራይዞች፣ ለሴት ስራ ፈጣሪዎች፣ በሁሉም ክልሎች ካሉ የሴክተር <K> በአፈፃፀም ብልጫ ላገኙ <J> ለዩኒቨርሲቲ <I> ስራ ፈጣሪዎች እውቅናና ሽልማት ይሰጣል ተብሏል።<H> የ<G> የኢትዮጵያ ከተሞች <F> አዘጋጅ በእለቱ ይፋ <E> የዋንጫ ርክክብም ይኖራል ብለዋል ሚኒስትር ዴኤታው። ስምንተኛውን የከተሞች ፎረም የተለየ ለማድረግ ከ <D> አለምአቀፍ<C> ፎረም ልምድ ተወስ ⁇ <B> ያሉት አቶ ካሳሁን ፎረሙ ለመጀመሪያ <A> በታዳጊ ክልል <z>ም ልዩ ያደርገዋል ብለዋል።<y> ክልል ከተማ ልማትና ኮንስትራክሽን ቢሮ ሀላፊ ዶ/ር<x> ክልሉ ፎረሙን ለማስተናገድ ዝግጅቱን አጠናቋል፤ ተሳታፊ ከተሞችም ወደ ጅግጅጋ እየገቡ ነው ብለዋል። ቢሮ ሀላፊው በጥቂት <w> ከወራት በፊት ተከስቶ የነበረው ችግር ገፅ<v> አበላሽቶ የነበረ ቢሆንም አሁን ግን ምንም የፀጥታም ይሁን የደህንነት ችግር የለም ብለዋል። ዶ <u>ር<t> ስምንተኛው የከተሞች ፎረም የክልላችንን ብሎም የከተማችንን <s> ሰላም የምናረጋግጥበት <r> የምናሳይበት እንዲሆን ሰፊ <q> ሰርተናል <p>ም እያየን ነው ብለዋል። ስምንተኛው የኢትዮጵያ ከተሞች ፎረም ከየካቲት 9-14/2011 ''መደመር ለኢትዮጵያ<o> ብልፅግና'' በሚል መሪ ቃል በጅግጅጋ ይካሄዳል። <n>\n",
      "\n",
      "Targets: \n",
      "\n",
      " <Z> የከተሞች<Y> ምንም<X> ሚኒስትር <W>ም <V> ሚኒስትር<U> ዝግጅታቸውን <T> ጀምሮ<S> ስቴዲየም <R> በከተሞች<Q> ዕድል ፈጠራ ኢንተርፕራይዞች <P> ኮንስትራክሽን<O> ካሳሁን<N> ኤግዚቢሽን <M> በተደረጉ<L> አመት <K> ተቋማት <J> እንዲሁም <I> ተመራቂ<H> በተመሳሳይ<G>ዘጠነኛው <F> ፎረም <E> ይደረጋል፤ <D>ማሌዥያ<C> የከተሞች<B>ል <A> ጊዜ <z> መካሄዱ<y> የሱማሌ<x> በበኩላቸው <w> ግለሰቦች<v>ታችንን <u>/<t> አብዱልፈታህ <s> አስተማማኝ <r>ና በተግባርም <q> ስራ <p> ውጤቱን<o> ከተሞች <n> ምንጭ፦\n"
     ]
    }
   ],
   "source": [
    "print('Inputs: \\n\\n', pretty_decode(inps_sample, sentinels, tokenizer))\n",
    "print('\\nTargets: \\n\\n', pretty_decode(targs_sample, sentinels, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'አስቀድሜ ጥያቄዬ በጨዋነት በውስጥ መስመር እንዲደርስዎ አድርጌ ፍትህን ለማገዝ ብሞክር እርስዎ የመፅሀፍ ቅዱሱ የዳዊት ኦሮዮንን መንገድ በመምረጥዎ በይፋ ለመፃፍ ተገድጃለሁ አሁንም መረጃው እንዴት እሱ ጋር ደረሰ የሚለውን ውትወታ ትተው በማንኛውም መንገድ ቀጥተኛ ምላሽ ይስጡኝ ከመስከረም ወዲያ አሁን ያለሁ መንግስት ህጋዊ የስራ ዘመኑ ስለሚያበቃ የባለአደራ መንግስት እንዲቋቋም ሆኖም አሁን ያለው የአብይ መንግስት አስፈፃሚ አካል የመንግስትን የእለ ተእለት ተግባራትን እየከወነ ምርጫ እስኪደረግ ለ አመት እእነዚህን ወሳኝ ጉዳዮችን የሚያስፈፅም አካል እንዲቋቋምና ክትትል እንዲደረግ በመግለጫው ጠይቀዋል የአማራ ህዝብ በአእምሮ ክንፉ ያልበረረበት ጥበብና ፍልስፍና ያልከፈተው የእውቀት ጎዳና አይኑ ያላየው ጆሮው ያልሰማው ልቡ ያላሰበው እውቀትና ብልሀት የለምከአማራ ህዝብ የሀገሪቱ ዘርፈ ብዙ እውቀት መንጭቶ የሞላበትከሙላቱም በመልክ በመልኩ ሲቀዳበት የኖረ ከኢትዮጵያ አልፎ ለአለም ሲታደል የኖረውና የሚኖረው እውቀት የተገኘበት ታላቅ ነገድ ነው ዛሬ በየትኛውም መለኪያ ይሁን መመዘኛ ኢትዮጵያዊነት የሚንፀባረቀው በአማራ ህዝብ ላይ ብቻ ነውሌላው የትህነግን ባንዲራ ለብሶየኦነግን ባንዲራ እያውለበለበ የኢትዮጵያን ሰንደቅአላማ በእግሩ ረግጦታልጨርቅ ነው ብለው አቃጥለውታልቀዳደው ጥለውታል'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(tokenizer.tokenize(\"አስቀድሜ ጥያቄዬ በጨዋነት በውስጥ መስመር እንዲደርስዎ አድርጌ ፍትህን ለማገዝ ብሞክር  እርስዎ የመፅሀፍ ቅዱሱ የዳዊት  ኦሮዮንን መንገድ በመምረጥዎ በይፋ ለመፃፍ ተገድጃለሁ  አሁንም መረጃው እንዴት እሱ ጋር ደረሰ የሚለውን ውትወታ ትተው በማንኛውም መንገድ ቀጥተኛ ምላሽ ይስጡኝ   ከመስከረም   ወዲያ አሁን ያለሁ መንግስት ህጋዊ የስራ ዘመኑ ስለሚያበቃ የባለአደራ መንግስት እንዲቋቋም ሆኖም አሁን ያለው የአብይ መንግስት አስፈፃሚ አካል የመንግስትን የእለ ተእለት ተግባራትን እየከወነ ምርጫ እስኪደረግ ለ አመት እእነዚህን ወሳኝ ጉዳዮችን የሚያስፈፅም አካል እንዲቋቋምና ክትትል እንዲደረግ በመግለጫው ጠይቀዋል የአማራ ህዝብ በአእምሮ ክንፉ ያልበረረበት ጥበብና ፍልስፍና ያልከፈተው የእውቀት ጎዳና አይኑ ያላየው ጆሮው ያልሰማው ልቡ ያላሰበው እውቀትና ብልሀት የለምከአማራ ህዝብ የሀገሪቱ ዘርፈ ብዙ እውቀት መንጭቶ የሞላበትከሙላቱም በመልክ በመልኩ ሲቀዳበት የኖረ ከኢትዮጵያ አልፎ ለአለም ሲታደል የኖረውና የሚኖረው እውቀት የተገኘበት ታላቅ ነገድ ነው ዛሬ በየትኛውም መለኪያ ይሁን መመዘኛ ኢትዮጵያዊነት የሚንፀባረቀው በአማራ ህዝብ ላይ ብቻ ነውሌላው የትህነግን ባንዲራ ለብሶየኦነግን ባንዲራ እያውለበለበ የኢትዮጵያን ሰንደቅአላማ በእግሩ ረግጦታልጨርቅ ነው ብለው አቃጥለውታልቀዳደው ጥለውታል\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Creating the training data pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create pairs using the cleaned_data by iterating over the data and create(inp,targ) pairs using the function I defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targets_pairs=[tokenize_and_mask(text.encode('utf-8', errors=\"ignore\").decode('utf-8'),tokenizer=tokenizer) for text in cleaned_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "\n",
      " ሰው<Z> ለመርዳት<Y> መሆን በቂ ነው ! ትላንት የካቲት 1/2017 ዓ/<X> በጀመረው የመቄዶንያ የአረጋዊያን እና የአእምሮ ህሙማን መርጃ <W> ማሰባሰብ ዘመቻ እስኩን 120,000,000 ብር ተሰብስቧል። መቄዶንያ በሚያስገነባው ሆስፒታል ጭምር ያለው ህንፃ ለማጠናቀቅ <V> እጥረት<U> ህንፃው ለማጠናቀቅ ገንዘብ ተቸግረናል። ለማጠናቀቅ ወደ 5 ቢሊዮን ብር ያስፈልጋል። በቀጥታ ይከታተሉ የምትችሉትን ሁሉ <T> አድርጉ።\n",
      "\n",
      "Targets: \n",
      "\n",
      " <Z>ን<Y> ሰው<X>ም <W> ማዕከል የድጋፍ <V> የገንዘብ<U> አጋጥሞታል። <T> ድጋፍ\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Inputs: \n",
      "\n",
      " \" ቋሚ ሠራተኞች<Z> ማሻሻያው አልተካተትን<Y> \" - የሀዋሳ ዙሪያ ወረዳ መንግስት ሠራተኞች የማክሮ ኢኮኖሚ ማሻሻያ<X>ን ተከትሎ የሚከሰቱ <W> ዉድነትና ተያያዥ ጉዳዮችን ታሳቢ በማድረግ የመንግስት ሠራተኞች <V> ማሻሻያ ተደርጎ<U> ወር 2017 ዓ/ም ጀምሮ ተግባራዊ የተደረገ መሆኑ ይታወቃል። በሲዳማ ክልል፤ ሰሜናዊ ሲዳማ ዞን፤ ሀዋሳ ዙሪያ ወረዳ በተለያዩ የመንግስት መስሪያ ቤቶች የሚሰሩ የመንግስት <T> ግን \" ከ2012 ዓ/<S> ጀምሮ በቋሚነት ተቀጥረን እየሰራን ያለን ቢሆንም በአዲሱ የመንግስት ሠራተኞች የደመወዝ ማሻሻያ አልተካተት <R>ም \" ሲሉ ቅሬታቸዉን ለቲክቫህ ኢትዮጵያ አስገብተዋል። ቅሬታቸዉን<Q>ን መካከል ፦ <P> በከተማ ልማትና<O>፣<N> ማዘጋጃ ቤቶች፣ - <M> ፣ - በሴቶችና ሕፃናት እንዲሁም በሕብረት ስራ ጽ/<L> የሚሰሩ ሠራተኞች ናቸው። \" በወቅቱ <K> ማስታወቂያ ወጥቶ ተመዝግበንና ተወዳድረን ማለፋችን ተረጋግጦ <J>ቋሚነት ደብዳቤ ተሰጥቶን ላለፉት <I>ና<H> ዓመታት ደሞዝ ሲከፈለን በቆየንባቸው መደቦች ላይ እየሰራን ባለን<G> በአዲሱ <F> ማሻሻያ አለመካተታችን ለዘርፈ ብዙ ችግሮች ዳርጎናል \" ብለዋል። \" ለወረዳዉ  ⁇ ብሊክ <E>ና የሰዉ ሃብት <D>/ቤት እና ለክልሉ  ⁇ ብሊክ ሰርቪስ ቢሮ ቅሬታችንን በአካልና<C> ብናቀርብም ተገቢዉ<B> አልተሰጠንም <A> ለኢትዮጵያ <z> ጠባቂ ተቋም<y> መረጃ እያደራጀን ነው<x> ሲሉ ተናግረዋል። ቃላቸውን ለቲክቫህ ኢትዮጵያ የሰጡት ፤ የሀዋሳ ዙሪያ ወረዳ  ⁇ ብሊክ ሰርቪስ እና የሰዉ ሃብት ልማት ጽ/ <w> አቶ ሃይሉ አቢኖ  ⁇  \" በወረዳዉ በ<v> ዓ/ም የነበረው አግባብነት <u> ቅጥር በአንድ መደብ ሶስት<t> ሰዎችን በተደራራቢ <s> የ <r> ሁኔታዎች አሁን ለተፈጠረው ችግር ዋነኛ <q> ሆኗል \" ሲሉ ገልጸዋል። ከዞኑ <p> የክልሉ  ⁇ ብልክ ሰርቪስ ጋር በመናበብ መፍትሔ እያፈላለጉ ስለመሆኑም ጠቁመዋል። በወቅቱ ይህን ተግባር የፈፀሙ<o> እና የሰዉ ሃብት ልማት ኃላፊዎች ላይ እርምጃ <n> የሚናገሩት ኃላፊዉ በወረዳዉ በዚህ <m> ተጠቀጥ<l> የደመወዝ ማሻሻያ ያልካተቱ <k> በቀጣይ<j>ላቸዉ 470 በተለያዩ መስሪያ ቤቶች ዉስጥ የተለዩ ሰራተኞች ስለመኖራቸዉ አክለዋል። የሰሜናዊ ሲዳማ ዞን <i> ⁇ ብልክ ሰርቪስና የሰዉ ሃይል ልማት<h> ኃላፊ አቶ በዛብህ ባርሶ በበኩላቸው በ<g> 2012 በአከባቢው <f> ቅጥሮች መፈፀማቸውን ገልጸዋል። በ<e> አጣሪ ቡድን ተቋቁሞ በአዲሱ ደሞዝ ያልተካተቱንና<d> ቅጥር ያልተፈፀመባቸዉ ክፍት መደቦች <c> የመለየት ስራ መከናወኑን አንስተዉ በሀዋሳ ዙሪያ<b> ብቻ 407 ክፍት መደቦች መኖራቸዉን ለማወቅ መቻሉን ገልፀዋል። የክልሉ የበላይ አመራሮች በሚያስቀምጡት አቅጣጫ መሰረት እነዚህን ሠራተኞች በነዚህ <a> መደቦች ይወዳታልመደልደልና ሌሎችምስማርትፎን አመራትሏክች በመፈለግ በአጭር ስለምሻ ዉስጥ እልባት ለመስጠት እየተሰራ መሆኑን አስታውቀዋል። ቲክቫህ ኢትዮጵያ ጉዳዩን እስከመጨረሻ ተከታትሎ መረጃውን ይልካል።\n",
      "\n",
      "Targets: \n",
      "\n",
      " <Z> ሆነን ሳለ በደሞዝ<Y>ም<X> ሪፎርሙ <W> የኑሮ <V> ደሞዝ<U> ከጥቅምት <T> ሠራተኞች<S>ም <R>ን<Q> ካደረሱ <P> -<O> ኮንስትራክሽን<N> - <M> በትምህርት ዘርፍ<L>ቤቶች <K> በአግባቡ <J> የ <I> አምስት<H> ስድስት<G>በት <F> የደሞዝ <E> ሰርቪስ <D> ልማት ጽ<C> በፅሁፍ<B> ምላሽ <A> ጉዳዩን <z> እምባ<y> ለማቅረብ<x> \" <w>ቤት ኃላፊ<v>2012 <u> በሌለው<t>ና አራት <s>ነት <r>መቅጠር <q> ምክንያት <p>ና<o> አመራሮች <n> መወሰዱን <m> መልክ<l>ረዉ በአዲሱ <k>ና<j> መፍትሔ የሚፈለግ <i> <h> መምሪያ<g>2011 እና <f> ሕገወጥ<e>ወረዳዉ<d> በወረዳው <c>ን<b> ወረዳ <a> ክፍት ይወዳታል የስማርትፎን ሕጋዊትሏክ ⁇  ስለምሻ ጊዜ\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pairs in inputs_targets_pairs[:2]:\n",
    "    print('Inputs: \\n\\n', pretty_decode(pairs[0], sentinels, tokenizer))\n",
    "    print('\\nTargets: \\n\\n', pretty_decode(pairs[1], sentinels, tokenizer))\n",
    "    print(\"\\n---------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of inputs and targets pairs:  193419\n",
      "Training data size: 154735\n",
      "Validation data size: 38684\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of inputs and targets pairs: \",len(inputs_targets_pairs))\n",
    "training_size=int(len(inputs_targets_pairs)*0.8)\n",
    "training_data=inputs_targets_pairs[:training_size]\n",
    "validation_data=inputs_targets_pairs[training_size:]\n",
    "print(f\"Training data size: {len(training_data)}\")\n",
    "print(f\"Validation data size: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a Tensorflow model we need to arrange the data into datasets. Now, I will get the `inputs` and the `targets` for the transformer model from the `training_data and validation_data`. Before creating the dataset, I need to be sure that all `inputs` have the same length by truncating the longer sequences and padding the shorter ones with `0`. The same must be done for the targets. The function `tf.keras.preprocessing.sequence.pad_sequences` will help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_inputs_padded=tf.keras.utils.pad_sequences(\n",
    "    [pairs[0] for pairs in training_data],\n",
    "    maxlen=None,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    ")\n",
    "training_data_targets_padded=tf.keras.utils.pad_sequences(\n",
    "    [pairs[1] for pairs in training_data],\n",
    "    maxlen=None,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    ")\n",
    "\n",
    "validation_data_inputs_padded=tf.keras.utils.pad_sequences(\n",
    "    [pairs[0] for pairs in validation_data],\n",
    "    maxlen=None,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    ")\n",
    "\n",
    "validation_data_targets_padded=tf.keras.utils.pad_sequences(\n",
    "    [pairs[1] for pairs in validation_data],\n",
    "    maxlen=None,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    ")\n",
    "BUFFER_SIZE = 12000\n",
    "BATCH_SIZE = 64\n",
    "training_dataset_final=tf.data.Dataset.from_tensor_slices((training_data_inputs_padded,training_data_targets_padded))\n",
    "validation_dataset_final=tf.data.Dataset.from_tensor_slices((validation_data_inputs_padded,validation_data_targets_padded))\n",
    "training_dataset_final=training_dataset_final.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_dataset_final=validation_dataset_final.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Tokenize both the training and validation sets using our tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pretraining the Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to define the structure of the transformer network and pretrain it on the dataset given above. The general structure of the transformer model we will build is shown in the figure below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src = \"images/fulltransformer.png\" width=\"500\" height=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "As you can see in the figure, the input embeddings are added with positional embedding vectors to capture the position of words in a sentence. The following function creates positional encoding given the embedding vectors.\n",
    "\n",
    "In sequence-to-sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model. However, when you train a Transformer network using multi-head attention, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i)}= sin\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i+1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "*   `d` is the dimension of the word embedding and positional encoding.\n",
    "*   `pos` is the position of the word.\n",
    "*   `i` refers to each of the different dimensions in the positional encodings, where `i = k // 2`.\n",
    "\n",
    "To develop some intuition about positional encodings, you can think of them broadly as a feature that contains the information about the relative positions of words. The sum of the positional encoding and word embedding is ultimately what is fed into the model.  If you just hard code the positions in, say by adding a matrix of 1's or whole numbers to the word embedding, the semantic meaning is distorted. Conversely, the values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted, and is instead enriched with positional information. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data.\n",
    "\n",
    "### Sine and Cosine Angles\n",
    "\n",
    "Notice that even though the sine and cosine positional encoding equations take in different arguments (`2i` versus `2i+1`, or even versus odd numbers) the inner terms for both equations are the same:\n",
    "\n",
    "$$\\theta(pos, i, d) = \\frac{pos}{10000^{\\frac{2i}{d}}}$$\n",
    "\n",
    "Consider the inner term as you calculate the positional encoding for a word in a sequence:\n",
    "\n",
    "$PE_{(pos, 0)}= sin\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i = 0` gives `i = 0`\n",
    "\n",
    "$PE_{(pos, 1)}= cos\\left(\\frac{pos}{{10000}^{\\frac{0}{d}}}\\right)$, since solving `2i + 1 = 1` gives `i = 0`\n",
    "\n",
    "The angle is the same for both! The angles for $PE_{(pos, 2)}$ and $PE_{(pos, 3)}$ are the same as well, since for both, `i = 1` and therefore the inner term is $\\left(\\frac{pos}{{10000}^{\\frac{2}{d}}}\\right)$. This relationship holds true for all paired sine and cosine curves:\n",
    "\n",
    "| k             | 0                         | 1                         | 2                         | 3                         | ... | d - 2                     | d - 1                     |\n",
    "| ------------- | ------------------------- | ------------------------- | ------------------------- | ------------------------- | --- | ------------------------- | ------------------------- |\n",
    "| encoding(0) = | [sin(θ(0, 0, d))         | cos(θ(0, 0, d))         | sin(θ(0, 1, d))         | cos(θ(0, 1, d))         | ... | sin(θ(0, d//2, d))        | cos(θ(0, d//2, d))        |\n",
    "| encoding(1) = | [sin(θ(1, 0, d))         | cos(θ(1, 0, d))         | sin(θ(1, 1, d))         | cos(θ(1, 1, d))         | ... | sin(θ(1, d//2, d))        | cos(θ(1, d//2, d))        |\n",
    "| ...           | ...                       | ...                       | ...                       | ...                       | ... | ...                       | ...                       |\n",
    "| encoding(pos) =| [sin(θ(pos, 0, d))        | cos(θ(pos, 0, d))        | sin(θ(pos, 1, d))        | cos(θ(pos, 1, d))        | ... | sin(θ(pos, d//2, d))       | cos(θ(pos, d//2, d))]      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d_model):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int): Maximum number of positions to be encoded \n",
    "        d_model (int): Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n",
    "    \"\"\"\n",
    "    \n",
    "    position = np.arange(positions)[:, np.newaxis]\n",
    "    k = np.arange(d_model)[np.newaxis, :]\n",
    "    i = k // 2\n",
    "    \n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
    "    angle_rads = position * angle_rates\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masking we will define here is different from the masking we used while preparing the data for Masked Language modeling. \n",
    "\n",
    "\n",
    "There are two types of masks that are useful when building your Transformer network: the *padding mask* and the *look-ahead mask*. Both help the softmax computation give the appropriate weights to the words in your input sentence. \n",
    "\n",
    "### 1.1 - Padding Mask\n",
    "\n",
    "Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let's say the maximum length of your model is five, it is fed the following sequences:\n",
    "\n",
    "    [[\"Do\", \"you\", \"know\", \"when\", \"Jane\", \"is\", \"going\", \"to\", \"visit\", \"Africa\"], \n",
    "     [\"Jane\", \"visits\", \"Africa\", \"in\", \"September\" ],\n",
    "     [\"Exciting\", \"!\"]\n",
    "    ]\n",
    "\n",
    "which might get vectorized as:\n",
    "\n",
    "    [[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],\n",
    "     [ 56, 1285, 15, 181, 545],\n",
    "     [ 87, 600]\n",
    "    ]\n",
    "    \n",
    "When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:\n",
    "\n",
    "    [[ 71, 121, 4, 56, 99],\n",
    "     [ 2344, 345, 1284, 15, 0],\n",
    "     [ 56, 1285, 15, 181, 545],\n",
    "     [ 87, 600, 0, 0, 0],\n",
    "    ]\n",
    "    \n",
    "Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length. Similarly, for sequences shorter than the maximum length, zeros will also be added for padding.\n",
    "\n",
    "When pasing these vectors through the attention layers, the zeros will typically disappear  (you will get completely new vectors given the mathematical operations that happen in the attention block). However, you still want the network to attend only to the first few numbers in that vector (given by the sentence length) and this is when a padding mask comes in handy. You will need to define a boolean mask that specifies to which elements you must attend (1) and which elements you must ignore (0) and you do this by looking at all the zeros in the sequence. Then you use the mask to set the values of the vectors (corresponding to the zeros in the initial vector) close to negative infinity (-1e9).\n",
    "\n",
    "Imagine your input vector is `[87, 600, 0, 0, 0]`. This would give you a mask of `[1, 1, 0, 0, 0]`. When your vector passes through the attention mechanism, you get another (randomly looking) vector, let's say `[1, 2, 3, 4, 5]`, which after masking becomes `[1, 2, -1e9, -1e9, -1e9]`, so that when you take the softmax, the last three elements (where there were zeros in the input) don't affect the score.\n",
    "\n",
    "The [MultiheadAttention](https://keras.io/api/layers/attention_layers/multi_head_attention/) layer implemented in Keras, uses this masking logic.\n",
    "\n",
    "**Note:** The below functions create the masking of both types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids (matrix like): matrix of size (n, m)\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (n, 1, m)\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding to the attention logits. \n",
    "    # this will allow for broadcasting later when comparing sequences\n",
    "    return seq[:, tf.newaxis, :] \n",
    "\n",
    "\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns a lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length (int): matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 - Self-Attention\n",
    "\n",
    "As the authors of the Transformers paper state, \"Attention is All You Need\". \n",
    "\n",
    "<center><img src=\"images/attention.png\" alt=\"Encoder\" width=\"600\"/></center>\n",
    "\n",
    "<center><caption><font color='purple'><b>Figure 1: Self-Attention calculation visualization</font></</caption></center>\n",
    "    \n",
    "\n",
    "The use of self-attention paired with traditional convolutional networks allows for parallelization which speeds up training. we will implement **scaled dot product attention** which takes in a query, key, value, and a mask as inputs to return rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{4}\\\n",
    "$$\n",
    "\n",
    "* $Q$ is the matrix of queries \n",
    "* $K$ is the matrix of keys\n",
    "* $V$ is the matrix of values\n",
    "* $M$ is the optional mask you choose to apply \n",
    "* ${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode\n",
    "\n",
    "\n",
    "This will be handled by Tensorlfow so we will not searately define a function to handel self-attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the encoder part of the transformer using multi-head attention and feed forward. \n",
    "The structure of the model we will implement will look like the following figure.\n",
    "\n",
    "<center><img src=\"images/encoders.png\" alt=\"Encoder\" width=\"400\" /> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above figure inside the Encoder there is a feed forward layer. Here we will use 2 Dense layers as part of the Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    \"\"\"\n",
    "    Returns a sequential model consisting of two dense layers. The first dense layer has\n",
    "    fully_connected_dim neurons and is activated by relu. The second dense layer has\n",
    "    embedding_dim and no activation.\n",
    "\n",
    "    Arguments:\n",
    "        embedding_dim (int): output dimension\n",
    "        fully_connected_dim (int): dimension of the hidden layer\n",
    "\n",
    "    Returns:\n",
    "        _ (tf.keras.Model): sequential model\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, d_model)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define the encoder layer class that contains both the multi-head attention and the FullyConnected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This architecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out (tf.Tensor): Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        self_mha_output = self.mha(x, x, x, mask)  # Self attention (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # skip connection\n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer\n",
    "        skip_x_attention = self.layernorm1(x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer through a ffn\n",
    "        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output\n",
    "        # to get the output of the encoder layer\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the full Encoder Layer including the Embedding of the tokens and addition of positional embedding with Dropout layer before entering the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Pass input through the Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        # Scale embedding by multiplying it by the square root of the embedding dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        # Add the position encoding to embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        # Pass the encoded embedding through a dropout layer\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the decoder part of the transformer using masked multi-head attention, multi-head attention and feed forward. \n",
    "\n",
    "<b>N.B  pre-training transformer with both Encoder and decoder with MLM is not common task as most models like BERT which are pretrained using masked language modeling(MLM) need only encoders. But here I used both encoder and decoders so that the model can be further pre-trained or fine-tuned for tasks that need both encoder and decoder, like Neural Machine translation as well.</b>\n",
    "\n",
    "The structure of the decoder layer we will implement will look like the following figure.\n",
    "\n",
    "<center><img src=\"images/decoders.png\" alt=\"Encoder\" width=\"400\" /> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The decoder layer is composed by two multi-head attention blocks, \n",
    "    one that takes the new input and uses self-attention, and the other \n",
    "    one that combines it with the output of the encoder, followed by a\n",
    "    fully connected block. \n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output (tf.Tensor): Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            out3 (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attn_weights_block1 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, target_seq_len)\n",
    "            attn_weights_block2 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "  \n",
    "        # enc_output.shape == (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # BLOCK 1\n",
    "        # calculate self-attention and return attention scores as attn_weights_block1.\n",
    "        # Dropout will be applied during training \n",
    "        mult_attn_out1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask, return_attention_scores=True)\n",
    "        \n",
    "        # apply layer normalization (layernorm1) to the sum of the attention output and the input \n",
    "        Q1 = self.layernorm1(mult_attn_out1 + x)\n",
    "\n",
    "        # BLOCK 2\n",
    "        # calculate self-attention using the Q from the first block and K and V from the encoder output. \n",
    "        # Dropout will be applied during training\n",
    "        # Return attention scores as attn_weights_block2 \n",
    "        mult_attn_out2, attn_weights_block2 = self.mha2(Q1,enc_output,enc_output, padding_mask, return_attention_scores=True)\n",
    "        \n",
    "        # # apply layer normalization (layernorm2) to the sum of the attention output and the Q from the first block \n",
    "        mult_attn_out2 = self.layernorm2(mult_attn_out2+Q1)\n",
    "                \n",
    "        #BLOCK 3\n",
    "        # pass the output of the second block through a ffn\n",
    "        ffn_output = self.ffn(mult_attn_out2)\n",
    "        \n",
    "        # apply a dropout layer to the ffn output\n",
    "        # use `training=training`\n",
    "        ffn_output =self.dropout_ffn(ffn_output)\n",
    "        \n",
    "        # apply layer normalization (layernorm3) to the sum of the ffn output and the output of the second block\n",
    "        out3 =self.layernorm3(ffn_output+mult_attn_out2)\n",
    "      \n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the full Decoder Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the target input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    decoder Layers\n",
    "        \n",
    "    \"\"\" \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len)\n",
    "            enc_output (tf.Tensor):  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "\n",
    "        # create word embeddings \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # scale embeddings by multiplying by the square root of their dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        \n",
    "        # add positional encodings to word embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # apply a dropout layer to x\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # use a for loop to pass x through a stack of decoder layers and update attention_weights \n",
    "        for i in range(self.num_layers):\n",
    "            # pass x and the encoder output through a stack of decoder layers and save the attention weights\n",
    "            # of block 1 and 2 \n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   look_ahead_mask=look_ahead_mask,\n",
    "                                                   padding_mask=padding_mask)\n",
    "\n",
    "            #update attention_weights dictionary with the attention weights of block 1 and block 2\n",
    "            attention_weights[f'decoder_layer{i+1}_block1_self_att'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2_decenc_att'] = block2\n",
    "\n",
    "        \n",
    "        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine both the encoder and the decoder layers defined above into a single transformer model. The full structure of the model we will form is depicted below. In the code, in addition to encoder and decoder we will add a final Dense layer with softmax  activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/transformer.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size, \n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_sentence (tf.Tensor): Tensor of shape (batch_size, input_seq_len)\n",
    "                              An array of the indexes of the words in the input sentence\n",
    "            output_sentence (tf.Tensor): Tensor of shape (batch_size, target_seq_len)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            dec_padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output (tf.Tensor): The final output of the model\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "       \n",
    "        # call self.encoder with the appropriate arguments to get the encoder output\n",
    "        enc_output = self.encoder(input_sentence, training, enc_padding_mask)\n",
    "        \n",
    "        # call self.decoder with the appropriate arguments to get the decoder output\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n",
    "        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training, \n",
    "           look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # pass decoder output through a linear layer and softmax\n",
    "        final_output = self.final_layer(dec_output)\n",
    " \n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Intialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will intialize our model to pre-train it on the data we defined. Most of the parameter values we will use here are taken form the <a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need</a> paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum positional encoding length for input: 1385\n",
      "Maximum positional encoding length for target: 408\n"
     ]
    }
   ],
   "source": [
    "#let's find the maximum length in our training data to set it as the maximum positional encoding\n",
    "POSITIONAL_ENCODING_INPUT_LENGTH =training_data_inputs_padded.shape[1]\n",
    "POSITIONAL_ENCODING_TARGET_LENGTH =training_data_targets_padded.shape[1]\n",
    "print(f\"Maximum positional encoding length for input: {POSITIONAL_ENCODING_INPUT_LENGTH}\")\n",
    "print(f\"Maximum positional encoding length for target: {POSITIONAL_ENCODING_TARGET_LENGTH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "NUM_LAYERS = 6\n",
    "EMBEDDING_DIM = 512\n",
    "FULLY_CONNECTED_DIM = 2048\n",
    "NUM_HEADS= 8\n",
    "vocab_size = tokenizer.vocab_size()\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "transformer = Transformer(\n",
    "    NUM_LAYERS, \n",
    "    EMBEDDING_DIM, \n",
    "    NUM_HEADS, \n",
    "    FULLY_CONNECTED_DIM,\n",
    "    vocab_size, \n",
    "    vocab_size, \n",
    "    POSITIONAL_ENCODING_INPUT_LENGTH, \n",
    "    POSITIONAL_ENCODING_TARGET_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finished defining our model and processing our traning and validation datas. The next step will be training !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=1000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(real, pred, loss_object):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer, loss object, and metrics\n",
    "learning_rate = CustomSchedule(d_model=512)  # Replace 512 with your model's embedding dimension\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# Metrics to track losses\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar, model, loss_object, optimizer, train_loss):\n",
    "    tar_inp = tar[:, :-1]  # Input to the decoder (shifted right)\n",
    "    tar_real = tar[:, 1:]  # Target output (shifted left)\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Pass `training=True` as a keyword argument\n",
    "        predictions, _ = model(\n",
    "            inp, tar_inp, \n",
    "            training=True,  # <-- Fix: Pass as keyword argument\n",
    "            enc_padding_mask=enc_padding_mask, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            padding_mask=enc_padding_mask\n",
    "        )\n",
    "        loss = masked_loss(tar_real, predictions, loss_object)  # Compute masked loss\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)  # Update the training loss metric\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def val_step(inp, tar, model, loss_object, val_loss):\n",
    "    tar_inp = tar[:, :-1]  # Input to the decoder (shifted right)\n",
    "    tar_real = tar[:, 1:]  # Target output (shifted left)\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "\n",
    "    # Forward pass\n",
    "    # Pass `training=False` as a keyword argument\n",
    "    predictions, _ = model(\n",
    "        inp, tar_inp, \n",
    "        training=False,  # <-- Fix: Pass as keyword argument\n",
    "        enc_padding_mask=enc_padding_mask, \n",
    "        look_ahead_mask=look_ahead_mask, \n",
    "        padding_mask=enc_padding_mask\n",
    "    )\n",
    "    \n",
    "    # Compute masked loss\n",
    "    loss = masked_loss(tar_real, predictions, loss_object)\n",
    "    \n",
    "    # Update the validation loss metric\n",
    "    val_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1/2418\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/ipykernel_5709/4039732158.py\", line 47, in train_step  *\n        predictions, _ = model(\n    File \"/Users/mahder/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3186, in bind\n        return self._bind(args, kwargs)\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3156, in _bind\n        raise TypeError('missing a required argument: {arg!r}'. \\\n\n    TypeError: missing a required argument: 'dec_padding_mask'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    120\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m--> 121\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_dataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[126], line 101\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, epochs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataset):\n",
      "File \u001b[0;32m~/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/__autograph_generated_file6yp7b8ce.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(inp, tar, model, loss_object, optimizer, train_loss)\u001b[0m\n\u001b[1;32m     11\u001b[0m look_ahead_mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(create_look_ahead_mask), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(tar_inp),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m1\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 13\u001b[0m     (predictions, _) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtar_inp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(masked_loss), (ag__\u001b[38;5;241m.\u001b[39mld(tar_real), ag__\u001b[38;5;241m.\u001b[39mld(predictions), ag__\u001b[38;5;241m.\u001b[39mld(loss_object)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py:3156\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3150\u001b[0m     \u001b[38;5;66;03m# We have no value for this parameter.  It's fine though,\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;66;03m# if it has a default value, or it is an '*args'-like\u001b[39;00m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;66;03m# parameter, left alone by the processing of positional\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m     \u001b[38;5;66;03m# arguments.\u001b[39;00m\n\u001b[1;32m   3154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m partial \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m _VAR_POSITIONAL \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m                                         param\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m _empty):\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m   3157\u001b[0m                         \u001b[38;5;28mformat\u001b[39m(arg\u001b[38;5;241m=\u001b[39mparam_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _POSITIONAL_ONLY:\n\u001b[1;32m   3161\u001b[0m         \u001b[38;5;66;03m# This should never happen in case of a properly built\u001b[39;00m\n\u001b[1;32m   3162\u001b[0m         \u001b[38;5;66;03m# Signature object (but let's have this check here\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m         \u001b[38;5;66;03m# to ensure correct behaviour just in case)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/ipykernel_5709/4039732158.py\", line 47, in train_step  *\n        predictions, _ = model(\n    File \"/Users/mahder/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3186, in bind\n        return self._bind(args, kwargs)\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3156, in _bind\n        raise TypeError('missing a required argument: {arg!r}'. \\\n\n    TypeError: missing a required argument: 'dec_padding_mask'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Custom learning rate schedule\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=1000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)  # 1 / sqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)  # step / (warmup_steps ** 1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# Masked loss function\n",
    "def masked_loss(real, pred, loss_object):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))  # Mask for padding tokens (assuming 0 is the padding token)\n",
    "    loss_ = loss_object(real, pred)  # Compute the loss for each token\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)  # Cast the mask to the same dtype as the loss\n",
    "    loss_ *= mask  # Apply the mask\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)  # Return the mean loss over non-padding tokens\n",
    "\n",
    "# Define the optimizer, loss object, and metrics\n",
    "learning_rate = CustomSchedule(d_model=512)  # Replace 512 with your model's embedding dimension\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# Metrics to track losses\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "# Training step\n",
    "@tf.function\n",
    "def train_step(inp, tar, model, loss_object, optimizer, train_loss):\n",
    "    tar_inp = tar[:, :-1]  # Input to the decoder (shifted right)\n",
    "    tar_real = tar[:, 1:]  # Target output (shifted left)\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Pass `training=True` as a keyword argument\n",
    "        predictions, _ = model(\n",
    "            inp, tar_inp, \n",
    "            training=True,  # <-- Fix: Pass as keyword argument\n",
    "            enc_padding_mask=enc_padding_mask, \n",
    "            look_ahead_mask=look_ahead_mask, \n",
    "            padding_mask=enc_padding_mask\n",
    "        )\n",
    "        loss = masked_loss(tar_real, predictions, loss_object)  # Compute masked loss\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)  # Update the training loss metric\n",
    "\n",
    "# Validation step\n",
    "@tf.function\n",
    "def val_step(inp, tar, model, loss_object, val_loss):\n",
    "    tar_inp = tar[:, :-1]  # Input to the decoder (shifted right)\n",
    "    tar_real = tar[:, 1:]  # Target output (shifted left)\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "\n",
    "    # Forward pass\n",
    "    # Pass `training=False` as a keyword argument\n",
    "    predictions, _ = model(\n",
    "        inp, tar_inp, \n",
    "        training=False,  # <-- Fix: Pass as keyword argument\n",
    "        enc_padding_mask=enc_padding_mask, \n",
    "        look_ahead_mask=look_ahead_mask, \n",
    "        padding_mask=enc_padding_mask\n",
    "    )\n",
    "    \n",
    "    # Compute masked loss\n",
    "    loss = masked_loss(tar_real, predictions, loss_object)\n",
    "    \n",
    "    # Update the validation loss metric\n",
    "    val_loss(loss)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_dataset, val_dataset, epochs):\n",
    "    losses = []  # List to store (train_loss, val_loss) for each epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Reset metrics at the start of each epoch\n",
    "        train_loss.reset_state()\n",
    "        val_loss.reset_state()\n",
    "\n",
    "        # Training phase\n",
    "        for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "            print(f'Epoch {epoch+1}, Batch {batch+1}/{len(train_dataset)}', end='\\r')\n",
    "            train_step(inp, tar, model, loss_object, optimizer, train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        for (batch, (inp, tar)) in enumerate(val_dataset):\n",
    "            val_step(inp, tar, model, loss_object, val_loss)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss.result():.4f}, Val Loss: {val_loss.result():.4f}')\n",
    "        losses.append((train_loss.result(), val_loss.result()))  # Store losses for later analysis\n",
    "\n",
    "        # Print the time taken for the epoch\n",
    "        print(f'Time taken for one epoch: {time.time() - start} sec')\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save_weights('./model_weights')\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "losses = train_model(transformer, training_dataset_final, validation_dataset_final, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1/2418\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/ipykernel_5709/1244604823.py\", line 12, in train_step  *\n        predictions, _ = model(\n    File \"/Users/mahder/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3186, in bind\n        return self._bind(args, kwargs)\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3156, in _bind\n        raise TypeError('missing a required argument: {arg!r}'. \\\n\n    TypeError: missing a required argument: 'dec_padding_mask'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_dataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[123], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataset):\n",
      "File \u001b[0;32m~/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/__autograph_generated_filefr62rc36.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(inp, tar, model, loss_object, optimizer, train_loss)\u001b[0m\n\u001b[1;32m     11\u001b[0m look_ahead_mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(create_look_ahead_mask), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(tar_inp),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m1\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 13\u001b[0m     (predictions, _) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtar_inp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_padding_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(masked_loss), (ag__\u001b[38;5;241m.\u001b[39mld(tar_real), ag__\u001b[38;5;241m.\u001b[39mld(predictions), ag__\u001b[38;5;241m.\u001b[39mld(loss_object)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py:3156\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3150\u001b[0m     \u001b[38;5;66;03m# We have no value for this parameter.  It's fine though,\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;66;03m# if it has a default value, or it is an '*args'-like\u001b[39;00m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;66;03m# parameter, left alone by the processing of positional\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m     \u001b[38;5;66;03m# arguments.\u001b[39;00m\n\u001b[1;32m   3154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m partial \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m _VAR_POSITIONAL \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m                                         param\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m _empty):\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m \\\n\u001b[1;32m   3157\u001b[0m                         \u001b[38;5;28mformat\u001b[39m(arg\u001b[38;5;241m=\u001b[39mparam_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _POSITIONAL_ONLY:\n\u001b[1;32m   3161\u001b[0m         \u001b[38;5;66;03m# This should never happen in case of a properly built\u001b[39;00m\n\u001b[1;32m   3162\u001b[0m         \u001b[38;5;66;03m# Signature object (but let's have this check here\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m         \u001b[38;5;66;03m# to ensure correct behaviour just in case)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/var/folders/y6/b7qt1wsj5hs191q5tfnn06dw0000gn/T/ipykernel_5709/1244604823.py\", line 12, in train_step  *\n        predictions, _ = model(\n    File \"/Users/mahder/Real Projects/Mahder AI/MlEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3186, in bind\n        return self._bind(args, kwargs)\n    File \"/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\", line 3156, in _bind\n        raise TypeError('missing a required argument: {arg!r}'. \\\n\n    TypeError: missing a required argument: 'dec_padding_mask'\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "losses = train_model(transformer, training_dataset_final, validation_dataset_final, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
