{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1><b>Pretraining a Transformer Model from Scratch on an Amharic Dataset and Fine-Tuning for Amharic Hate Speech Recognition</b></h1>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  \n",
    "\n",
    "1. [Introduction](#introduction)  \n",
    "2. [Dataset Collection & Preprocessing](#dataset-collection--preprocessing)  \n",
    "   - 2.1 [Data Collection](#data-collection)  \n",
    "   - 2.2 [Data Cleaning](#data-cleaning)  \n",
    "   - 2.3 [Tokenization](#tokenization)  \n",
    "3. [Pretraining the Transformer Model](#pretraining-the-transformer-model)  \n",
    "4. [Fine-Tuning for Hate Speech Recognition](#fine-tuning-for-hate-speech-recognition)  \n",
    "5. [Evaluation](#evaluation)  \n",
    "6. [Deployment on Mahder AI App](#deployment-on-mahder-ai-app)  \n",
    "7. [Conclusion](#conclusion)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "\n",
    "In this notebook, I will pretrain a Transformer network on an Amharic dataset collected from a variety of Telegram channels from scratch using the Masked Language Model (MLM). Then, I will fine-tune it on hate speech labeled data and deploy the model on the **Mahder AI** app.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection  \n",
    "\n",
    "In order to pretrain the Transformer network from scratch, we will use **self-supervised learning**, which requires a large corpus of unlabeled text. We will apply a **Masked Language Model (MLM)** to pre-train the model.  \n",
    "\n",
    "#### **Why Telegram Channels?**  \n",
    "Telegram is the most widely used platform for information storage in Ethiopia. For this reason, I have chosen **Telegram channels** as the primary data source. Most of the selected channels are news channels, ensuring a diverse and rich dataset.  \n",
    "\n",
    "#### **Data Collection Method**  \n",
    "To collect the data, I used the **Telethon Python library** and the **Telegram API** to scrape text from selected channels.  \n",
    "\n",
    "#### **Selected Telegram Channels**  \n",
    "The dataset has been collected from the following Telegram channels:  \n",
    "\n",
    "- [Tikvah Ethiopia](https://t.me/tikvahethiopia)  \n",
    "- [Addis Standard Amharic](https://t.me/AddisstandardAmh)  \n",
    "- [Tarikn Wedehuala](https://t.me/TariknWedehuala)  \n",
    "- [Addis News](https://t.me/Addis_News)  \n",
    "- [Zena 24 Now](https://t.me/zena24now)  \n",
    "- [Tikvah University](https://t.me/TikvahUniversity)  \n",
    "- [Tikvah Ethiopia Magazine](https://t.me/tikvahethmagazine)  \n",
    "- [Tikvah Ethiopia Sport](https://t.me/tikvahethsport)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
